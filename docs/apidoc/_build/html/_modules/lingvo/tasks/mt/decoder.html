

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lingvo.tasks.mt.decoder &mdash; lingvo  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../../index.html" class="icon icon-home"> lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.tasks.mt.decoder</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.tasks.mt.decoder</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;Machine translation decoder.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">range</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">zip</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">function</span>

<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">attention</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">base_decoder</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">base_layer</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">cluster_factory</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">layers_with_attention</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">model_helper</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">plot</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">quant_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">rnn_cell</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">rnn_layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">summary_utils</span>


<span class="nd">@function</span><span class="o">.</span><span class="n">Defun</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">AssertIdShape</span><span class="p">(</span><span class="n">expected_ids_shape_pattern</span><span class="p">,</span> <span class="n">ids_shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
  <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span>
      <span class="n">py_utils</span><span class="o">.</span><span class="n">assert_shape_match</span><span class="p">(</span><span class="n">ids_shape</span><span class="p">,</span> <span class="n">expected_ids_shape_pattern</span><span class="p">)</span>
  <span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">py_utils</span><span class="o">.</span><span class="n">assert_shape_match</span><span class="p">(</span><span class="n">ids_shape</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">x_shape</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">ids_shape</span><span class="p">)</span>


<div class="viewcode-block" id="MTBaseDecoder"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder">[docs]</a><span class="k">class</span> <span class="nc">MTBaseDecoder</span><span class="p">(</span><span class="n">base_decoder</span><span class="o">.</span><span class="n">BaseBeamSearchDecoder</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Base class for Lingvo MT decoders.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="MTBaseDecoder.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MTBaseDecoder</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;label_smoothing&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Label smoothing class.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Softmax params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;per_word_avg_loss&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Compute loss averaged per word. If False &#39;</span>
             <span class="s1">&#39;loss is computed averaged per sequence.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;random_seed&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
             <span class="s1">&#39;If set, this decides the random seed to apply in various random&#39;</span>
             <span class="s1">&#39; ops such that this decoder is deterministic. Set this&#39;</span>
             <span class="s1">&#39; random_seed only for unittests.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;unidi_rnn_type&#39;</span><span class="p">,</span> <span class="s1">&#39;func&#39;</span><span class="p">,</span> <span class="s1">&#39;Options: func, native_cudnn. &#39;</span>
             <span class="s1">&#39;func: FRNN, native_cudnn: CuDNNLSTM.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;feed_attention_context_vec_to_softmax&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;Whether to concatenate attention context vector to rnn output&#39;</span>
             <span class="s1">&#39; before softmax.&#39;</span><span class="p">)</span>

    <span class="c1"># Default config for the softmax part.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32000</span>  <span class="c1"># 32k</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">=</span> <span class="mi">8</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="nd">@base_layer</span><span class="o">.</span><span class="n">initializer</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MTBaseDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;smoother&#39;</span>
      <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;smoother&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span><span class="p">)</span>

<div class="viewcode-block" id="MTBaseDecoder._FPropSoftmax"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._FPropSoftmax">[docs]</a>  <span class="k">def</span> <span class="nf">_FPropSoftmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                    <span class="n">theta</span><span class="p">,</span>
                    <span class="n">softmax_input</span><span class="p">,</span>
                    <span class="n">target_labels</span><span class="p">,</span>
                    <span class="n">target_weights</span><span class="p">,</span>
                    <span class="n">target_paddings</span><span class="p">,</span>
                    <span class="n">target_segment_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes cross-entropy loss given the softmax input, labels and weights.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this</span>
<span class="sd">        layer and its children layers.</span>
<span class="sd">      softmax_input: A tensor of shape [time, batch, p.softmax.input_dim].</span>
<span class="sd">      target_labels: A matrix of tf.int32. [time, batch].</span>
<span class="sd">      target_weights: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      target_paddings: A matrix of params.dtype. [time, batch].</span>
<span class="sd">      target_segment_ids: A matrix of params.dtype. [time, batch].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A dictionary containing metrics for the xent loss and prediction accuracy.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">softmax_input</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">softmax_input</span><span class="p">],</span>
          <span class="n">class_weights</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
          <span class="n">class_ids</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_labels</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># [time, batch, num_classes]</span>
      <span class="n">target_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">smoother</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">smoother</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">),</span>
                              <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">target_labels</span><span class="p">),</span>
                              <span class="n">target_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
      <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">softmax_input</span><span class="p">],</span>
          <span class="n">class_weights</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
          <span class="n">class_probabilities</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_probs</span><span class="p">,</span>
                                         <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">]))</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">per_word_avg_loss</span><span class="p">:</span>
      <span class="n">final_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
      <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">total_weight</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;num_predictions&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># NOTE: Per-sequence loss is the sum of each example&#39;s loss.  The</span>
      <span class="c1"># final loss for a training batch is the mean loss of sequences in</span>
      <span class="c1"># the batch.</span>
      <span class="c1"># [time, batch]</span>
      <span class="n">per_example_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">per_example_xent</span><span class="p">,</span>
                                    <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">))</span>
      <span class="n">per_sequence_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">per_example_loss</span> <span class="o">*</span> <span class="n">target_weights</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">target_segment_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
            <span class="s1">&#39;Need target segment ids for &#39;</span>
            <span class="s1">&#39;normalizing loss when training with packed inputs.&#39;</span><span class="p">)</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_segment_ids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">target_segment_ids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">per_sequence_loss</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">per_sequence_loss</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_samples</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">per_sequence_loss</span><span class="p">)</span>
      <span class="n">loss_weight</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">per_sequence_loss</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">ret_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">final_loss</span><span class="p">,</span> <span class="n">loss_weight</span><span class="p">),</span>
        <span class="s1">&#39;log_pplx&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span><span class="p">,</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">total_weight</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="c1"># NOTE: tf.argmax is not implemented for the JF backend, see b/36093673</span>
    <span class="c1"># Skip the fraction_of_correct_next_step_preds during training.</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">is_eval</span><span class="p">:</span>
      <span class="n">logits</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">logits</span>
      <span class="n">correct_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_labels</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])),</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">correct_next_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
          <span class="n">correct_preds</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
      <span class="n">num_preds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">target_weights</span><span class="p">)</span>
      <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span>
          <span class="n">correct_next_preds</span> <span class="o">/</span> <span class="n">num_preds</span><span class="p">,</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fraction_of_correct_next_step_preds&#39;</span><span class="p">)</span>
      <span class="n">ret_dict</span><span class="p">[</span><span class="s1">&#39;fraction_of_correct_next_step_preds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">num_preds</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ret_dict</span></div>

<div class="viewcode-block" id="MTBaseDecoder.ComputeLoss"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder.ComputeLoss">[docs]</a>  <span class="k">def</span> <span class="nf">ComputeLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">segment_id</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
      <span class="n">segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">segment_ids</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FPropSoftmax</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span>
                              <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">weights</span><span class="p">),</span>
                              <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">),</span> <span class="n">segment_id</span><span class="p">)</span></div>

<div class="viewcode-block" id="MTBaseDecoder._TruncateTargetSequence"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._TruncateTargetSequence">[docs]</a>  <span class="k">def</span> <span class="nf">_TruncateTargetSequence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Truncate padded time steps from all sequences.&quot;&quot;&quot;</span>
    <span class="c1"># The following tensors are all in the [batch, time] shape.</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># Let&#39;s make a copy of targets.</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">target_ids</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span>
    <span class="n">target_labels</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">labels</span>
    <span class="n">target_weights</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">weights</span>
    <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span>
    <span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_int32</span><span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">target_paddings</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="n">summary_utils</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s1">&#39;max_seq_length&#39;</span><span class="p">,</span> <span class="n">max_seq_length</span><span class="p">)</span>
    <span class="c1"># Assert to make sure after max_seq_length, all are padded steps for all</span>
    <span class="c1"># sequences.</span>
    <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">([</span>
        <span class="n">py_utils</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">[:,</span> <span class="n">max_seq_length</span><span class="p">:]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="p">],</span> <span class="n">target_paddings</span><span class="p">)</span>
    <span class="n">target_ids</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">([</span>
        <span class="n">AssertIdShape</span><span class="p">(</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">),</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_labels</span><span class="p">),</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">),</span>
            <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_weights</span><span class="p">))</span>
    <span class="p">],</span> <span class="n">target_ids</span><span class="p">)</span>
    <span class="n">targets</span><span class="o">.</span><span class="n">ids</span> <span class="o">=</span> <span class="n">target_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_seq_length</span><span class="p">]</span>
    <span class="n">targets</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">target_labels</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_seq_length</span><span class="p">]</span>
    <span class="n">targets</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">target_weights</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_seq_length</span><span class="p">]</span>
    <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span> <span class="o">=</span> <span class="n">target_paddings</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_seq_length</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">targets</span></div>

<div class="viewcode-block" id="MTBaseDecoder._AddAttenProbsSummary"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTBaseDecoder._AddAttenProbsSummary">[docs]</a>  <span class="k">def</span> <span class="nf">_AddAttenProbsSummary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Add image summary of attention probs.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_paddings: source padding, of shape [src_len, src_batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">          predict. Each tensor in targets is of shape [tgt_batch, tgt_len].</span>
<span class="sd">      atten_probs: a list of attention probs, each element is of shape</span>
<span class="sd">          [tgt_len, tgt_batch, src_len].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plot</span><span class="o">.</span><span class="n">MatplotlibFigureSummary</span><span class="p">(</span>
        <span class="s1">&#39;decoder_example&#39;</span><span class="p">,</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">num_rows</span><span class="p">),</span>
        <span class="n">max_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">subplot_grid_shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">PlotAttention</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">cur_atten_probs</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">set_x_label</span><span class="p">):</span>
      <span class="n">plot</span><span class="o">.</span><span class="n">AddImage</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">cur_atten_probs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">)</span>
      <span class="n">axes</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">plot</span><span class="o">.</span><span class="n">ToUnicode</span><span class="p">(</span><span class="s1">&#39;Output sequence index&#39;</span><span class="p">),</span> <span class="n">wrap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">set_x_label</span><span class="p">:</span>
        <span class="n">axes</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">plot</span><span class="o">.</span><span class="n">ToUnicode</span><span class="p">(</span><span class="s1">&#39;Input sequence index&#39;</span><span class="p">),</span> <span class="n">wrap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">srclen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">source_paddings</span><span class="p">[:,</span> <span class="n">index</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">tgtlen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">probs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">):</span>
      <span class="c1"># Extract first entry in batch of attention prob matrices</span>
      <span class="c1"># [tgt_len, src_len]</span>
      <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[:,</span> <span class="n">index</span><span class="p">,</span> <span class="p">:]</span>
      <span class="n">probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">probs</span><span class="p">[:</span><span class="n">tgtlen</span><span class="p">,</span> <span class="p">:</span><span class="n">srclen</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">fig</span><span class="o">.</span><span class="n">AddSubplot</span><span class="p">(</span>
          <span class="p">[</span><span class="n">probs</span><span class="p">],</span>
          <span class="n">PlotAttention</span><span class="p">,</span>
          <span class="n">title</span><span class="o">=</span><span class="s1">&#39;atten_probs_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span>
          <span class="n">set_x_label</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">Finalize</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="MTDecoderV1"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1">[docs]</a><span class="k">class</span> <span class="nc">MTDecoderV1</span><span class="p">(</span><span class="n">MTBaseDecoder</span><span class="p">,</span> <span class="n">quant_utils</span><span class="o">.</span><span class="n">QuantizableLayer</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;MT decoder v1.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="MTDecoderV1.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MTDecoderV1</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="c1"># Shared embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span> <span class="s1">&#39;Embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;source_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;Dimension of the source encoding.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;attention&#39;</span><span class="p">,</span> <span class="n">attention</span><span class="o">.</span><span class="n">AdditiveAttention</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Additive attention params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;atten_rnn_cell_tpl&#39;</span><span class="p">,</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Attention RNNCell params template.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;rnn_cell_tpl&#39;</span><span class="p">,</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;RNNCell params template.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;rnn_cell_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;size of the rnn cells.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;rnn_layers&#39;</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;Number of rnn layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;residual_start&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Start residual connections from this layer.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;target_seq_len&#39;</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="s1">&#39;During beam search, decodes &#39;</span>
             <span class="s1">&#39;up to this length.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;atten_rnn_cls&#39;</span><span class="p">,</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNNWithAttention</span><span class="p">,</span>
             <span class="s1">&#39;Which atten rnn cls to use.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;use_prev_atten_ctx&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
             <span class="s1">&#39;If True, all decoder layers use previous attention context as &#39;</span>
             <span class="s1">&#39;input. Otherwise, only first decoder layer uses previous &#39;</span>
             <span class="s1">&#39;attention context and the rest of the layers use current &#39;</span>
             <span class="s1">&#39;attention context.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;dropout_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Prob at which we do dropout.&#39;</span><span class="p">)</span>
    <span class="c1"># Default value was mildly tuned. Could be further tuned in the future.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;qlogsoftmax_range_min&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="s1">&#39;Quantization of the output of &#39;</span>
             <span class="s1">&#39;log softmax.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;use_zero_atten_state&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;To use zero attention state &#39;</span>
        <span class="s1">&#39;instead of computing attention with zero query vector.&#39;</span><span class="p">)</span>

    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;cc_schedule&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Clipping cap schedule.&#39;</span><span class="p">)</span>

    <span class="n">disable_vn</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">VariationalNoiseParams</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">default_params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.04</span><span class="p">)</span>

    <span class="c1"># Default config for the embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">32000</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">default_params_init</span>

    <span class="c1"># Default config for the attention model.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Filled in after dims are known.</span>
    <span class="c1"># Default config for the attention rnn cell.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">atten_rnn_cell_tpl</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">atten_rnn_cell_tpl</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">default_params_init</span>
    <span class="c1"># Default config for the rnn cell.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">default_params_init</span>
    <span class="c1"># Default config for the softmax part.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">disable_vn</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32000</span>  <span class="c1"># 32k</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">default_params_init</span>

    <span class="c1"># Default config for beam search.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">length_normalization</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">coverage_penalty</span> <span class="o">=</span> <span class="mf">0.2</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="nd">@base_layer</span><span class="o">.</span><span class="n">initializer</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MTDecoderV1</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">cc_schedule</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cc_schedule</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;cc_schedule&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
        <span class="n">emb_device</span> <span class="o">=</span> <span class="n">cluster_factory</span><span class="o">.</span><span class="n">Current</span><span class="p">()</span><span class="o">.</span><span class="n">WorkerDeviceInModelSplit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">emb_device</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">emb_device</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="p">)</span>

        <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span>
        <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">query_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span>
        <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">params_init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span>
              <span class="mf">1.</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">query_dim</span><span class="p">))</span>
        <span class="n">atten_params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>

        <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">atten_rnn_cell_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;atten_rnn&#39;</span>
        <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">params</span><span class="o">.</span><span class="n">reset_cell_state</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
        <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span>
        <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span>
        <span class="n">atten_rnn_cell</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>

        <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">atten_rnn_cls</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;frnn_with_atten&#39;</span>
        <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">atten_rnn_cell</span>
        <span class="n">params</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">atten_params</span>
        <span class="n">params</span><span class="o">.</span><span class="n">output_prev_atten_ctx</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">use_prev_atten_ctx</span>
        <span class="n">params</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
        <span class="n">params</span><span class="o">.</span><span class="n">use_zero_atten_state</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">use_zero_atten_state</span>
        <span class="n">params</span><span class="o">.</span><span class="n">atten_context_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;frnn_with_atten&#39;</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

        <span class="c1"># TODO(zhifengc): Avoid this?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rnn_attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">rnn_cell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">attention</span>

        <span class="n">rnn_layers_params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_layers</span><span class="p">):</span>
          <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
          <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
          <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
          <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span>
          <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span>
          <span class="n">params</span><span class="o">.</span><span class="n">reset_cell_state</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
          <span class="n">rnn_cell_p</span> <span class="o">=</span> <span class="n">params</span>

          <span class="n">params</span> <span class="o">=</span> <span class="n">model_helper</span><span class="o">.</span><span class="n">CreateUnidirectionalRNNParams</span><span class="p">(</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">rnn_cell_p</span><span class="p">)</span>
          <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;frnn</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
          <span class="n">params</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
          <span class="n">rnn_layers_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;frnn&#39;</span><span class="p">,</span> <span class="n">rnn_layers_params</span><span class="p">)</span>

      <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">feed_attention_context_vec_to_softmax</span><span class="p">:</span>
        <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

      <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;beam_search&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="p">)</span>

<div class="viewcode-block" id="MTDecoderV1.ApplyDropout"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.ApplyDropout">[docs]</a>  <span class="k">def</span> <span class="nf">ApplyDropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="o">&lt;</span> <span class="mf">1.0</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">is_eval</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x_in</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">dropout_prob</span><span class="p">)</span></div>

<div class="viewcode-block" id="MTDecoderV1.ApplyClipping"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.ApplyClipping">[docs]</a>  <span class="k">def</span> <span class="nf">ApplyClipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cc_schedule</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">cc_schedule</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">x</span></div>

  <span class="nd">@py_utils</span><span class="o">.</span><span class="n">NameScopeDecorator</span><span class="p">(</span><span class="s1">&#39;MTDecoderV1/ComputePredictions&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">ComputePredictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span>
                         <span class="n">src_segment_id</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decodes `targets` given encoded source.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      source_encs: source encoding, of shape [time, batch, depth].</span>
<span class="sd">      source_paddings: source encoding&#39;s padding, of shape [time, batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [batch, time].</span>
<span class="sd">      src_segment_id: source segment id, of shape [time, batch].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A Tensor with shape [time, batch, params.softmax.input_dim].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">time</span><span class="p">,</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">])</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="n">target_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasRank</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">target_segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">segment_ids</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">target_segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">use_tpu</span><span class="p">():</span>
        <span class="n">emb_device</span> <span class="o">=</span> <span class="n">cluster_factory</span><span class="o">.</span><span class="n">Current</span><span class="p">()</span><span class="o">.</span><span class="n">WorkerDeviceInModelSplit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">emb_device</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">emb_device</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="n">summary_utils</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s1">&#39;input_emb&#39;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyDropout</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_emb_out</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="c1"># Layer 0 interwines with attention.</span>
        <span class="p">(</span><span class="n">atten_ctxs</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="p">,</span>
            <span class="n">source_encs</span><span class="p">,</span>
            <span class="n">source_paddings</span><span class="p">,</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">target_paddings</span><span class="p">,</span>
            <span class="n">src_segment_id</span><span class="o">=</span><span class="n">src_segment_id</span><span class="p">,</span>
            <span class="n">segment_id</span><span class="o">=</span><span class="n">target_segment_id</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">add_summary</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_AddAttenProbsSummary</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="p">[</span><span class="n">atten_probs</span><span class="p">])</span>

        <span class="n">atten_ctxs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">atten_ctxs</span><span class="p">)</span>
        <span class="n">summary_utils</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s1">&#39;atten_ctxs&#39;</span><span class="p">,</span> <span class="n">atten_ctxs</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frnn</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">frnn</span><span class="p">)):</span>
          <span class="c1"># Forward through Layer-(i + 1) because Layer-0 handled before.</span>
          <span class="n">ys</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
              <span class="n">layer_theta</span><span class="p">,</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">xs</span><span class="p">,</span> <span class="n">atten_ctxs</span><span class="p">],</span> <span class="mi">2</span><span class="p">),</span>
              <span class="n">target_paddings</span><span class="p">,</span>
              <span class="n">segment_id</span><span class="o">=</span><span class="n">target_segment_id</span><span class="p">)</span>
          <span class="n">ys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyDropout</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
          <span class="k">if</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">p</span><span class="o">.</span><span class="n">residual_start</span><span class="p">:</span>
            <span class="n">xs</span> <span class="o">+=</span> <span class="n">ys</span>  <span class="c1"># Residual skip</span>
            <span class="n">xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">xs</span> <span class="o">=</span> <span class="n">ys</span>
          <span class="n">summary_utils</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s1">&#39;layer_out_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">feed_attention_context_vec_to_softmax</span><span class="p">:</span>
          <span class="n">xs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">xs</span><span class="p">,</span> <span class="n">atten_ctxs</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">xs</span>

<div class="viewcode-block" id="MTDecoderV1.ComputeLoss"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.ComputeLoss">[docs]</a>  <span class="k">def</span> <span class="nf">ComputeLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">segment_id</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
      <span class="n">segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">segment_ids</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FPropSoftmax</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span>
                              <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">weights</span><span class="p">),</span>
                              <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">),</span> <span class="n">segment_id</span><span class="p">)</span></div>

  <span class="nd">@py_utils</span><span class="o">.</span><span class="n">NameScopeDecorator</span><span class="p">(</span><span class="s1">&#39;MTDecoderV1/InitDecoder&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_InitDecoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial decoder states.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">          its children layers.</span>
<span class="sd">      source_encs: source encoding, of shape [time, batch, depth].</span>
<span class="sd">      source_paddings: source encoding&#39;s padding, of shape [time, batch].</span>
<span class="sd">      num_hyps: Scalar Tensor of type int, Number of hypothesis maintained in</span>
<span class="sd">          beam search, equal to beam_size * num_hyps_per_beam.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Tuple of initial model states.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">rnn_states</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_rnn_attn</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">num_hyps</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">frnn</span><span class="p">:</span>
      <span class="n">rnn_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">num_hyps</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_zero_atten_state</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">InitForSourcePacked</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span>
                                      <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">)</span>
      <span class="n">s_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">atten_context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
          <span class="p">[</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">source_dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">source_encs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">atten_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">ZeroAttentionState</span><span class="p">(</span><span class="n">s_seq_len</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">)</span>
      <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">s_seq_len</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">source_encs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">InitForSourcePacked</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span>
                                      <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">)</span>

      <span class="n">src_seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">zero_atten_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">ZeroAttentionState</span><span class="p">(</span><span class="n">src_seq_len</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">)</span>

      <span class="p">(</span><span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span>
       <span class="n">atten_states</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">ComputeContextVector</span><span class="p">(</span>
           <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span>
           <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">rnn_cell_dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
           <span class="n">attention_state</span><span class="o">=</span><span class="n">zero_atten_state</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">atten_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">rnn_states</span><span class="p">,</span> <span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span>

  <span class="nd">@py_utils</span><span class="o">.</span><span class="n">NameScopeDecorator</span><span class="p">(</span><span class="s1">&#39;MTDecoderV1/DecodeStep&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_DecodeStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">embs</span><span class="p">,</span> <span class="n">step_paddings</span><span class="p">,</span> <span class="n">prev_atten_context</span><span class="p">,</span>
                  <span class="n">rnn_states</span><span class="p">,</span> <span class="n">prev_atten_states</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decode one step.&quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">new_rnn_states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">new_rnn_states_0</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rnn_attn</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
        <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_states</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
            <span class="n">act</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">embs</span><span class="p">,</span> <span class="n">prev_atten_context</span><span class="p">],</span> <span class="mi">1</span><span class="p">)],</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">step_paddings</span><span class="p">,</span>
            <span class="n">reset_mask</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">step_paddings</span><span class="p">)))</span>
    <span class="n">new_rnn_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_rnn_states_0</span><span class="p">)</span>
    <span class="n">rnn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_rnn_attn</span><span class="o">.</span><span class="n">GetOutput</span><span class="p">(</span><span class="n">new_rnn_states_0</span><span class="p">)</span>
    <span class="n">cur_atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">ComputeContextVector</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">frnn_with_atten</span><span class="o">.</span><span class="n">atten</span><span class="p">,</span>
            <span class="n">rnn_out</span><span class="p">,</span>
            <span class="n">attention_state</span><span class="o">=</span><span class="n">prev_atten_states</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">atten_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_prev_atten_ctx</span><span class="p">:</span>
      <span class="n">atten_context</span> <span class="o">=</span> <span class="n">prev_atten_context</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">atten_context</span> <span class="o">=</span> <span class="n">cur_atten_context</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frnn</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">frnn</span><span class="p">)):</span>
      <span class="n">new_rnn_states_i</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">layer_theta</span><span class="o">.</span><span class="n">cell</span><span class="p">,</span> <span class="n">rnn_states</span><span class="p">[</span><span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">],</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span>
              <span class="n">act</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">rnn_out</span><span class="p">,</span> <span class="n">atten_context</span><span class="p">],</span> <span class="mi">1</span><span class="p">)],</span>
              <span class="n">padding</span><span class="o">=</span><span class="n">step_paddings</span><span class="p">,</span>
              <span class="n">reset_mask</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">step_paddings</span><span class="p">)))</span>
      <span class="n">new_rnn_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_rnn_states_i</span><span class="p">)</span>
      <span class="n">new_rnn_out</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">GetOutput</span><span class="p">(</span><span class="n">new_rnn_states_i</span><span class="p">)</span>
      <span class="k">if</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">p</span><span class="o">.</span><span class="n">residual_start</span><span class="p">:</span>
        <span class="n">rnn_out</span> <span class="o">+=</span> <span class="n">new_rnn_out</span>
        <span class="n">rnn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">rnn_out</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">rnn_out</span> <span class="o">=</span> <span class="n">new_rnn_out</span>
    <span class="c1"># Concatenating atten_context vec to rnn output before softmax might help</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">feed_attention_context_vec_to_softmax</span><span class="p">:</span>
      <span class="n">step_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">rnn_out</span><span class="p">,</span> <span class="n">atten_context</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">step_out</span> <span class="o">=</span> <span class="n">rnn_out</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">cur_atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">new_rnn_states</span><span class="p">,</span> <span class="n">step_out</span><span class="p">,</span>
            <span class="n">atten_states</span><span class="p">)</span>

<div class="viewcode-block" id="MTDecoderV1._GetAttentionInitState"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._GetAttentionInitState">[docs]</a>  <span class="k">def</span> <span class="nf">_GetAttentionInitState</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Gets the attention initialization state.</span>

<span class="sd">    It is valid to call this after `_DecoderInit()`. Inference subclasses use</span>
<span class="sd">    this to split computation across subgraph boundaries.</span>

<span class="sd">    Returns:</span>
<span class="sd">      `.NestedMap` of attention source states.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">GetInitializationSourceState</span><span class="p">()</span></div>

<div class="viewcode-block" id="MTDecoderV1._SetAttentionInitState"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._SetAttentionInitState">[docs]</a>  <span class="k">def</span> <span class="nf">_SetAttentionInitState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_init_state</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the attention initialization state.</span>

<span class="sd">    Args:</span>
<span class="sd">      new_init_state: `.NestedMap` compatible with that returned from</span>
<span class="sd">        `_GetAttentionSourceState`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_atten</span><span class="o">.</span><span class="n">SetInitializationSourceState</span><span class="p">(</span><span class="n">new_init_state</span><span class="p">)</span></div>

<div class="viewcode-block" id="MTDecoderV1._InitBeamSearchStateCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._InitBeamSearchStateCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_InitBeamSearchStateCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                   <span class="n">source_encs</span><span class="p">,</span>
                                   <span class="n">source_paddings</span><span class="p">,</span>
                                   <span class="n">num_hyps_per_beam</span><span class="p">,</span>
                                   <span class="n">additional_source_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial beams search states.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_encs: A tensor of shape [src_len, src_batch, source_dim].</span>
<span class="sd">      source_paddings: A tensor of shape [src_len, src_batch].</span>
<span class="sd">      num_hyps_per_beam: An int, number hyps to keep for source sentence.</span>
<span class="sd">      additional_source_info: a `.NestedMap` of tensors containing extra context</span>
<span class="sd">          information about the source that may be useful for decoding.</span>
<span class="sd">    Returns:</span>
<span class="sd">      A tuple (initial_results, states).</span>
<span class="sd">        initial_results: a `.NestedMap` of initial results.</span>
<span class="sd">          atten_probs:</span>
<span class="sd">            The initial attention probs, of shape [tgt_batch, src_len].</span>
<span class="sd">        states: a `.NestedMap` of initial model states.</span>
<span class="sd">          rnn_states:</span>
<span class="sd">            Initial state of the RNN.</span>
<span class="sd">          atten_context:</span>
<span class="sd">            Initial attention context vector.</span>
<span class="sd">          atten_states:</span>
<span class="sd">            Initial attention state.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># additional_source_info is currently not used.</span>
    <span class="k">del</span> <span class="n">additional_source_info</span>
    <span class="n">num_beams</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">num_hyps</span> <span class="o">=</span> <span class="n">num_beams</span> <span class="o">*</span> <span class="n">num_hyps_per_beam</span>
    <span class="n">rnn_states</span><span class="p">,</span> <span class="n">init_atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">atten_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_InitDecoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">))</span>

    <span class="n">initial_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span><span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">})</span>

    <span class="k">return</span> <span class="n">initial_results</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;rnn_states&#39;</span><span class="p">:</span> <span class="n">rnn_states</span><span class="p">,</span>
        <span class="s1">&#39;atten_context&#39;</span><span class="p">:</span> <span class="n">init_atten_context</span><span class="p">,</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>
        <span class="s1">&#39;atten_states&#39;</span><span class="p">:</span> <span class="n">atten_states</span><span class="p">,</span>
    <span class="p">})</span></div>

  <span class="nd">@py_utils</span><span class="o">.</span><span class="n">NameScopeDecorator</span><span class="p">(</span><span class="s1">&#39;MTDecoderV1/PreBeamSearchStepCallback&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_PreBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                 <span class="n">source_encs</span><span class="p">,</span>
                                 <span class="n">source_paddings</span><span class="p">,</span>
                                 <span class="n">step_ids</span><span class="p">,</span>
                                 <span class="n">states</span><span class="p">,</span>
                                 <span class="n">num_hyps_per_beam</span><span class="p">,</span>
                                 <span class="n">additional_source_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns logits for sampling ids and the next model states.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_encs: A tensor of shape [src_len, src_batch, source_dim].</span>
<span class="sd">      source_paddings: A tensor of shape [src_len, src_batch].</span>
<span class="sd">      step_ids: A tensor of shape [tgt_batch, 1].</span>
<span class="sd">      states: A `.NestedMap` of tensors representing states that the clients</span>
<span class="sd">          would like to keep track of for each of the active hyps.</span>
<span class="sd">      num_hyps_per_beam: Beam size.</span>
<span class="sd">      additional_source_info: a `.NestedMap` of tensors containing extra context</span>
<span class="sd">          information about the source that may be useful for decoding.</span>
<span class="sd">    Returns:</span>
<span class="sd">      A tuple (results, out_states).</span>
<span class="sd">      results: A `.NestedMap` of beam search results.</span>
<span class="sd">        atten_probs:</span>
<span class="sd">          The updated attention probs, of shape [tgt_batch, src_len].</span>
<span class="sd">        log_probs:</span>
<span class="sd">          Log prob for each of the tokens in the target vocab. This is of shape</span>
<span class="sd">          [tgt_batch, vocab_size].</span>
<span class="sd">      out_states: A `.NestedMap`. The updated states.</span>
<span class="sd">        rnn_states:</span>
<span class="sd">          Last state of the RNN.</span>
<span class="sd">        atten_context:</span>
<span class="sd">          Updated attention context vector.</span>
<span class="sd">        atten_states:</span>
<span class="sd">          Updates attention states.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># additional_source_info is currently not used.</span>
    <span class="k">del</span> <span class="n">additional_source_info</span>

    <span class="n">prev_rnn_states</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;rnn_states&#39;</span><span class="p">]</span>
    <span class="n">prev_atten_context</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;atten_context&#39;</span><span class="p">]</span>
    <span class="n">prev_atten_probs</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;atten_probs&#39;</span><span class="p">]</span>
    <span class="n">prev_atten_states</span> <span class="o">=</span> <span class="n">states</span><span class="p">[</span><span class="s1">&#39;atten_states&#39;</span><span class="p">]</span>
    <span class="n">step_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">EmbLookupDefaultTheta</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ApplyClipping</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">embs</span><span class="p">)</span>
    <span class="n">atten_context</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">,</span> <span class="n">rnn_states</span><span class="p">,</span> <span class="n">step_out</span><span class="p">,</span> <span class="n">atten_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_DecodeStep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">embs</span><span class="p">,</span> <span class="n">step_paddings</span><span class="p">,</span> <span class="n">prev_atten_context</span><span class="p">,</span>
                         <span class="n">prev_rnn_states</span><span class="p">,</span> <span class="n">prev_atten_states</span><span class="p">))</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">atten_probs</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">prev_atten_probs</span><span class="p">))</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">Logits</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">step_out</span><span class="p">])</span>
    <span class="n">log_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fns</span><span class="o">.</span><span class="n">qlogsoftmax</span><span class="p">(</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">qmin</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">qlogsoftmax_range_min</span><span class="p">,</span> <span class="n">qmax</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">use_prev_atten_ctx</span><span class="p">:</span>
      <span class="n">cur_atten_probs</span> <span class="o">=</span> <span class="n">prev_atten_probs</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">cur_atten_probs</span> <span class="o">=</span> <span class="n">atten_probs</span>

    <span class="n">bs_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">cur_atten_probs</span><span class="p">,</span>  <span class="c1"># the probs exposed to beam search</span>
        <span class="s1">&#39;log_probs&#39;</span><span class="p">:</span> <span class="n">log_probs</span><span class="p">,</span>
    <span class="p">})</span>
    <span class="n">new_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;rnn_states&#39;</span><span class="p">:</span> <span class="n">rnn_states</span><span class="p">,</span>
        <span class="s1">&#39;atten_context&#39;</span><span class="p">:</span> <span class="n">atten_context</span><span class="p">,</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>  <span class="c1"># the updated attention probs</span>
        <span class="s1">&#39;atten_states&#39;</span><span class="p">:</span> <span class="n">atten_states</span><span class="p">,</span>
    <span class="p">})</span>

    <span class="k">return</span> <span class="n">bs_results</span><span class="p">,</span> <span class="n">new_states</span>

<div class="viewcode-block" id="MTDecoderV1._PostBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1._PostBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PostBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                  <span class="n">source_encs</span><span class="p">,</span>
                                  <span class="n">source_paddings</span><span class="p">,</span>
                                  <span class="n">new_step_ids</span><span class="p">,</span>
                                  <span class="n">states</span><span class="p">,</span>
                                  <span class="n">additional_source_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># There is nothing to do here.</span>
    <span class="k">return</span> <span class="n">states</span></div>

<div class="viewcode-block" id="MTDecoderV1.BeamSearchDecode"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.MTDecoderV1.BeamSearchDecode">[docs]</a>  <span class="k">def</span> <span class="nf">BeamSearchDecode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                       <span class="n">source_encs</span><span class="p">,</span>
                       <span class="n">source_paddings</span><span class="p">,</span>
                       <span class="n">num_hyps_per_beam_override</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                       <span class="n">additional_source_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Performs beam-search based decoding.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_encs: source encoding, of shape [time, batch, depth].</span>
<span class="sd">      source_paddings: source encoding&#39;s padding, of shape [time, batch].</span>
<span class="sd">      num_hyps_per_beam_override: If set to a value &lt;= 0, this parameter is</span>
<span class="sd">        ignored. If set to a value &gt; 0, then this value will be used to</span>
<span class="sd">        override `p.num_hyps_per_beam`.</span>
<span class="sd">      additional_source_info: a `.NestedMap` of tensors containing extra context</span>
<span class="sd">          information about the source that may be useful for decoding.</span>

<span class="sd">    Returns:</span>
<span class="sd">      BeamSearchDecodeOutput, a namedtuple containing the decode results.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">del</span> <span class="n">additional_source_info</span>  <span class="c1"># Unused.</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">BeamSearchDecode</span><span class="p">(</span>
        <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">num_hyps_per_beam_override</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_InitBeamSearchStateCallback</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PreBeamSearchStepCallback</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_PostBeamSearchStepCallback</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="TransformerDecoder"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder">[docs]</a><span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">MTBaseDecoder</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Transformer decoder.</span>

<span class="sd">  Implements the decoder of Transformer model:</span>
<span class="sd">  https://arxiv.org/abs/1706.03762.</span>
<span class="sd">  &quot;&quot;&quot;</span>

<div class="viewcode-block" id="TransformerDecoder.Params"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder.Params">[docs]</a>  <span class="nd">@classmethod</span>
  <span class="k">def</span> <span class="nf">Params</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">TransformerDecoder</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;token_emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Token embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;position_emb&#39;</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Position embedding layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;source_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;Dimension of encoder outputs.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;model_dim&#39;</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;Model dimension that applies to embedding &#39;</span>
             <span class="s1">&#39;layers and all Transformer layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;num_trans_layers&#39;</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;Number of Transformer layers.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;trans_tpl&#39;</span><span class="p">,</span> <span class="n">layers_with_attention</span><span class="o">.</span><span class="n">TransformerLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">(),</span>
             <span class="s1">&#39;Transformer layer params.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;target_seq_len&#39;</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="s1">&#39;Target seq length.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;input_dropout_prob&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;Prob at which we do input dropout.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
        <span class="s1">&#39;is_transparent&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;If set, expects a tensor of shape &#39;</span>
        <span class="s1">&#39;[time, batch, source_dim, num_trans_layers] as source encodings.&#39;</span><span class="p">)</span>

    <span class="c1"># Default config for the token embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">32000</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span>
        <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">))</span>
    <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">scale_sqrt_depth</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Default config for the position embedding.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>

    <span class="c1"># Default config for the transformer layers.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">is_decoder</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_atten_tpl</span><span class="o">.</span><span class="n">num_attention_heads</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_fflayer_tpl</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">tr_fflayer_tpl</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">2048</span>

    <span class="c1"># Default config for beam search.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">length_normalization</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">coverage_penalty</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">return</span> <span class="n">p</span></div>

  <span class="nd">@base_layer</span><span class="o">.</span><span class="n">initializer</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TransformerDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span>
    <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">embedding_dim</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;token_emb.embedding_dim != model_dim (</span><span class="si">%s</span><span class="s1"> vs. </span><span class="si">%s</span><span class="s1">), &#39;</span>
                         <span class="s1">&#39;creating a projection!&#39;</span><span class="p">)</span>
      <span class="n">proj_p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">proj_p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb_proj&#39;</span>
      <span class="n">proj_p</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span>
      <span class="n">proj_p</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;emb_proj&#39;</span><span class="p">,</span> <span class="n">proj_p</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_token_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;token_emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;position_emb&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">position_emb</span><span class="p">)</span>

      <span class="n">dropout_tpl</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DropoutLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">dropout_tpl</span><span class="o">.</span><span class="n">keep_prob</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dropout_prob</span><span class="p">)</span>
      <span class="n">dropout_tpl</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">random_seed</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;input_dropout&#39;</span><span class="p">,</span> <span class="n">dropout_tpl</span><span class="p">)</span>

      <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">random_seed</span>
      <span class="n">params_trans_layers</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">trans_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;trans_layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span>
        <span class="n">params</span><span class="o">.</span><span class="n">packed_input</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span>
        <span class="n">params_trans_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChildren</span><span class="p">(</span><span class="s1">&#39;trans&#39;</span><span class="p">,</span> <span class="n">params_trans_layers</span><span class="p">)</span>

      <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>

      <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">target_seq_len</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">target_seq_len</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">CreateChild</span><span class="p">(</span><span class="s1">&#39;beam_search&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">beam_search</span><span class="p">)</span>

<div class="viewcode-block" id="TransformerDecoder._FProp"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._FProp">[docs]</a>  <span class="k">def</span> <span class="nf">_FProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span>
             <span class="n">src_segment_id</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decodes `targets` given encoded source.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      source_encs: source encoding. When `p.is_transparent` is False, it is a</span>
<span class="sd">        tensor of shape [time, batch, depth]. When `p.is_transparent` is True,</span>
<span class="sd">        it is a tensor of shape [time, batch, depth, num_trans_layers] if</span>
<span class="sd">        `p.is_eval` is True, and a list of `num_trans_layers` tensors of shape</span>
<span class="sd">        [time, batch, depth] if `p.is_eval` is False.</span>
<span class="sd">      source_paddings: source encoding&#39;s padding, of shape [time, batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [batch, time].</span>
<span class="sd">      src_segment_id: source segment id, of shape [time, batch].</span>

<span class="sd">    Returns:</span>
<span class="sd">      Output of last decoder layer, [target_time, target_batch, source_dim].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">time</span><span class="p">,</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">is_transparent</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">is_eval</span><span class="p">:</span>
        <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span>
            <span class="n">source_encs</span><span class="p">,</span> <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">])</span>
        <span class="n">source_encs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">):</span>
          <span class="n">source_encs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                             <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">])</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_encs</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="c1"># [batch, time]</span>
      <span class="n">target_ids</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">ids</span>
      <span class="c1"># [time, batch]</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">paddings</span><span class="p">)</span>
      <span class="n">target_segment_pos</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">target_segment_id</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">target_segment_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">segment_ids</span><span class="p">)</span>
        <span class="n">target_segment_pos</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">segment_pos</span>
        <span class="k">assert</span> <span class="n">src_segment_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;Need to provide src_segment_id &#39;</span>
                                            <span class="s1">&#39;for packed input.&#39;</span><span class="p">)</span>

      <span class="c1"># Embedding layer</span>
      <span class="c1"># [batch, time, model_dim]</span>
      <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">token_emb</span><span class="p">,</span> <span class="n">target_ids</span><span class="p">)</span>
      <span class="n">target_time</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
      <span class="c1"># [1, time, model_dim]</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">packed_input</span><span class="p">:</span>
        <span class="n">posit_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FPropWithPosition</span><span class="p">(</span>
            <span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span> <span class="n">target_segment_pos</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">posit_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span> <span class="n">target_time</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

      <span class="c1"># [time, batch, model_dim]</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">token_embs</span> <span class="o">+</span> <span class="n">posit_embs</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">:</span>
        <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_proj</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb_proj</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>

      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">input_embs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dropout</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">input_dropout</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>

      <span class="n">atten_probs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">layer_in</span> <span class="o">=</span> <span class="n">input_embs</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trans</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">trans</span><span class="p">)):</span>
        <span class="c1"># [time, batch, model_dim]</span>
        <span class="n">layer_out</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
            <span class="n">layer_theta</span><span class="p">,</span>
            <span class="n">layer_in</span><span class="p">,</span>
            <span class="n">target_paddings</span><span class="p">,</span>
            <span class="n">source_encs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">source_paddings</span><span class="p">,</span>
            <span class="n">source_segment_id</span><span class="o">=</span><span class="n">target_segment_id</span><span class="p">,</span>
            <span class="n">aux_segment_id</span><span class="o">=</span><span class="n">src_segment_id</span><span class="p">)</span>
        <span class="n">layer_in</span> <span class="o">=</span> <span class="n">layer_out</span>
        <span class="n">atten_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">add_summary</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_AddAttenProbsSummary</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">atten_probs</span><span class="p">)</span>

      <span class="k">return</span> <span class="n">layer_out</span></div>

<div class="viewcode-block" id="TransformerDecoder.ExtendStep"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder.ExtendStep">[docs]</a>  <span class="k">def</span> <span class="nf">ExtendStep</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">new_ids</span><span class="p">,</span>
                 <span class="n">t</span><span class="p">,</span> <span class="n">prefix_states</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Extend prefix as represeted by `prefix_states` by one more step.</span>

<span class="sd">    This function is expected to be called during fast decoding of Transformer</span>
<span class="sd">    models.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      source_encs: source encoding, of shape [time, batch, depth]. Can be [time,</span>
<span class="sd">        bs, depth, num_trans_layers] if is_transparent is set.</span>
<span class="sd">      source_paddings: source encoding&#39;s padding, of shape [time, batch].</span>
<span class="sd">      new_ids: new input ids, of shape [batch].</span>
<span class="sd">      t: a scalar, the current time step, 0-based.</span>
<span class="sd">      prefix_states: a `.NestedMap` representing the prefix that has already</span>
<span class="sd">        been decoded.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A pair (last_decoder_out, prefix_states), where last_decoder_out is the</span>
<span class="sd">      output of the last decoder layer of shape [batch, model_dim], and</span>
<span class="sd">      `prefix_states` is the update prefix states.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="n">time</span><span class="p">,</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_paddings</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">is_transparent</span><span class="p">:</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span>
          <span class="n">source_encs</span><span class="p">,</span> <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">])</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">HasShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">,</span> <span class="p">[</span><span class="n">time</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span><span class="p">])</span>
      <span class="n">source_encs</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_encs</span><span class="p">]</span> <span class="o">*</span> <span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
      <span class="c1"># Embedding layer</span>
      <span class="c1"># [batch, time, model_dim]</span>
      <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">token_emb</span><span class="p">,</span> <span class="n">new_ids</span><span class="p">)</span>
      <span class="c1"># [time, model_dim]</span>
      <span class="n">posit_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">position_emb</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">position_emb</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>
      <span class="n">input_embs</span> <span class="o">=</span> <span class="n">token_embs</span> <span class="o">+</span> <span class="n">posit_embs</span>

      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">token_emb</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">:</span>
        <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_proj</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">emb_proj</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>

      <span class="n">input_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dropout</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">theta</span><span class="o">.</span><span class="n">input_dropout</span><span class="p">,</span> <span class="n">input_embs</span><span class="p">)</span>
      <span class="c1"># Make a copy of the input.</span>
      <span class="n">out_prefix_states</span> <span class="o">=</span> <span class="n">prefix_states</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">prefix_states</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

      <span class="n">layer_in</span> <span class="o">=</span> <span class="n">input_embs</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer_theta</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trans</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">trans</span><span class="p">)):</span>
        <span class="c1"># [time, batch, model_dim]</span>
        <span class="n">layer_prefix_states</span> <span class="o">=</span> <span class="n">prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">layer_out</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">updated_prefix_states</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">ExtendStep</span><span class="p">(</span>
            <span class="n">layer_theta</span><span class="p">,</span> <span class="n">layer_in</span><span class="p">,</span> <span class="n">layer_prefix_states</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">source_paddings</span><span class="p">)</span>
        <span class="n">out_prefix_states</span><span class="p">[</span><span class="s1">&#39;layer_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">updated_prefix_states</span>
        <span class="n">layer_in</span> <span class="o">=</span> <span class="n">layer_out</span>

      <span class="k">return</span> <span class="n">layer_out</span><span class="p">,</span> <span class="n">out_prefix_states</span></div>

<div class="viewcode-block" id="TransformerDecoder.ComputePredictions"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder.ComputePredictions">[docs]</a>  <span class="k">def</span> <span class="nf">ComputePredictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span>
                         <span class="n">src_segment_id</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Decodes `targets` given encoded source.</span>

<span class="sd">    Args:</span>
<span class="sd">      theta: A `.NestedMap` object containing weights&#39; values of this layer and</span>
<span class="sd">        its children layers.</span>
<span class="sd">      source_encs: source encoding, of shape [time, batch, depth]. Can be [time,</span>
<span class="sd">        batch, depth, num_layers] if is_transparent is set.</span>
<span class="sd">      source_paddings: source encoding&#39;s padding, of shape [time, batch].</span>
<span class="sd">      targets: A dict of string to tensors representing the targets one try to</span>
<span class="sd">        predict. Each tensor in targets is of shape [batch, time].</span>
<span class="sd">      src_segment_id: source segment id, of shape [time, batch].</span>

<span class="sd">    Returns:</span>
<span class="sd">      A Tensor with shape [time, batch, params.softmax.input_dim].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_FProp</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span>
                       <span class="n">src_segment_id</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformerDecoder._InitBeamSearchStateCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._InitBeamSearchStateCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_InitBeamSearchStateCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                   <span class="n">source_encs</span><span class="p">,</span>
                                   <span class="n">source_paddings</span><span class="p">,</span>
                                   <span class="n">num_hyps_per_beam</span><span class="p">,</span>
                                   <span class="n">additional_source_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns initial beams search states.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_encs: A tensor of shape [src_len, src_batch, source_dim].</span>
<span class="sd">          Can be [time, batch, depth, num_layers] if is_transparent is set.</span>
<span class="sd">      source_paddings: A tensor of shape [src_len, src_batch].</span>
<span class="sd">      num_hyps_per_beam: An int, number hyps to keep for source sentence.</span>
<span class="sd">      additional_source_info: a `.NestedMap` of tensors containing extra context</span>
<span class="sd">          information about the source that may be useful for decoding.</span>
<span class="sd">    Returns:</span>
<span class="sd">      A tuple (initial_results, states).</span>
<span class="sd">        initial_results: a `.NestedMap` of initial results.</span>
<span class="sd">          atten_probs:</span>
<span class="sd">            The initial attention probs, of shape [tgt_batch, src_len].</span>
<span class="sd">        states: a `.NestedMap` of initial model states.</span>
<span class="sd">          source_encs:</span>
<span class="sd">            A tensor of shape [src_batch, src_len, source_dim].</span>
<span class="sd">          source_paddings:</span>
<span class="sd">            A tensor of shape [src_batch, src_len].</span>
<span class="sd">          target_ids:</span>
<span class="sd">            Initial empty list of decoded ids. [num_hyps, 0].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># additional_source_info is currently not used.</span>
    <span class="k">del</span> <span class="n">additional_source_info</span>

    <span class="n">num_hyps</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_hyps_per_beam</span>
    <span class="n">source_len</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Dummy attention probs</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">source_len</span><span class="p">])</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">source_len</span><span class="p">)</span>
    <span class="n">initial_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span><span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">})</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">num_hyps</span>
    <span class="n">key_channels</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>
    <span class="n">value_channels</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">model_dim</span>

    <span class="n">prefix_states</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;layer_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">layer</span><span class="p">:</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
            <span class="s1">&#39;key&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">key_channels</span><span class="p">]),</span>
            <span class="s1">&#39;value&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">value_channels</span><span class="p">]),</span>
        <span class="p">})</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">num_trans_layers</span><span class="p">)</span>
    <span class="p">})</span>

    <span class="k">return</span> <span class="n">initial_results</span><span class="p">,</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;prefix_states&#39;</span><span class="p">:</span> <span class="n">prefix_states</span><span class="p">,</span>
        <span class="s1">&#39;time_step&#39;</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="p">})</span></div>

<div class="viewcode-block" id="TransformerDecoder._PreBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._PreBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PreBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                 <span class="n">source_encs</span><span class="p">,</span>
                                 <span class="n">source_paddings</span><span class="p">,</span>
                                 <span class="n">step_ids</span><span class="p">,</span>
                                 <span class="n">states</span><span class="p">,</span>
                                 <span class="n">num_hyps_per_beam</span><span class="p">,</span>
                                 <span class="n">additional_source_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns logits for sampling ids and the next model states.</span>

<span class="sd">    Args:</span>
<span class="sd">      source_encs: A tensor of shape [src_len, src_batch, source_dim].</span>
<span class="sd">          Can be [time, batch, depth, num_layers] if is_transparent is set.</span>
<span class="sd">      source_paddings: A tensor of shape [src_len, src_batch].</span>
<span class="sd">      step_ids: A tensor of shape [tgt_batch, 1].</span>
<span class="sd">      states: A `.NestedMap` of tensors representing states that the clients</span>
<span class="sd">          would like to keep track of for each of the active hyps.</span>
<span class="sd">      num_hyps_per_beam: Beam size.</span>
<span class="sd">      additional_source_info: a `.NestedMap` of tensors containing extra context</span>
<span class="sd">          information about the source that may be useful for decoding.</span>
<span class="sd">    Returns:</span>
<span class="sd">      A tuple (results, out_states).</span>
<span class="sd">        results: A `.NestedMap` of beam search results.</span>
<span class="sd">          atten_probs:</span>
<span class="sd">            The updated attention probs, of shape [tgt_batch, src_len].</span>
<span class="sd">          log_probs:</span>
<span class="sd">            Log prob for each of the tokens in the target vocab. This is of</span>
<span class="sd">            shape [tgt_batch, vocab_size].</span>
<span class="sd">        out_states: A `.NestedMap`. The updated states.</span>
<span class="sd">           source_encs:</span>
<span class="sd">             A tensor of shape [src_batch, src_len, source_dim].</span>
<span class="sd">           source_paddings:</span>
<span class="sd">             A tensor of shape [src_batch, src_len].</span>
<span class="sd">           target_ids:</span>
<span class="sd">             Updated list of decoded ids. [num_hyps, Num of decoded ids].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
    <span class="c1"># additional_source_info is currently not used.</span>
    <span class="k">del</span> <span class="n">additional_source_info</span>

    <span class="n">target_time</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">time_step</span>
    <span class="n">prefix_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">prefix_states</span>

    <span class="n">new_states</span> <span class="o">=</span> <span class="n">states</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

    <span class="n">layer_out</span><span class="p">,</span> <span class="n">updated_prefix_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ExtendStep</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">step_ids</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">target_time</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">prefix_states</span><span class="p">)</span>

    <span class="n">new_states</span><span class="o">.</span><span class="n">prefix_states</span> <span class="o">=</span> <span class="n">updated_prefix_states</span>
    <span class="n">new_states</span><span class="o">.</span><span class="n">time_step</span> <span class="o">=</span> <span class="n">target_time</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="n">softmax_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">layer_out</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">input_dim</span><span class="p">])</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">Logits</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">softmax</span><span class="p">,</span> <span class="p">[</span><span class="n">softmax_input</span><span class="p">])</span>

    <span class="n">num_hyps</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">step_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">source_len</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetShape</span><span class="p">(</span><span class="n">source_encs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># [time * batch, num_classes] -&gt; [time, batch, num_classes]</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_hyps</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">num_classes</span><span class="p">))</span>
    <span class="c1"># [time, batch, num_classes] -&gt; [batch, time, num_classes]</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="c1"># Dummy attention probs</span>
    <span class="n">atten_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">num_hyps</span><span class="p">,</span> <span class="n">source_len</span><span class="p">])</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_float</span><span class="p">(</span><span class="n">source_len</span><span class="p">)</span>

    <span class="c1"># Only return logits for the last ids</span>
    <span class="n">log_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">bs_results</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">({</span>
        <span class="s1">&#39;atten_probs&#39;</span><span class="p">:</span> <span class="n">atten_probs</span><span class="p">,</span>
        <span class="s1">&#39;log_probs&#39;</span><span class="p">:</span> <span class="n">log_probs</span><span class="p">,</span>
    <span class="p">})</span>

    <span class="k">return</span> <span class="n">bs_results</span><span class="p">,</span> <span class="n">new_states</span></div>

<div class="viewcode-block" id="TransformerDecoder._PostBeamSearchStepCallback"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder._PostBeamSearchStepCallback">[docs]</a>  <span class="k">def</span> <span class="nf">_PostBeamSearchStepCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                  <span class="n">source_encs</span><span class="p">,</span>
                                  <span class="n">source_paddings</span><span class="p">,</span>
                                  <span class="n">new_step_ids</span><span class="p">,</span>
                                  <span class="n">states</span><span class="p">,</span>
                                  <span class="n">additional_source_info</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># There is nothing to do here.</span>
    <span class="k">return</span> <span class="n">states</span></div>

<div class="viewcode-block" id="TransformerDecoder.BeamSearchDecode"><a class="viewcode-back" href="../../../../lingvo.tasks.mt.decoder.html#lingvo.tasks.mt.decoder.TransformerDecoder.BeamSearchDecode">[docs]</a>  <span class="k">def</span> <span class="nf">BeamSearchDecode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                       <span class="n">source_encs</span><span class="p">,</span>
                       <span class="n">source_paddings</span><span class="p">,</span>
                       <span class="n">num_hyps_per_beam_override</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_search</span><span class="o">.</span><span class="n">BeamSearchDecode</span><span class="p">(</span>
        <span class="n">source_encs</span><span class="p">,</span> <span class="n">source_paddings</span><span class="p">,</span> <span class="n">num_hyps_per_beam_override</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_InitBeamSearchStateCallback</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_PreBeamSearchStepCallback</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_PostBeamSearchStepCallback</span><span class="p">)</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../../',
            VERSION:'',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>