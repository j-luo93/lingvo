

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lingvo.core.rnn_layers_test &mdash; lingvo  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.core.rnn_layers_test</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.core.rnn_layers_test</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;Tests for rnn_layers.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">unittest</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">range</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">zip</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">inplace_ops</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">attention</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">base_layer</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">cluster_factory</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">layers_with_attention</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">rnn_cell</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">rnn_layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">test_utils</span>

<span class="n">FLAGS</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">FLAGS</span>

<span class="c1"># pylint: disable=invalid-name</span>
<span class="n">ComputeNumericGradient</span> <span class="o">=</span> <span class="n">test_utils</span><span class="o">.</span><span class="n">ComputeNumericGradient</span>
<span class="c1"># pylint: enable=invalid-name</span>
<span class="n">assert_shape_match</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">assert_shape_match</span>


<div class="viewcode-block" id="TimestepAccumulator"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.TimestepAccumulator">[docs]</a><span class="k">class</span> <span class="nc">TimestepAccumulator</span><span class="p">(</span><span class="n">base_layer</span><span class="o">.</span><span class="n">Accumulator</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simple accumulator for counting timesteps.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="TimestepAccumulator.DefaultValue"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.TimestepAccumulator.DefaultValue">[docs]</a>  <span class="k">def</span> <span class="nf">DefaultValue</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span></div>

<div class="viewcode-block" id="TimestepAccumulator.Increment"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.TimestepAccumulator.Increment">[docs]</a>  <span class="k">def</span> <span class="nf">Increment</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">SetValue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">GetValue</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="AddTimestepAccumulator"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.AddTimestepAccumulator">[docs]</a><span class="k">def</span> <span class="nf">AddTimestepAccumulator</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
  <span class="n">orig_fprop</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">FProp</span>

  <span class="k">def</span> <span class="nf">WrappedFProp</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">accumulators</span><span class="o">.</span><span class="n">ts_count</span><span class="o">.</span><span class="n">Increment</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">orig_fprop</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

  <span class="n">layer</span><span class="o">.</span><span class="n">FProp</span> <span class="o">=</span> <span class="n">WrappedFProp</span>

  <span class="n">layer</span><span class="o">.</span><span class="n">RegisterAccumulator</span><span class="p">(</span><span class="s1">&#39;ts_count&#39;</span><span class="p">,</span> <span class="n">TimestepAccumulator</span><span class="p">())</span></div>


<div class="viewcode-block" id="LayersTestBase"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTestBase">[docs]</a><span class="k">class</span> <span class="nc">LayersTestBase</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">_testStackedFRNNHelper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                             <span class="bp">cls</span><span class="p">,</span>
                             <span class="n">dtype</span><span class="p">,</span>
                             <span class="n">trailing_pad_len</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                             <span class="n">keep_prob</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">123456</span><span class="p">)</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">slen</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">+</span> <span class="n">trailing_pad_len</span>
    <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span>
        <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
        <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
        <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">dims</span>
        <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">dims</span>

        <span class="n">sfrnn_params</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
        <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;sfrnn&#39;</span>
        <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">cell_tpl</span> <span class="o">=</span> <span class="n">params</span>
        <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
        <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">skip_start</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">dropout</span><span class="o">.</span><span class="n">keep_prob</span> <span class="o">=</span> <span class="n">keep_prob</span>
        <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">dropout</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">123456</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;sfrnn&#39;</span><span class="p">):</span>
          <span class="n">sfrnn</span> <span class="o">=</span> <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sfrnn_params</span><span class="p">)</span>

        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dims</span><span class="p">)),</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="n">paddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">trailing_pad_len</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
          <span class="n">paddings</span><span class="p">[</span><span class="o">-</span><span class="n">trailing_pad_len</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>
          <span class="n">paddings</span><span class="p">[</span><span class="o">-</span><span class="n">trailing_pad_len</span> <span class="o">-</span> <span class="mi">3</span><span class="p">:</span><span class="o">-</span><span class="n">trailing_pad_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

        <span class="n">sfrnn_outputs</span><span class="p">,</span> <span class="n">sfrnn_final</span> <span class="o">=</span> <span class="n">sfrnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">sfrnn_outputs</span><span class="p">,</span> <span class="n">sfrnn_final</span><span class="p">])</span>

  <span class="k">def</span> <span class="nf">_testStackedFRNNGradHelper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">cls</span><span class="p">):</span>
    <span class="n">trailing_pad_len</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">slen</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">+</span> <span class="n">trailing_pad_len</span>
    <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">dims</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">dims</span>

      <span class="n">sfrnn_params</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;sfrnn&#39;</span>
      <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">cell_tpl</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
      <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">skip_start</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;sfrnn&#39;</span><span class="p">):</span>
        <span class="n">sfrnn</span> <span class="o">=</span> <span class="n">sfrnn_params</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sfrnn_params</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dims</span><span class="p">)),</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">paddings</span><span class="p">[</span><span class="o">-</span><span class="n">trailing_pad_len</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>
      <span class="n">paddings</span><span class="p">[</span><span class="o">-</span><span class="n">trailing_pad_len</span> <span class="o">-</span> <span class="mi">3</span><span class="p">:</span><span class="o">-</span><span class="n">trailing_pad_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>

      <span class="n">sfrnn_outputs</span><span class="p">,</span> <span class="n">sfrnn_final</span> <span class="o">=</span> <span class="n">sfrnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>

      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">sfrnn_outputs</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">fin</span> <span class="ow">in</span> <span class="n">sfrnn_final</span><span class="o">.</span><span class="n">rnn</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">fin</span><span class="o">.</span><span class="n">m</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">fin</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
      <span class="n">xs</span> <span class="o">=</span> <span class="n">sfrnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
      <span class="n">dxs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>

      <span class="c1"># Compares the sym grad against the numeric grads.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">grad_step</span> <span class="o">=</span> <span class="mi">17</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">dxs</span><span class="p">)</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_utils</span><span class="o">.</span><span class="n">PickEveryN</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">grad_step</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">sym_grads</span><span class="p">]</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">test_utils</span><span class="o">.</span><span class="n">PickEveryN</span><span class="p">(</span>
              <span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">grad_step</span><span class="p">),</span>
              <span class="n">grad_step</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">xs</span>
      <span class="p">]</span>
      <span class="k">for</span> <span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">num</span><span class="p">)))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;max = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span></div>


<div class="viewcode-block" id="LayersTest"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest">[docs]</a><span class="k">class</span> <span class="nc">LayersTest</span><span class="p">(</span><span class="n">LayersTestBase</span><span class="p">):</span>

<div class="viewcode-block" id="LayersTest.testRNN"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testRNN">[docs]</a>  <span class="k">def</span> <span class="nf">testRNN</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="mi">2</span>

      <span class="n">rnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn&#39;</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">10</span>
      <span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">rnn_params</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">paddings_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">):</span>
        <span class="n">inputs_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">paddings_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>
      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>

      <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs_sequence</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">paddings_sequence</span><span class="p">)</span>
      <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">*=</span> <span class="n">paddings</span>
      <span class="n">sum_outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="n">actual</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="nb">sum</span><span class="o">=</span><span class="n">sum_outputs</span><span class="p">,</span> <span class="o">**</span><span class="n">final</span><span class="p">))</span>

      <span class="c1"># In case this test ever breaks, you can uncomment the line below, copy</span>
      <span class="c1"># out the golden values, and then comment out the line below again.</span>
      <span class="c1">#</span>
      <span class="n">sum_expected</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.46614376</span><span class="p">,</span> <span class="mf">0.86599183</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.63463444</span><span class="p">,</span> <span class="mf">0.57043159</span><span class="p">],</span>
                      <span class="p">[</span><span class="o">-</span><span class="mf">0.64659989</span><span class="p">,</span> <span class="mf">0.72516292</span><span class="p">]]</span>
      <span class="n">c_expected</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.63455635</span><span class="p">,</span> <span class="mf">0.76446551</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.59985822</span><span class="p">,</span> <span class="mf">0.6631192</span><span class="p">],</span>
                    <span class="p">[</span><span class="o">-</span><span class="mf">0.63043576</span><span class="p">,</span> <span class="mf">0.77522433</span><span class="p">]]</span>
      <span class="n">m_expected</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.23307188</span><span class="p">,</span> <span class="mf">0.43299592</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.31731722</span><span class="p">,</span> <span class="mf">0.2852158</span><span class="p">],</span>
                    <span class="p">[</span><span class="o">-</span><span class="mf">0.32329994</span><span class="p">,</span> <span class="mf">0.36258146</span><span class="p">]]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sum_expected</span><span class="p">,</span> <span class="n">actual</span><span class="o">.</span><span class="n">sum</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">m_expected</span><span class="p">,</span> <span class="n">actual</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">c_expected</span><span class="p">,</span> <span class="n">actual</span><span class="o">.</span><span class="n">c</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testReversePaddedSequence"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testReversePaddedSequence">[docs]</a>  <span class="k">def</span> <span class="nf">testReversePaddedSequence</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
      <span class="c1"># inputs is [seq_length, batch_size, input_dim] = [4, 3, 2]</span>
      <span class="c1"># The length of each batch is [2, 3, 4]</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">],</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">]],</span>
           <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">23</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">26</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">35</span><span class="p">,</span> <span class="mi">36</span><span class="p">]]],</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="p">[[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]]],</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">actual_output</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">_ReversePaddedSequence</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
      <span class="n">expected_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
          <span class="p">[[[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="p">[</span><span class="mi">23</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> <span class="p">[</span><span class="mi">35</span><span class="p">,</span> <span class="mi">36</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">],</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">26</span><span class="p">]],</span>
           <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">16</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span>
                                                         <span class="mi">6</span><span class="p">]]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">actual_output</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_CreateCuDNNLSTMParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                             <span class="n">input_nodes</span><span class="p">,</span>
                             <span class="n">cell_nodes</span><span class="p">,</span>
                             <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                             <span class="n">is_eval</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">CuDNNLSTM</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;cudnn_lstm&#39;</span>
    <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
    <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="n">is_eval</span>
    <span class="n">params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">params</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm_cell&#39;</span>
    <span class="n">params</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">input_nodes</span>
    <span class="n">params</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">cell_nodes</span>
    <span class="n">params</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">cell_value_cap</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">params</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">forget_gate_bias</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">params</span>

<div class="viewcode-block" id="LayersTest.testCuDNNLSTM"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testCuDNNLSTM">[docs]</a>  <span class="nd">@unittest</span><span class="o">.</span><span class="n">skipUnless</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_built_with_cuda</span><span class="p">(),</span> <span class="s1">&#39;Only available on GPU.&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">testCuDNNLSTM</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">seq_length</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">input_nodes</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">cell_nodes</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
    <span class="n">inputs_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">input_nodes</span><span class="p">))</span>
    <span class="n">paddings_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">model_var_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
        <span class="n">size</span><span class="o">=</span><span class="p">((</span><span class="n">input_nodes</span> <span class="o">+</span> <span class="n">cell_nodes</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">cell_nodes</span> <span class="o">+</span> <span class="mi">8</span> <span class="o">*</span> <span class="n">cell_nodes</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_CreateLayer</span><span class="p">(</span><span class="n">is_eval</span><span class="p">):</span>
      <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_CreateCuDNNLSTMParams</span><span class="p">(</span>
          <span class="n">input_nodes</span><span class="p">,</span> <span class="n">cell_nodes</span><span class="p">,</span> <span class="n">is_eval</span><span class="o">=</span><span class="n">is_eval</span><span class="p">)</span>
      <span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">CuDNNLSTM</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">inputs_v</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">paddings_v</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="c1"># Set outputs of padding inputs to 0. for comparison.</span>
      <span class="n">outputs</span> <span class="o">*=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">paddings</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">is_eval</span><span class="p">:</span>
        <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;CuDNNLSTM_vars&#39;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">model_var_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">all_vars</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">model_var_v</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_var_init</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span>

    <span class="c1"># Train graph</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">87654321</span>
        <span class="n">init_op</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">_CreateLayer</span><span class="p">(</span><span class="n">is_eval</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># pylint:disable=unbalanced-tuple-unpacking</span>
        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

        <span class="c1"># Initialize all the variables, and then run one step.</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
        <span class="n">init_op</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

        <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_temp_dir</span><span class="p">(),</span> <span class="s1">&#39;cudnn-lstm-test&#39;</span><span class="p">)</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>

        <span class="p">(</span><span class="n">cudnn_outputs_v</span><span class="p">,</span> <span class="n">cudnn_m_v</span><span class="p">,</span>
         <span class="n">cudnn_c_v</span><span class="p">)</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">outputs</span><span class="p">,</span> <span class="n">final</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">final</span><span class="o">.</span><span class="n">c</span><span class="p">])</span>

    <span class="c1"># Eval graph</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">87654321</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">_CreateLayer</span><span class="p">(</span><span class="n">is_eval</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># pylint:disable=unbalanced-tuple-unpacking</span>
        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

        <span class="c1"># Initialize all the variables, and then run one step.</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>

        <span class="p">(</span><span class="n">rnn_outputs_v</span><span class="p">,</span> <span class="n">rnn_m_v</span><span class="p">,</span>
         <span class="n">rnn_c_v</span><span class="p">)</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">outputs</span><span class="p">,</span> <span class="n">final</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">final</span><span class="o">.</span><span class="n">c</span><span class="p">])</span>

    <span class="c1"># CuDNNLSTM train and eval mode are equivalent and its checkpoints can</span>
    <span class="c1"># be consumed by FRNN in eval mode.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">rnn_outputs_v</span><span class="p">,</span> <span class="n">cudnn_outputs_v</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">rnn_m_v</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">cudnn_m_v</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">rnn_c_v</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">cudnn_c_v</span><span class="p">))</span></div>

<div class="viewcode-block" id="LayersTest.testCuDNNLSTMGradientChecker"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testCuDNNLSTMGradientChecker">[docs]</a>  <span class="nd">@unittest</span><span class="o">.</span><span class="n">skipUnless</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_built_with_cuda</span><span class="p">(),</span> <span class="s1">&#39;Only available on GPU.&#39;</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">testCuDNNLSTMGradientChecker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">seq_length</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">input_nodes</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">cell_nodes</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span>

    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
    <span class="n">inputs_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">input_nodes</span><span class="p">))</span>
    <span class="n">paddings_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">paddings_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mf">0.</span><span class="p">]),</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">paddings_v</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">g</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">87654321</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_CreateCuDNNLSTMParams</span><span class="p">(</span>
            <span class="n">input_nodes</span><span class="p">,</span> <span class="n">cell_nodes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">is_eval</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">CuDNNLSTM</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">inputs_v</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">paddings_v</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">params</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;/gpu:0&#39;</span><span class="p">):</span>
          <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
        <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;CuDNNLSTM_vars&#39;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">outputs</span> <span class="o">*</span> <span class="n">paddings</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span>
            <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">final</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()])</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>

        <span class="c1"># Initialize all the variables, and then run one step.</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

        <span class="n">symbolic_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">gd</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="k">for</span> <span class="n">gd</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
        <span class="n">numerical_grads</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">:</span>
          <span class="n">numerical_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">symbolic_grads</span><span class="p">,</span> <span class="n">numerical_grads</span><span class="p">):</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testRNNGradientChecker"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testRNNGradientChecker">[docs]</a>  <span class="k">def</span> <span class="nf">testRNNGradientChecker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="mi">2</span>

      <span class="n">rnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn&#39;</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">10</span>
      <span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">rnn_params</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">paddings_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">):</span>
        <span class="n">inputs_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>
        <span class="n">paddings_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">))</span>

      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="p">[[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="p">[[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

      <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs_sequence</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">paddings_sequence</span><span class="p">)</span>
      <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">*=</span> <span class="n">paddings</span>
      <span class="n">sum_outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">sum_outputs</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">final</span><span class="o">.</span><span class="n">m</span> <span class="o">+</span> <span class="n">final</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
      <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;LSTMCellSimple_vars&#39;</span><span class="p">)</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>

      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="n">symbolic_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">gd</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="k">for</span> <span class="n">gd</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
      <span class="n">numerical_grads</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">:</span>
        <span class="n">numerical_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">symbolic_grads</span><span class="p">,</span> <span class="n">numerical_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testRNNReversed"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testRNNReversed">[docs]</a>  <span class="k">def</span> <span class="nf">testRNNReversed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Test an RNN layer with reverse=true.</span>

<span class="sd">    This should yield the same output as feeding reversed input into</span>
<span class="sd">    the same RNN with reverse=false (except the output is in reversed order).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">timesteps</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">padding_steps</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">depth</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">lstm_params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">lstm_params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">lstm_params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">depth</span>
      <span class="n">lstm_params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">depth</span>

      <span class="n">rnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">lstm_params</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="n">timesteps</span>

      <span class="n">fwd_rnn_params</span> <span class="o">=</span> <span class="n">rnn_params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">fwd_rnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;fwd&#39;</span>
      <span class="n">fwd_rnn_params</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;fwd_lstm&#39;</span>
      <span class="n">fwd_rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">fwd_rnn_params</span><span class="p">)</span>

      <span class="n">bak_rnn_params</span> <span class="o">=</span> <span class="n">rnn_params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">bak_rnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;bak&#39;</span>
      <span class="n">bak_rnn_params</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;bak_lstm&#39;</span>
      <span class="n">bak_rnn_params</span><span class="o">.</span><span class="n">reverse</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">bak_rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">bak_rnn_params</span><span class="p">)</span>

      <span class="c1"># Create 8 timesteps of random input, 2 timesteps of zeros, and paddings</span>
      <span class="c1"># to match.</span>
      <span class="n">fwd_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
              <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
                  <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">timesteps</span> <span class="o">-</span> <span class="n">padding_steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">depth</span><span class="p">)),</span>
               <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">padding_steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">depth</span><span class="p">))),</span>
              <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">fwd_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
          <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">timesteps</span> <span class="o">-</span> <span class="n">padding_steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">depth</span><span class="p">)),</span>
           <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">padding_steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">depth</span><span class="p">))),</span>
          <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">bak_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">fwd_inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>
      <span class="n">bak_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">fwd_paddings</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>

      <span class="c1"># Run the forward rnn with reversed inputs</span>
      <span class="n">reversed_outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">fwd_rnn</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">fwd_rnn</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">bak_inputs</span><span class="p">,</span>
                                          <span class="n">bak_paddings</span><span class="p">)</span>
      <span class="n">reversed_outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">reversed_outputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>

      <span class="c1"># Run the backward rnn with forward inputs.  Note we reuse the fwd_rnn</span>
      <span class="c1"># theta so the results should match</span>
      <span class="n">bak_outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">bak_rnn</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">fwd_rnn</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">fwd_inputs</span><span class="p">,</span> <span class="n">fwd_paddings</span><span class="p">)</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">actual_reversed_outputs</span><span class="p">,</span> <span class="n">actual_bak_outputs</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
          <span class="p">[</span><span class="n">reversed_outputs</span><span class="p">,</span> <span class="n">bak_outputs</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">actual_reversed_outputs</span><span class="p">,</span> <span class="n">actual_bak_outputs</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testRNNWithConvLSTMCell"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testRNNWithConvLSTMCell">[docs]</a>  <span class="k">def</span> <span class="nf">testRNNWithConvLSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">ConvLSTMCell</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv_lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">inputs_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cell_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

      <span class="n">rnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn&#39;</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">10</span>
      <span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">rnn_params</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">paddings_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">):</span>
        <span class="n">inputs_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">paddings_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>
      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>

      <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs_sequence</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">paddings_sequence</span><span class="p">)</span>
      <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">paddings</span><span class="p">,</span>
                            <span class="p">[</span><span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

      <span class="n">sum_outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
      <span class="n">sum_final_m</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">final</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
      <span class="n">sum_final_c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">final</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">actual</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
          <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">(</span><span class="nb">sum</span><span class="o">=</span><span class="n">sum_outputs</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">sum_final_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">sum_final_c</span><span class="p">))</span>

      <span class="c1"># In case this test ever breaks, you can uncomment the line below, copy</span>
      <span class="c1"># out the golden values, and then comment out the line below again.</span>
      <span class="c1">#</span>
      <span class="c1"># print(&#39;sum_outputs&#39;, np.array_repr(actual.sum))</span>
      <span class="c1"># print(&#39;final_m&#39;, np.array_repr(actual.m))</span>
      <span class="c1"># print(&#39;final_c&#39;, np.array_repr(actual.c))</span>

      <span class="n">sum_expected</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.59282923</span><span class="p">,</span> <span class="mf">0.85964835</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.09797788</span><span class="p">]</span>
      <span class="n">m_expected</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.32634005</span><span class="p">,</span> <span class="mf">0.38098311</span><span class="p">,</span> <span class="mf">0.23331133</span><span class="p">]</span>
      <span class="n">c_expected</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.72942424</span><span class="p">,</span> <span class="mf">2.72087693</span><span class="p">,</span> <span class="mf">2.97179723</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sum_expected</span><span class="p">,</span> <span class="n">actual</span><span class="o">.</span><span class="n">sum</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">m_expected</span><span class="p">,</span> <span class="n">actual</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">c_expected</span><span class="p">,</span> <span class="n">actual</span><span class="o">.</span><span class="n">c</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_testFRNNWithConvLSTMCell</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">ConvLSTMCell</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv_lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">inputs_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cell_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

      <span class="n">rnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn&#39;</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">10</span>

      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;rnn&#39;</span><span class="p">):</span>
        <span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">rnn_params</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">paddings_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">):</span>
        <span class="n">inputs_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">paddings_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>
      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>

      <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs_sequence</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">paddings_sequence</span><span class="p">)</span>
      <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">paddings</span><span class="p">,</span>
                            <span class="p">[</span><span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">rnn_outputs</span> <span class="o">=</span> <span class="n">outputs</span>

      <span class="n">frnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;frnn&#39;</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">vn</span> <span class="o">=</span> <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span>

      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;frnn&#39;</span><span class="p">):</span>
        <span class="n">frnn</span> <span class="o">=</span> <span class="n">frnn_params</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">frnn_params</span><span class="p">)</span>

      <span class="n">frnn_outputs</span><span class="p">,</span> <span class="n">frnn_final</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs_sequence</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">paddings_sequence</span><span class="p">))</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">paddings_sequence</span><span class="p">)</span>
      <span class="n">frnn_outputs</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">paddings</span><span class="p">,</span>
                                 <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">paddings</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">))</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="p">(</span><span class="n">rnn_outputs_v</span><span class="p">,</span> <span class="n">rnn_final_v</span><span class="p">,</span> <span class="n">frnn_outputs_v</span><span class="p">,</span>
       <span class="n">frnn_final_v</span><span class="p">)</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">rnn_outputs</span><span class="p">,</span> <span class="n">final</span><span class="p">,</span> <span class="n">frnn_outputs</span><span class="p">,</span> <span class="n">frnn_final</span><span class="p">])</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">rnn_outputs_v</span><span class="p">,</span> <span class="n">frnn_outputs_v</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">rnn_final_v</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">frnn_final_v</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">rnn_final_v</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">frnn_final_v</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>

<div class="viewcode-block" id="LayersTest.testFRNNWithConvLSTMCell4"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testFRNNWithConvLSTMCell4">[docs]</a>  <span class="k">def</span> <span class="nf">testFRNNWithConvLSTMCell4</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testFRNNWithConvLSTMCell</span><span class="p">()</span></div>

<div class="viewcode-block" id="LayersTest.testRNNWithConvLSTMCellGradientChecker"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testRNNWithConvLSTMCellGradientChecker">[docs]</a>  <span class="k">def</span> <span class="nf">testRNNWithConvLSTMCellGradientChecker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">ConvLSTMCell</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv_lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">inputs_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cell_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

      <span class="n">rnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn&#39;</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">10</span>
      <span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">rnn_params</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">paddings_sequence</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">):</span>
        <span class="n">inputs_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">paddings_sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>
      <span class="n">paddings_sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>

      <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">inputs_sequence</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">paddings_sequence</span><span class="p">)</span>
      <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">paddings</span><span class="p">,</span>
                            <span class="p">[</span><span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
          <span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">final</span><span class="o">.</span><span class="n">m</span> <span class="o">+</span> <span class="n">final</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
      <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">all_variables</span><span class="p">()</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>

      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="n">symbolic_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">gd</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="k">for</span> <span class="n">gd</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
      <span class="n">numerical_grads</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">:</span>
        <span class="n">numerical_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">symbolic_grads</span><span class="p">,</span> <span class="n">numerical_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_testFRNNWithConvLSTMCellGradientChecker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">ConvLSTMCell</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv_lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">inputs_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cell_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

      <span class="n">frnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn&#39;</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">frnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNN</span><span class="p">(</span><span class="n">frnn_params</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs_sequence</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">inplace_ops</span><span class="o">.</span><span class="n">inplace_update</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>

      <span class="n">outputs</span><span class="p">,</span> <span class="n">final</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs_sequence</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">final</span><span class="o">.</span><span class="n">m</span> <span class="o">+</span> <span class="n">final</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
      <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">all_variables</span><span class="p">()</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>

      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="n">symbolic_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">gd</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="k">for</span> <span class="n">gd</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
      <span class="n">numerical_grads</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">:</span>
        <span class="n">numerical_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">symbolic_grads</span><span class="p">,</span> <span class="n">numerical_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<div class="viewcode-block" id="LayersTest.testFRNNWithConvLSTMCellGradientChecker"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testFRNNWithConvLSTMCellGradientChecker">[docs]</a>  <span class="k">def</span> <span class="nf">testFRNNWithConvLSTMCellGradientChecker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testFRNNWithConvLSTMCellGradientChecker</span><span class="p">()</span></div>

<div class="viewcode-block" id="LayersTest.testFRNNWithLSTMCellSimpleDeterministicGradientChecker"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testFRNNWithLSTMCellSimpleDeterministicGradientChecker">[docs]</a>  <span class="k">def</span> <span class="nf">testFRNNWithLSTMCellSimpleDeterministicGradientChecker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimpleDeterministic</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv_lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">zo_prob</span> <span class="o">=</span> <span class="mf">0.25</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="mi">4</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="mi">6</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span>

      <span class="n">frnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn&#39;</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">frnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNN</span><span class="p">(</span><span class="n">frnn_params</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs_sequence</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">inplace_ops</span><span class="o">.</span><span class="n">inplace_update</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">]])</span>

      <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs_sequence</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">*=</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

      <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>

      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="n">symbolic_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">gd</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="k">for</span> <span class="n">gd</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
      <span class="n">numerical_grads</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">:</span>
        <span class="n">numerical_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">symbolic_grads</span><span class="p">,</span> <span class="n">numerical_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.00001</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_testFRNNHelper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">slen</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.24</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">dims</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">dims</span>

      <span class="n">frnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;frnn&#39;</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;frnn&#39;</span><span class="p">):</span>
        <span class="n">frnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNN</span><span class="p">(</span><span class="n">frnn_params</span><span class="p">)</span>
        <span class="n">AddTimestepAccumulator</span><span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">cell</span><span class="p">)</span>

      <span class="n">rnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn&#39;</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="n">slen</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;rnn&#39;</span><span class="p">):</span>
        <span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="n">rnn_params</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dims</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">paddings</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="n">frnn_outputs</span><span class="p">,</span> <span class="n">frnn_final</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">rnn_outputs</span><span class="p">,</span> <span class="n">rnn_final</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">paddings</span><span class="p">))</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">frnn_out</span><span class="p">,</span> <span class="n">frnn_final</span><span class="p">,</span> <span class="n">rnn_out</span><span class="p">,</span> <span class="n">rnn_final</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
          <span class="p">[</span><span class="n">frnn_outputs</span><span class="p">,</span> <span class="n">frnn_final</span><span class="p">,</span> <span class="n">rnn_outputs</span><span class="p">,</span> <span class="n">rnn_final</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">frnn_out</span><span class="p">,</span> <span class="n">rnn_out</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">frnn_final</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">rnn_final</span><span class="o">.</span><span class="n">m</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">frnn_final</span><span class="o">.</span><span class="n">c</span><span class="p">,</span> <span class="n">rnn_final</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>

<div class="viewcode-block" id="LayersTest.testFRNNNoInline"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testFRNNNoInline">[docs]</a>  <span class="k">def</span> <span class="nf">testFRNNNoInline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testFRNNHelper</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span></div>

<div class="viewcode-block" id="LayersTest.testFRNNInline"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testFRNNInline">[docs]</a>  <span class="k">def</span> <span class="nf">testFRNNInline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testFRNNHelper</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span></div>

  <span class="k">def</span> <span class="nf">_testFRNNGradHelper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span>  <span class="c1"># More stable using float64.</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">slen</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">dims</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">dims</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>

      <span class="n">frnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;frnn&#39;</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">params</span>
      <span class="n">frnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNN</span><span class="p">(</span><span class="n">frnn_params</span><span class="p">)</span>
      <span class="n">AddTimestepAccumulator</span><span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">cell</span><span class="p">)</span>
      <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">b</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dims</span><span class="p">)),</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">paddings</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">frnn_outputs</span><span class="p">,</span> <span class="n">frnn_final</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">frnn_outputs</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
          <span class="n">frnn_final</span><span class="o">.</span><span class="n">m</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">frnn_final</span><span class="o">.</span><span class="n">c</span><span class="p">)</span>
      <span class="n">dw</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">dinputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">grad_step</span> <span class="o">=</span> <span class="mi">7</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">db</span><span class="p">,</span> <span class="n">dw</span><span class="p">,</span> <span class="n">dinputs</span><span class="p">])</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_utils</span><span class="o">.</span><span class="n">PickEveryN</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">grad_step</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">sym_grads</span><span class="p">]</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">test_utils</span><span class="o">.</span><span class="n">PickEveryN</span><span class="p">(</span>
              <span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">grad_step</span><span class="p">),</span>
              <span class="n">grad_step</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">inputs</span><span class="p">]</span>
      <span class="p">]</span>
      <span class="k">for</span> <span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">num</span><span class="p">)))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;max = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>

<div class="viewcode-block" id="LayersTest.testFRNNGradNoInline"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testFRNNGradNoInline">[docs]</a>  <span class="k">def</span> <span class="nf">testFRNNGradNoInline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testFRNNGradHelper</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span></div>

<div class="viewcode-block" id="LayersTest.testFRNNGradInline"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testFRNNGradInline">[docs]</a>  <span class="k">def</span> <span class="nf">testFRNNGradInline</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testFRNNGradHelper</span><span class="p">(</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span></div>

<div class="viewcode-block" id="LayersTest.testStackedFRNNDropout"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testStackedFRNNDropout">[docs]</a>  <span class="k">def</span> <span class="nf">testStackedFRNNDropout</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">v1_out</span><span class="p">,</span> <span class="n">unused_v1_fin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_testStackedFRNNHelper</span><span class="p">(</span>
        <span class="n">rnn_layers</span><span class="o">.</span><span class="n">StackedFRNNLayerByLayer</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
        <span class="n">trailing_pad_len</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">keep_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_gpu_available</span><span class="p">():</span>
      <span class="n">rtol</span> <span class="o">=</span> <span class="mf">1e-5</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">rtol</span> <span class="o">=</span> <span class="mf">1e-6</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">([</span><span class="mf">175.974121</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v1_out</span> <span class="o">*</span> <span class="n">v1_out</span><span class="p">)],</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testStackedFRNNLayerByLayerGrad"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testStackedFRNNLayerByLayerGrad">[docs]</a>  <span class="k">def</span> <span class="nf">testStackedFRNNLayerByLayerGrad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testStackedFRNNGradHelper</span><span class="p">(</span><span class="n">rnn_layers</span><span class="o">.</span><span class="n">StackedFRNNLayerByLayer</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_testBidirectionalFRNNHelper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                   <span class="n">trailing_pad_len</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                   <span class="n">cluster_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">slen</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">+</span> <span class="n">trailing_pad_len</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">(</span><span class="n">allow_soft_placement</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm_forward&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2938482</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">dims</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">dims</span>
      <span class="n">lstm_forward</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm_backward&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mi">83820209838</span><span class="p">)</span>
      <span class="n">lstm_backward</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>

      <span class="n">frnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">BidirectionalFRNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;bifrnn&#39;</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">fwd</span> <span class="o">=</span> <span class="n">lstm_forward</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">bak</span> <span class="o">=</span> <span class="n">lstm_backward</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;frnn&#39;</span><span class="p">):</span>
        <span class="n">frnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">BidirectionalFRNN</span><span class="p">(</span><span class="n">frnn_params</span><span class="p">)</span>

      <span class="n">rnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">BidirectionalRNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;rnn&#39;</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">fwd</span> <span class="o">=</span> <span class="n">lstm_forward</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">bak</span> <span class="o">=</span> <span class="n">lstm_backward</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">rnn_params</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="n">slen</span>

      <span class="k">with</span> <span class="n">cluster_factory</span><span class="o">.</span><span class="n">Cluster</span><span class="p">(</span><span class="n">cluster_params</span> <span class="k">if</span> <span class="n">cluster_params</span> <span class="k">else</span>
                                   <span class="n">cluster_factory</span><span class="o">.</span><span class="n">Cluster</span><span class="o">.</span><span class="n">Params</span><span class="p">()):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;rnn&#39;</span><span class="p">):</span>
          <span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">BidirectionalRNN</span><span class="p">(</span><span class="n">rnn_params</span><span class="p">)</span>

          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
          <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
              <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dims</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
          <span class="n">paddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
          <span class="n">paddings</span><span class="p">[</span><span class="o">-</span><span class="n">trailing_pad_len</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>
          <span class="n">paddings</span><span class="p">[</span><span class="o">-</span><span class="n">trailing_pad_len</span> <span class="o">-</span> <span class="mi">3</span><span class="p">:</span><span class="o">-</span><span class="n">trailing_pad_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>
          <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

          <span class="n">frnn_outputs</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
          <span class="n">rnn_outputs</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span>
              <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">paddings</span><span class="p">))</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">rnn_outputs_val</span><span class="p">,</span> <span class="n">frnn_outputs_val</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="n">trailing_pad_len</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">rnn_outputs</span><span class="p">,</span> <span class="n">frnn_outputs</span><span class="p">])</span>
      <span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">rnn_outputs_val</span><span class="p">,</span> <span class="n">frnn_outputs_val</span><span class="p">)</span>

<div class="viewcode-block" id="LayersTest.testBidirectionalFRNN"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testBidirectionalFRNN">[docs]</a>  <span class="k">def</span> <span class="nf">testBidirectionalFRNN</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testBidirectionalFRNNHelper</span><span class="p">()</span></div>

<div class="viewcode-block" id="LayersTest.testBidirectionalFRNNTrailingPadding"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testBidirectionalFRNNTrailingPadding">[docs]</a>  <span class="k">def</span> <span class="nf">testBidirectionalFRNNTrailingPadding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testBidirectionalFRNNHelper</span><span class="p">(</span><span class="n">trailing_pad_len</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testBidirectionalFRNNSplit"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testBidirectionalFRNNSplit">[docs]</a>  <span class="k">def</span> <span class="nf">testBidirectionalFRNNSplit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">cluster_params</span> <span class="o">=</span> <span class="n">cluster_factory</span><span class="o">.</span><span class="n">Cluster</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">cluster_params</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
        <span class="n">gpus_per_replica</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">devices_per_split</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;/job:localhost&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testBidirectionalFRNNHelper</span><span class="p">(</span><span class="n">cluster_params</span><span class="o">=</span><span class="n">cluster_params</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_testBidirectionalFRNNGradientHelper</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span>  <span class="c1"># More stable using float64.</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">slen</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm_forward&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">dims</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">dims</span>
      <span class="n">lstm_forward</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm_backward&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mi">83820209838</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">lstm_backward</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>

      <span class="n">frnn_params</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">BidirectionalFRNN</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;bifrnn&#39;</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">fwd</span> <span class="o">=</span> <span class="n">lstm_forward</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">frnn_params</span><span class="o">.</span><span class="n">bak</span> <span class="o">=</span> <span class="n">lstm_backward</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">frnn</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">BidirectionalFRNN</span><span class="p">(</span><span class="n">frnn_params</span><span class="p">)</span>
      <span class="n">w0</span><span class="p">,</span> <span class="n">b0</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">fwd_rnn</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">fwd_rnn</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
      <span class="n">w1</span><span class="p">,</span> <span class="n">b1</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">bak_rnn</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">bak_rnn</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>

      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dims</span><span class="p">)),</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">slen</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
      <span class="n">paddings</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">1.0</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">paddings</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">frnn_outputs</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">frnn_outputs</span><span class="p">)</span>

      <span class="n">dw0</span><span class="p">,</span> <span class="n">db0</span><span class="p">,</span> <span class="n">dw1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dinputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">w0</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">inputs</span><span class="p">])</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">grad_step</span> <span class="o">=</span> <span class="mi">13</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">dw0</span><span class="p">,</span> <span class="n">db0</span><span class="p">,</span> <span class="n">dw1</span><span class="p">,</span> <span class="n">db1</span><span class="p">,</span> <span class="n">dinputs</span><span class="p">])</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">test_utils</span><span class="o">.</span><span class="n">PickEveryN</span><span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">grad_step</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">sym_grads</span><span class="p">]</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">test_utils</span><span class="o">.</span><span class="n">PickEveryN</span><span class="p">(</span>
              <span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">grad_step</span><span class="p">),</span>
              <span class="n">grad_step</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="p">[</span><span class="n">w0</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">w1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">inputs</span><span class="p">]</span>
      <span class="p">]</span>
      <span class="k">for</span> <span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">num</span><span class="p">)))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;max = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>

<div class="viewcode-block" id="LayersTest.testBidirectionalFRNNGrad"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testBidirectionalFRNNGrad">[docs]</a>  <span class="k">def</span> <span class="nf">testBidirectionalFRNNGrad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testBidirectionalFRNNGradientHelper</span><span class="p">()</span></div>

  <span class="k">def</span> <span class="nf">_MultiSourceFRNNWithAttentionInputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                          <span class="n">single_source</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="n">single_source_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                          <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">single_source</span><span class="p">:</span>
      <span class="n">src_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;en&#39;</span><span class="p">]</span>
      <span class="n">slens</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">]</span>
      <span class="n">sdepths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">single_source_length</span><span class="p">:</span>
      <span class="n">src_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;en1&#39;</span><span class="p">,</span> <span class="s1">&#39;en2&#39;</span><span class="p">,</span> <span class="s1">&#39;de&#39;</span><span class="p">]</span>
      <span class="n">slens</span> <span class="o">=</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
      <span class="n">sdepths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">src_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;en1&#39;</span><span class="p">,</span> <span class="s1">&#39;en2&#39;</span><span class="p">,</span> <span class="s1">&#39;de&#39;</span><span class="p">]</span>
      <span class="n">slens</span> <span class="o">=</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
      <span class="n">sdepths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
    <span class="n">sbatch</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">tlen</span> <span class="o">=</span> <span class="mi">7</span>
    <span class="n">tbatch</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">4</span>

    <span class="n">src_encs</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
    <span class="n">src_paddings</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">sdepth</span><span class="p">,</span> <span class="n">slen</span><span class="p">,</span> <span class="n">sname</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sdepths</span><span class="p">,</span> <span class="n">slens</span><span class="p">,</span> <span class="n">src_names</span><span class="p">):</span>
      <span class="n">src_encs</span><span class="p">[</span><span class="n">sname</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">slen</span><span class="p">,</span> <span class="n">sbatch</span><span class="p">,</span> <span class="n">sdepth</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">src_paddings</span><span class="p">[</span><span class="n">sname</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">slen</span><span class="p">,</span> <span class="n">sbatch</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">tlen</span><span class="p">,</span> <span class="n">tbatch</span><span class="p">,</span> <span class="n">dims</span><span class="p">)),</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">tlen</span><span class="p">,</span> <span class="n">tbatch</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_MultiSourceFRNNWithAttentionParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                          <span class="n">single_source</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="n">single_source_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                          <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">alt_depth</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="k">if</span> <span class="n">single_source</span><span class="p">:</span>
      <span class="n">src_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;en&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">src_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;en1&#39;</span><span class="p">,</span> <span class="s1">&#39;en2&#39;</span><span class="p">,</span> <span class="s1">&#39;de&#39;</span><span class="p">]</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">dims</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">lstm_params</span> <span class="o">=</span> <span class="n">p</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">attention</span><span class="o">.</span><span class="n">AdditiveAttention</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;atten&#39;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">12345</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">p</span><span class="o">.</span><span class="n">query_dim</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">p</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">attention_tpl</span> <span class="o">=</span> <span class="n">p</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">layers_with_attention</span><span class="o">.</span><span class="n">MergerLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;merger&#39;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">merger_op</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;mean&#39;</span> <span class="k">if</span> <span class="n">single_source</span> <span class="k">else</span> <span class="s1">&#39;atten&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">p</span><span class="o">.</span><span class="n">query_dim</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">p</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">merger_tpl</span> <span class="o">=</span> <span class="n">p</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">MultiSourceFRNNWithAttention</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;msrc_frnn_with_atten&#39;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">lstm_params</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention_tpl</span> <span class="o">=</span> <span class="n">attention_tpl</span>
    <span class="n">p</span><span class="o">.</span><span class="n">atten_merger</span> <span class="o">=</span> <span class="n">merger_tpl</span>
    <span class="n">p</span><span class="o">.</span><span class="n">source_names</span> <span class="o">=</span> <span class="n">src_names</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">single_source_length</span><span class="p">:</span>
      <span class="n">de_atten</span> <span class="o">=</span> <span class="n">attention_tpl</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">de_atten</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">alt_depth</span>
      <span class="n">p</span><span class="o">.</span><span class="n">source_name_to_attention_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;de&#39;</span><span class="p">:</span> <span class="n">de_atten</span><span class="p">}</span>
      <span class="n">merger_tpl</span><span class="o">.</span><span class="n">pre_proj_input_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">dims</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">alt_depth</span><span class="p">]</span>
      <span class="n">merger_tpl</span><span class="o">.</span><span class="n">pre_proj_output_dim</span> <span class="o">=</span> <span class="n">dims</span>
      <span class="n">merger_tpl</span><span class="o">.</span><span class="n">proj_tpl</span><span class="o">.</span><span class="n">batch_norm</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">merger_tpl</span><span class="o">.</span><span class="n">proj_tpl</span><span class="o">.</span><span class="n">weight_norm</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="n">p</span>

<div class="viewcode-block" id="LayersTest.testMultiSourceFRNNWithAttention"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testMultiSourceFRNNWithAttention">[docs]</a>  <span class="k">def</span> <span class="nf">testMultiSourceFRNNWithAttention</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionParams</span><span class="p">()</span>
      <span class="n">msrc_frnn</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
       <span class="n">paddings</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionInputs</span><span class="p">()</span>
      <span class="n">a</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">msrc_frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
                                         <span class="n">paddings</span><span class="p">)</span>
      <span class="n">msrc_frnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">m</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">ys</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">msrc_frnn_out</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
      <span class="c1"># pyformat: disable</span>
      <span class="c1"># pylint: disable=bad-whitespace</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="p">[</span>
              <span class="mf">11.87568951</span><span class="p">,</span>  <span class="mf">11.8436203</span> <span class="p">,</span>  <span class="mf">11.80368233</span><span class="p">,</span>  <span class="mf">11.80167198</span><span class="p">,</span>
              <span class="mf">11.82034779</span><span class="p">,</span>  <span class="mf">11.80246162</span><span class="p">,</span>  <span class="mf">11.80818748</span>
          <span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="p">[</span>
              <span class="mf">21.41802788</span><span class="p">,</span>  <span class="mf">20.86244965</span><span class="p">,</span>  <span class="mf">21.48164749</span><span class="p">,</span>  <span class="mf">19.95701981</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">0.54706949</span><span class="p">,</span>   <span class="mf">0.07046284</span><span class="p">,</span>  <span class="o">-</span><span class="mf">0.50449395</span><span class="p">,</span>   <span class="mf">0.0176318</span>
          <span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="p">[</span>
              <span class="mf">13.29822254</span><span class="p">,</span>  <span class="mf">14.01552773</span><span class="p">,</span>  <span class="mf">14.04851151</span><span class="p">,</span>  <span class="mf">13.28098106</span><span class="p">,</span>
              <span class="mf">14.05391502</span><span class="p">,</span>  <span class="mf">14.0585041</span>
          <span class="p">])</span></div>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace</span>

<div class="viewcode-block" id="LayersTest.testMultiSourceFRNNWithAttentionMultiDepth"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testMultiSourceFRNNWithAttentionMultiDepth">[docs]</a>  <span class="k">def</span> <span class="nf">testMultiSourceFRNNWithAttentionMultiDepth</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionParams</span><span class="p">(</span><span class="n">single_source_length</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">msrc_frnn</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span>
      <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionInputs</span><span class="p">(</span><span class="n">single_source_length</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">a</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">msrc_frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
                                         <span class="n">paddings</span><span class="p">)</span>
      <span class="n">msrc_frnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">m</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">ys</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">msrc_frnn_out</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
      <span class="c1"># pyformat: disable</span>
      <span class="c1"># pylint: disable=bad-whitespace</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="p">[</span>
              <span class="mf">5.976197</span><span class="p">,</span>  <span class="mf">5.932313</span><span class="p">,</span>  <span class="mf">5.917447</span><span class="p">,</span>  <span class="mf">5.907898</span><span class="p">,</span>  <span class="mf">5.907385</span><span class="p">,</span>  <span class="mf">5.90272</span> <span class="p">,</span>
              <span class="mf">5.890248</span>
          <span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="p">[</span>
              <span class="mf">2.635296e+01</span><span class="p">,</span>   <span class="mf">3.177989e+00</span><span class="p">,</span>   <span class="mf">1.024462e+01</span><span class="p">,</span>   <span class="mf">2.403777e+00</span><span class="p">,</span>
              <span class="o">-</span><span class="mf">4.908564e-01</span><span class="p">,</span>   <span class="mf">1.006475e-01</span><span class="p">,</span>  <span class="o">-</span><span class="mf">3.303704e-01</span><span class="p">,</span>  <span class="o">-</span><span class="mf">2.455414e-02</span>
          <span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="p">[</span>
              <span class="mf">6.610287</span><span class="p">,</span>  <span class="mf">6.657996</span><span class="p">,</span>  <span class="mf">7.452699</span><span class="p">,</span>  <span class="mf">6.626875</span><span class="p">,</span>  <span class="mf">6.60216</span> <span class="p">,</span>  <span class="mf">7.484191</span>
          <span class="p">])</span></div>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace</span>

<div class="viewcode-block" id="LayersTest.testMultiSourceFRNNWithAttentionSingleSource"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testMultiSourceFRNNWithAttentionSingleSource">[docs]</a>  <span class="k">def</span> <span class="nf">testMultiSourceFRNNWithAttentionSingleSource</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionParams</span><span class="p">(</span>
          <span class="n">single_source</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">frnn</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
       <span class="n">paddings</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionInputs</span><span class="p">(</span>
           <span class="n">single_source</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

      <span class="n">a</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">frnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">m</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">ys</span><span class="p">,</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">frnn_out</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

      <span class="c1"># These values are identical with FRNNWithAttention.</span>
      <span class="n">expected_sum12</span> <span class="o">=</span> <span class="p">[</span>
          <span class="mf">13.07380962</span><span class="p">,</span> <span class="mf">13.03321552</span><span class="p">,</span> <span class="mf">12.99956226</span><span class="p">,</span> <span class="mf">13.00612164</span><span class="p">,</span> <span class="mf">13.01202011</span><span class="p">,</span>
          <span class="mf">12.99347878</span><span class="p">,</span> <span class="mf">12.98680687</span>
      <span class="p">]</span>
      <span class="n">expected_sum01</span> <span class="o">=</span> <span class="p">[</span>
          <span class="mf">2.41238327e+01</span><span class="p">,</span> <span class="mf">2.11899853e+01</span><span class="p">,</span> <span class="mf">2.45926647e+01</span><span class="p">,</span> <span class="mf">2.22827835e+01</span><span class="p">,</span>
          <span class="o">-</span><span class="mf">5.62886238e-01</span><span class="p">,</span> <span class="mf">2.42760777e-02</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.79716980e-01</span><span class="p">,</span> <span class="mf">3.40666063e-02</span>
      <span class="p">]</span>
      <span class="n">expected_sum02</span> <span class="o">=</span> <span class="p">[</span>
          <span class="mf">12.74695969</span><span class="p">,</span> <span class="mf">16.13114548</span><span class="p">,</span> <span class="mf">16.66101837</span><span class="p">,</span> <span class="mf">12.74922562</span><span class="p">,</span> <span class="mf">16.16581345</span><span class="p">,</span>
          <span class="mf">16.65085411</span>
      <span class="p">]</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">expected_sum12</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">expected_sum01</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">expected_sum02</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testMultiSourceFRNNWithAttentionGradSingleSource"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testMultiSourceFRNNWithAttentionGradSingleSource">[docs]</a>  <span class="k">def</span> <span class="nf">testMultiSourceFRNNWithAttentionGradSingleSource</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

      <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionParams</span><span class="p">(</span>
          <span class="n">single_source</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">frnn</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
       <span class="n">paddings</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionInputs</span><span class="p">(</span>
           <span class="n">single_source</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

      <span class="c1"># Fetch all the parameters.</span>
      <span class="n">w0</span><span class="p">,</span> <span class="n">b0</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
      <span class="n">att0h</span><span class="p">,</span> <span class="n">att0q</span><span class="p">,</span> <span class="n">att0s</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hidden_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">query_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">source_var</span><span class="p">)</span>

      <span class="n">out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

      <span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span><span class="n">w0</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">att0h</span><span class="p">,</span> <span class="n">att0q</span><span class="p">,</span> <span class="n">att0s</span><span class="p">]</span>
      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span>
      <span class="p">]</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">([</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">sym</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">num</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span><span class="p">)),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span> <span class="o">-</span> <span class="n">num</span><span class="p">)),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span> <span class="o">-</span> <span class="n">num</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span><span class="p">))</span>
        <span class="p">])</span>

      <span class="k">def</span> <span class="nf">Compare</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;name = &#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">num</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>

      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">)):</span>
        <span class="n">Compare</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testMultiSourceFRNNWithAttentionGrad"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testMultiSourceFRNNWithAttentionGrad">[docs]</a>  <span class="k">def</span> <span class="nf">testMultiSourceFRNNWithAttentionGrad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

      <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionParams</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">frnn</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="c1"># Fetch all the parameters.</span>
      <span class="n">w0</span><span class="p">,</span> <span class="n">b0</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
      <span class="n">mh</span><span class="p">,</span> <span class="n">mq</span><span class="p">,</span> <span class="n">ms</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">atten_merger</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">hidden_var</span><span class="p">,</span>
                    <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">atten_merger</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">query_var</span><span class="p">,</span>
                    <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">atten_merger</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">source_var</span><span class="p">)</span>
      <span class="n">att0h</span><span class="p">,</span> <span class="n">att0q</span><span class="p">,</span> <span class="n">att0s</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hidden_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">query_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">source_var</span><span class="p">)</span>
      <span class="n">att1h</span><span class="p">,</span> <span class="n">att1q</span><span class="p">,</span> <span class="n">att1s</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hidden_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">query_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">source_var</span><span class="p">)</span>
      <span class="n">att2h</span><span class="p">,</span> <span class="n">att2q</span><span class="p">,</span> <span class="n">att2s</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">hidden_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">query_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">source_var</span><span class="p">)</span>

      <span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
       <span class="n">paddings</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionInputs</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

      <span class="n">out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

      <span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">w0</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mh</span><span class="p">,</span> <span class="n">mq</span><span class="p">,</span> <span class="n">ms</span><span class="p">,</span> <span class="n">att0h</span><span class="p">,</span> <span class="n">att0q</span><span class="p">,</span> <span class="n">att0s</span><span class="p">,</span> <span class="n">att1h</span><span class="p">,</span> <span class="n">att1q</span><span class="p">,</span> <span class="n">att1s</span><span class="p">,</span>
          <span class="n">att2h</span><span class="p">,</span> <span class="n">att2q</span><span class="p">,</span> <span class="n">att2s</span>
      <span class="p">]</span>
      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span>
      <span class="p">]</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">([</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">sym</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">num</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span><span class="p">)),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span> <span class="o">-</span> <span class="n">num</span><span class="p">)),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span> <span class="o">-</span> <span class="n">num</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span><span class="p">))</span>
        <span class="p">])</span>

      <span class="k">def</span> <span class="nf">Compare</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;name = &#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">num</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>

      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">)):</span>
        <span class="n">Compare</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testMultiSourceFRNNWithAttentionGradMultiDepth"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testMultiSourceFRNNWithAttentionGradMultiDepth">[docs]</a>  <span class="k">def</span> <span class="nf">testMultiSourceFRNNWithAttentionGradMultiDepth</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>

      <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionParams</span><span class="p">(</span>
          <span class="n">single_source_length</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">frnn</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="c1"># Fetch all the parameters.</span>
      <span class="n">w0</span><span class="p">,</span> <span class="n">b0</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">wm</span><span class="p">,</span> <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">cell</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
      <span class="n">mh</span><span class="p">,</span> <span class="n">mq</span><span class="p">,</span> <span class="n">ms</span><span class="p">,</span> <span class="n">mw0</span><span class="p">,</span> <span class="n">mw1</span><span class="p">,</span> <span class="n">mw2</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">atten_merger</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">hidden_var</span><span class="p">,</span>
                                   <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">atten_merger</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">query_var</span><span class="p">,</span>
                                   <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">atten_merger</span><span class="o">.</span><span class="n">atten</span><span class="o">.</span><span class="n">source_var</span><span class="p">,</span>
                                   <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">atten_merger</span><span class="o">.</span><span class="n">pre_proj</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">w</span><span class="p">,</span>
                                   <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">atten_merger</span><span class="o">.</span><span class="n">pre_proj</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">w</span><span class="p">,</span>
                                   <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">atten_merger</span><span class="o">.</span><span class="n">pre_proj</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
      <span class="n">att0h</span><span class="p">,</span> <span class="n">att0q</span><span class="p">,</span> <span class="n">att0s</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hidden_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">query_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">source_var</span><span class="p">)</span>
      <span class="n">att1h</span><span class="p">,</span> <span class="n">att1q</span><span class="p">,</span> <span class="n">att1s</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hidden_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">query_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">source_var</span><span class="p">)</span>
      <span class="n">att2h</span><span class="p">,</span> <span class="n">att2q</span><span class="p">,</span> <span class="n">att2s</span> <span class="o">=</span> <span class="p">(</span><span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">hidden_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">query_var</span><span class="p">,</span>
                             <span class="n">frnn</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">attentions</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">source_var</span><span class="p">)</span>

      <span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
       <span class="n">paddings</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_MultiSourceFRNNWithAttentionInputs</span><span class="p">(</span>
           <span class="n">single_source_length</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

      <span class="n">out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

      <span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">w0</span><span class="p">,</span> <span class="n">b0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mh</span><span class="p">,</span> <span class="n">mq</span><span class="p">,</span> <span class="n">ms</span><span class="p">,</span> <span class="n">att0h</span><span class="p">,</span> <span class="n">att0q</span><span class="p">,</span> <span class="n">att0s</span><span class="p">,</span> <span class="n">att1h</span><span class="p">,</span> <span class="n">att1q</span><span class="p">,</span> <span class="n">att1s</span><span class="p">,</span>
          <span class="n">att2h</span><span class="p">,</span> <span class="n">att2q</span><span class="p">,</span> <span class="n">att2s</span><span class="p">,</span> <span class="n">mw0</span><span class="p">,</span> <span class="n">mw1</span><span class="p">,</span> <span class="n">mw2</span>
      <span class="p">]</span>
      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span>
      <span class="p">]</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">([</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">sym</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">num</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span><span class="p">)),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span> <span class="o">-</span> <span class="n">num</span><span class="p">)),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span> <span class="o">-</span> <span class="n">num</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sym</span><span class="p">))</span>
        <span class="p">])</span>

      <span class="k">def</span> <span class="nf">Compare</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;name = &#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sym</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertFalse</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">num</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>

      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">)):</span>
        <span class="n">Compare</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">sym</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_CreateFRNNWithAttentionParams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">slen</span><span class="p">,</span> <span class="n">sbatch</span><span class="p">,</span> <span class="n">tlen</span><span class="p">,</span>
                                     <span class="n">tbatch</span><span class="p">):</span>
    <span class="c1"># Create RNN Layer.</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCellSimple</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lstm&#39;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">output_nonlinearity</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.02</span><span class="p">,</span> <span class="mi">429891685</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">p</span><span class="o">.</span><span class="n">num_input_nodes</span> <span class="o">=</span> <span class="n">dims</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="n">p</span><span class="o">.</span><span class="n">num_output_nodes</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">lstm_params</span> <span class="o">=</span> <span class="n">p</span>

    <span class="c1"># Create Attention Layer.</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">attention</span><span class="o">.</span><span class="n">AdditiveAttention</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;atten&#39;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">12345</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">source_dim</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">p</span><span class="o">.</span><span class="n">query_dim</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">p</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="n">dims</span>
    <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">atten</span> <span class="o">=</span> <span class="n">p</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">rnn_layers</span><span class="o">.</span><span class="n">FRNNWithAttention</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;frnn_with_atten&#39;</span>
    <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="n">p</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">lstm_params</span>
    <span class="n">p</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">atten</span>
    <span class="n">p</span><span class="o">.</span><span class="n">output_prev_atten_ctx</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">p</span>

<div class="viewcode-block" id="LayersTest.testFRNNWithAttentionSeparateSourceContextIdenticalToSourceEnc"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testFRNNWithAttentionSeparateSourceContextIdenticalToSourceEnc">[docs]</a>  <span class="k">def</span> <span class="nf">testFRNNWithAttentionSeparateSourceContextIdenticalToSourceEnc</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">slen</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">sbatch</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">tlen</span> <span class="o">=</span> <span class="mi">7</span>
    <span class="n">tbatch</span> <span class="o">=</span> <span class="mi">6</span>

    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_CreateFRNNWithAttentionParams</span><span class="p">(</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span>
          <span class="n">slen</span><span class="o">=</span><span class="n">slen</span><span class="p">,</span>
          <span class="n">sbatch</span><span class="o">=</span><span class="n">sbatch</span><span class="p">,</span>
          <span class="n">tlen</span><span class="o">=</span><span class="n">tlen</span><span class="p">,</span>
          <span class="n">tbatch</span><span class="o">=</span><span class="n">tbatch</span><span class="p">)</span>

      <span class="n">frnn</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">src_encs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">slen</span><span class="p">,</span> <span class="n">sbatch</span><span class="p">,</span> <span class="n">dims</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">src_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">slen</span><span class="p">,</span> <span class="n">sbatch</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">)</span>

      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">tlen</span><span class="p">,</span> <span class="n">tbatch</span><span class="p">,</span> <span class="n">dims</span><span class="p">)),</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">tlen</span><span class="p">,</span> <span class="n">tbatch</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">)</span>

      <span class="c1"># Run without specifying source context vectors.</span>
      <span class="n">atten_ctx</span><span class="p">,</span> <span class="n">rnn_out</span><span class="p">,</span> <span class="n">atten_prob</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span>
          <span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">)</span>
      <span class="n">frnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">atten_ctx</span><span class="p">,</span> <span class="n">rnn_out</span><span class="p">,</span> <span class="n">atten_prob</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

      <span class="c1"># Run after providing separate source context vectors set to the src_encs</span>
      <span class="c1"># should provide the same answer.</span>
      <span class="p">(</span><span class="n">atten_ctx_src_ctx</span><span class="p">,</span> <span class="n">rnn_out_src_ctx</span><span class="p">,</span> <span class="n">atten_prob_src_ctx</span><span class="p">,</span>
       <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span>
           <span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">src_contexts</span><span class="o">=</span><span class="n">src_encs</span><span class="p">)</span>
      <span class="n">frnn_out_src_ctx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
          <span class="p">[</span><span class="n">atten_ctx_src_ctx</span><span class="p">,</span> <span class="n">rnn_out_src_ctx</span><span class="p">,</span> <span class="n">atten_prob_src_ctx</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">frnn_out_v</span><span class="p">,</span> <span class="n">frnn_out_src_ctx_v</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">frnn_out</span><span class="p">,</span> <span class="n">frnn_out_src_ctx</span><span class="p">])</span>

      <span class="c1"># Expected last dimensions for atten_ctx_src_ctx, rnn_out_src_ctx,</span>
      <span class="c1"># atten_prob_src_ctx are respectively, (dims, dims, slen).</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">frnn_out_v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">tlen</span><span class="p">,</span> <span class="n">tbatch</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">dims</span> <span class="o">+</span> <span class="n">slen</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">frnn_out_src_ctx_v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">frnn_out_v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">frnn_out_v</span><span class="p">,</span> <span class="n">frnn_out_src_ctx_v</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayersTest.testFRNNWithAttentionSeparateSourceContextDifferentFromSourceEnc"><a class="viewcode-back" href="../../../lingvo.core.rnn_layers_test.html#lingvo.core.rnn_layers_test.LayersTest.testFRNNWithAttentionSeparateSourceContextDifferentFromSourceEnc">[docs]</a>  <span class="k">def</span> <span class="nf">testFRNNWithAttentionSeparateSourceContextDifferentFromSourceEnc</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">slen</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">sbatch</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">tlen</span> <span class="o">=</span> <span class="mi">7</span>
    <span class="n">tbatch</span> <span class="o">=</span> <span class="mi">6</span>

    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span>
        <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">SessionConfig</span><span class="p">(</span><span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_CreateFRNNWithAttentionParams</span><span class="p">(</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
          <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">,</span>
          <span class="n">slen</span><span class="o">=</span><span class="n">slen</span><span class="p">,</span>
          <span class="n">sbatch</span><span class="o">=</span><span class="n">sbatch</span><span class="p">,</span>
          <span class="n">tlen</span><span class="o">=</span><span class="n">tlen</span><span class="p">,</span>
          <span class="n">tbatch</span><span class="o">=</span><span class="n">tbatch</span><span class="p">)</span>

      <span class="n">frnn</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">src_encs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">slen</span><span class="p">,</span> <span class="n">sbatch</span><span class="p">,</span> <span class="n">dims</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">src_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">slen</span><span class="p">,</span> <span class="n">sbatch</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">)</span>

      <span class="c1"># We create src_contexts with even dimensions (0, 2) set to all zero, the</span>
      <span class="c1"># rest are set randomly.</span>
      <span class="n">src_contexts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">slen</span><span class="p">,</span> <span class="n">sbatch</span><span class="p">,</span> <span class="n">dims</span><span class="p">])</span>
      <span class="n">src_contexts</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">dims</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
      <span class="n">src_contexts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">src_contexts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">tlen</span><span class="p">,</span> <span class="n">tbatch</span><span class="p">,</span> <span class="n">dims</span><span class="p">)),</span> <span class="n">dtype</span><span class="p">)</span>
      <span class="n">paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">tlen</span><span class="p">,</span> <span class="n">tbatch</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="p">)</span>

      <span class="c1"># Run after providing separate source context vectors set to the src_encs</span>
      <span class="c1"># should provide the same answer.</span>
      <span class="n">atten_ctx</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">frnn</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span>
          <span class="n">src_encs</span><span class="p">,</span> <span class="n">src_paddings</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">paddings</span><span class="p">,</span> <span class="n">src_contexts</span><span class="o">=</span><span class="n">src_contexts</span><span class="p">)</span>

      <span class="c1"># Initialize all the variables, and then run one step.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">atten_ctx_v</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">atten_ctx</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">atten_ctx_v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">tlen</span><span class="p">,</span> <span class="n">tbatch</span><span class="p">,</span> <span class="n">dims</span><span class="p">))</span>
      <span class="c1"># Verify that the output also has zeros in the locations that the</span>
      <span class="c1"># source context has zeros.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">tlen</span><span class="p">,</span> <span class="n">tbatch</span><span class="p">,</span> <span class="n">dims</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)),</span>
          <span class="n">atten_ctx_v</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">dims</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span></div></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">main</span><span class="p">()</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>