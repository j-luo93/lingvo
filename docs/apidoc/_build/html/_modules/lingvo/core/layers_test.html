

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lingvo.core.layers_test &mdash; lingvo  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.core.layers_test</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.core.layers_test</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Tests for layers.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">range</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">zip</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">py_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">quant_utils</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">test_utils</span>


<div class="viewcode-block" id="BatchNormLayerTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.BatchNormLayerTest">[docs]</a><span class="k">class</span> <span class="nc">BatchNormLayerTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="BatchNormLayerTest.testBatchNormLayerConstruction"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.BatchNormLayerTest.testBatchNormLayerConstruction">[docs]</a>  <span class="k">def</span> <span class="nf">testBatchNormLayerConstruction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;bn&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">bn_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;BatchNormLayer_vars&#39;</span><span class="p">)</span>
      <span class="n">bn_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">bn_vars</span><span class="p">]</span>
      <span class="n">expected_var_names</span> <span class="o">=</span> <span class="p">[</span>
          <span class="s1">&#39;bn/beta/var:0&#39;</span><span class="p">,</span> <span class="s1">&#39;bn/gamma/var:0&#39;</span><span class="p">,</span> <span class="s1">&#39;bn/moving_mean/var:0&#39;</span><span class="p">,</span>
          <span class="s1">&#39;bn/moving_variance/var:0&#39;</span>
      <span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">expected_var_names</span><span class="p">,</span> <span class="n">bn_var_names</span><span class="p">)</span></div>

<div class="viewcode-block" id="BatchNormLayerTest.testBatchNormLayerMoments"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.BatchNormLayerTest.testBatchNormLayerMoments">[docs]</a>  <span class="k">def</span> <span class="nf">testBatchNormLayerMoments</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>

      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">bn_in1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">mean1</span><span class="p">,</span> <span class="n">var1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">_Moments</span><span class="p">(</span><span class="n">bn_in1</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">mean2</span><span class="p">,</span> <span class="n">var2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">moments</span><span class="p">(</span><span class="n">bn_in1</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

      <span class="n">in_padding2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">bn_in2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">in_padding3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">in_padding1</span><span class="p">,</span> <span class="n">in_padding2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">bn_in3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">bn_in1</span><span class="p">,</span> <span class="n">bn_in2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">mean3</span><span class="p">,</span> <span class="n">var3</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">_Moments</span><span class="p">(</span><span class="n">bn_in3</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">in_padding3</span><span class="p">)</span>
      <span class="n">mean4</span><span class="p">,</span> <span class="n">var4</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">moments</span><span class="p">(</span><span class="n">bn_in3</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

      <span class="n">mean_diff</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">mean3</span> <span class="o">-</span> <span class="n">mean4</span><span class="p">))</span>
      <span class="n">var_diff</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">var3</span> <span class="o">-</span> <span class="n">var4</span><span class="p">))</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">mean2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">mean1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">var2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">var1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">mean3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">mean1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">var3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">var1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="c1"># Since tf.nn.moments() doesn&#39;t support padding, it is expected to produce</span>
      <span class="c1"># different results than our own implementation (of moments).</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">0.095987</span><span class="p">,</span> <span class="n">mean_diff</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">0.364456</span><span class="p">,</span> <span class="n">var_diff</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span></div>

<div class="viewcode-block" id="BatchNormLayerTest.testBatchNormLayerFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.BatchNormLayerTest.testBatchNormLayerFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testBatchNormLayerFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;bn&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">bn_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">bn_in1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="n">bn_out</span> <span class="o">=</span> <span class="n">bn_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">bn_in1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">sig1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">bn_out</span><span class="p">)</span>
      <span class="n">sig2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">bn_out</span> <span class="o">*</span> <span class="n">bn_out</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sig1</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">47.8371887</span><span class="p">,</span> <span class="n">sig2</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span></div>

<div class="viewcode-block" id="BatchNormLayerTest.testBatchNormLayerFPropUseGlobalStatsForTraining"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.BatchNormLayerTest.testBatchNormLayerFPropUseGlobalStatsForTraining">[docs]</a>  <span class="k">def</span> <span class="nf">testBatchNormLayerFPropUseGlobalStatsForTraining</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;bn&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">params</span><span class="o">.</span><span class="n">use_moving_avg_in_training</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">bn_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">bn_in1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="n">bn_out</span> <span class="o">=</span> <span class="n">bn_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">bn_in1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">sig1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">bn_out</span><span class="p">)</span>
      <span class="n">sig2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">bn_out</span> <span class="o">*</span> <span class="n">bn_out</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">2.6593573</span><span class="p">,</span> <span class="n">sig1</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">15.464208</span><span class="p">,</span> <span class="n">sig2</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span></div>

<div class="viewcode-block" id="BatchNormLayerTest.testBatchNormLayerMomentsForConv"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.BatchNormLayerTest.testBatchNormLayerMomentsForConv">[docs]</a>  <span class="k">def</span> <span class="nf">testBatchNormLayerMomentsForConv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>

      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">bn_in1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">mean1</span><span class="p">,</span> <span class="n">var1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">_Moments</span><span class="p">(</span><span class="n">bn_in1</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">mean2</span><span class="p">,</span> <span class="n">var2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">moments</span><span class="p">(</span><span class="n">bn_in1</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

      <span class="n">in_padding2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">bn_in2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">in_padding3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">in_padding1</span><span class="p">,</span> <span class="n">in_padding2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">bn_in3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">bn_in1</span><span class="p">,</span> <span class="n">bn_in2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">mean3</span><span class="p">,</span> <span class="n">var3</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">_Moments</span><span class="p">(</span><span class="n">bn_in3</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">in_padding3</span><span class="p">)</span>
      <span class="n">mean4</span><span class="p">,</span> <span class="n">var4</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">moments</span><span class="p">(</span><span class="n">bn_in3</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

      <span class="n">mean_diff</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">mean3</span> <span class="o">-</span> <span class="n">mean4</span><span class="p">))</span>
      <span class="n">var_diff</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">var3</span> <span class="o">-</span> <span class="n">var4</span><span class="p">))</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">mean2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">mean1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">var2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">var1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">mean3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">mean1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">var3</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">var1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">0.1726295</span><span class="p">,</span> <span class="n">mean_diff</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">0.5592572093009949</span><span class="p">,</span> <span class="n">var_diff</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span></div>

<div class="viewcode-block" id="BatchNormLayerTest.testBatchNormLayerFPropForConv"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.BatchNormLayerTest.testBatchNormLayerFPropForConv">[docs]</a>  <span class="k">def</span> <span class="nf">testBatchNormLayerFPropForConv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;bn_conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">bn_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">bn_in1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="n">bn_out</span> <span class="o">=</span> <span class="n">bn_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">bn_in1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">sig1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">bn_out</span><span class="p">)</span>
      <span class="n">sig2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">bn_out</span> <span class="o">*</span> <span class="n">bn_out</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sig1</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">2039.398681</span><span class="p">,</span> <span class="n">sig2</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span></div></div>


<div class="viewcode-block" id="ConvLayerTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest">[docs]</a><span class="k">class</span> <span class="nc">ConvLayerTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerConstruction"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerConstruction">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerConstruction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">conv_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;ConvLayer_vars&#39;</span><span class="p">)</span>
      <span class="n">conv_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">conv_vars</span><span class="p">]</span>
      <span class="n">expected_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;conv/w/var:0&#39;</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">expected_var_names</span><span class="p">,</span> <span class="n">conv_var_names</span><span class="p">)</span>
      <span class="n">bn_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;BatchNormLayer_vars&#39;</span><span class="p">)</span>
      <span class="n">bn_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">bn_vars</span><span class="p">]</span>
      <span class="n">expected_var_names</span> <span class="o">=</span> <span class="p">[</span>
          <span class="s1">&#39;conv/beta/var:0&#39;</span><span class="p">,</span> <span class="s1">&#39;conv/gamma/var:0&#39;</span><span class="p">,</span> <span class="s1">&#39;conv/moving_mean/var:0&#39;</span><span class="p">,</span>
          <span class="s1">&#39;conv/moving_variance/var:0&#39;</span>
      <span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">expected_var_names</span><span class="p">,</span> <span class="n">bn_var_names</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerWithBiasConstruction"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerWithBiasConstruction">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerWithBiasConstruction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tests ConvLayer with only bias and without batch normalization.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">batch_norm</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">conv_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;ConvLayer_vars&#39;</span><span class="p">)</span>
      <span class="n">conv_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">conv_vars</span><span class="p">]</span>
      <span class="c1"># Has both &#39;w&#39; and &#39;b&#39;.</span>
      <span class="n">expected_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;conv/w/var:0&#39;</span><span class="p">,</span> <span class="s1">&#39;conv/b/var:0&#39;</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">expected_var_names</span><span class="p">,</span> <span class="n">conv_var_names</span><span class="p">)</span>
      <span class="c1"># No BatchNorm variables.</span>
      <span class="n">bn_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;BatchNormLayer_vars&#39;</span><span class="p">)</span>
      <span class="n">bn_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">bn_vars</span><span class="p">]</span>
      <span class="n">expected_var_names</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">expected_var_names</span><span class="p">,</span> <span class="n">bn_var_names</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerOutShape"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerOutShape">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerOutShape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
      <span class="n">out_shape</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">OutShape</span><span class="p">(</span><span class="n">in_shape</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">out_shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">(),</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
      <span class="n">in_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
      <span class="n">out_shape</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">OutShape</span><span class="p">(</span><span class="n">in_shape</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">out_shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">(),</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerWithDilationOutShape"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerWithDilationOutShape">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerWithDilationOutShape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dilation_rate</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="c1"># dilation_rate does not change output shape.</span>
      <span class="n">in_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
      <span class="n">out_shape</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">OutShape</span><span class="p">(</span><span class="n">in_shape</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">out_shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">(),</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
      <span class="n">in_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
      <span class="n">out_shape</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">OutShape</span><span class="p">(</span><span class="n">in_shape</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">out_shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">(),</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvPoolComputeOutPadding"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvPoolComputeOutPadding">[docs]</a>  <span class="k">def</span> <span class="nf">testConvPoolComputeOutPadding</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">in_padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
           <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">out_padding</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">_ComputeOutputPadding</span><span class="p">(</span><span class="n">in_padding</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
      <span class="n">expected_out_padding</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_out_padding</span><span class="p">,</span> <span class="n">out_padding</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvPoolComputeOutPaddingUnevenStride"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvPoolComputeOutPaddingUnevenStride">[docs]</a>  <span class="k">def</span> <span class="nf">testConvPoolComputeOutPaddingUnevenStride</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">in_padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span>
              <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
          <span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">out_padding</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">_ComputeOutputPadding</span><span class="p">(</span><span class="n">in_padding</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
      <span class="n">expected_out_padding</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_out_padding</span><span class="p">,</span> <span class="n">out_padding</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span></div>

  <span class="k">def</span> <span class="nf">_checkConvLayerShapes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                            <span class="n">input_shape</span><span class="p">,</span>
                            <span class="n">filter_shape</span><span class="p">,</span>
                            <span class="n">filter_stride</span><span class="p">,</span>
                            <span class="n">dilation_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="n">filter_shape</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="n">filter_stride</span>
      <span class="k">if</span> <span class="n">dilation_rate</span><span class="p">:</span>
        <span class="n">params</span><span class="o">.</span><span class="n">dilation_rate</span> <span class="o">=</span> <span class="n">dilation_rate</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

      <span class="n">inp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
      <span class="n">inp_pad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]))</span>
      <span class="n">out</span><span class="p">,</span> <span class="n">out_pad</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">inp_pad</span><span class="p">)</span>

    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">out</span><span class="p">,</span> <span class="n">out_pad</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">out</span><span class="p">,</span> <span class="n">out_pad</span><span class="p">])</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">out_pad</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="c1"># We expect conv_layer.OutShape can compute the actually output&#39;s shape.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">OutShape</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()))</span>
      <span class="c1"># We expect out_pad.shape matches the 1st 2 dimensions of out.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">out_pad</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerOutputShapes"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerOutputShapes">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerOutputShapes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_checkConvLayerShapes</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_checkConvLayerShapes</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_checkConvLayerShapes</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_checkConvLayerShapes</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dilation_rate</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_checkConvLayerShapes</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dilation_rate</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span></div>

  <span class="k">def</span> <span class="nf">_evalConvLayerFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">weight_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;RELU&#39;</span><span class="p">,</span>
                          <span class="n">conv_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                          <span class="n">dilation_rate</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ClearCachedSession</span><span class="p">()</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="n">strides</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dilation_rate</span> <span class="o">=</span> <span class="n">dilation_rate</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">conv_last</span> <span class="o">=</span> <span class="n">conv_last</span>
      <span class="n">params</span><span class="o">.</span><span class="n">batch_norm</span> <span class="o">=</span> <span class="n">batch_norm</span>
      <span class="n">params</span><span class="o">.</span><span class="n">weight_norm</span> <span class="o">=</span> <span class="n">weight_norm</span>
      <span class="n">params</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
      <span class="n">params</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">inputs1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="n">output1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">output2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs1</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">v1</span>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># pyformat: disable</span>
    <span class="c1"># pylint: disable=bad-whitespace</span>
    <span class="n">expected_output1</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[[[</span> <span class="mf">0.36669245</span><span class="p">,</span>  <span class="mf">0.91488785</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.07532132</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.34952009</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.91783941</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">]]],</span>
        <span class="p">[[[</span> <span class="mf">0.28304493</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.86575812</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.60203481</span><span class="p">]]]]</span>
    <span class="c1"># pyformat: enable</span>
    <span class="c1"># pylint: enable=bad-whitespace</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evalConvLayerFProp</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;actual = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">)])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output1</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerWithDilationFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerWithDilationFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerWithDilationFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># pyformat: disable</span>
    <span class="c1"># pylint: disable=bad-whitespace</span>
    <span class="n">expected_output1</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.48857123</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.07320869</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.1550007</span> <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.59097648</span><span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.20024362</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.64265913</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.52903616</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.099805</span>  <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.61720949</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.31608474</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.0175612</span> <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.17234094</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.21719536</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.68514931</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">]]],</span>
        <span class="p">[[[</span> <span class="mf">1.45240796</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.72675145</span><span class="p">,</span>  <span class="mf">1.971596</span>  <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.01062769</span><span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.70299017</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.36936104</span><span class="p">,</span>  <span class="mf">1.29897082</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.40132439</span><span class="p">,</span>  <span class="mf">1.74345171</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.02585058</span><span class="p">,</span>  <span class="mf">0.29061913</span><span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.32962656</span><span class="p">,</span>  <span class="mf">0.05025356</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.97244394</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.23401484</span><span class="p">,</span>  <span class="mf">0.5722279</span> <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.40940297</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.52711827</span><span class="p">]]]]</span>
    <span class="c1"># pyformat: enable</span>
    <span class="c1"># pylint: enable=bad-whitespace</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evalConvLayerFProp</span><span class="p">(</span><span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dilation_rate</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;testConvLayerWithDilationFProp actual = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">)])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output1</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerConvFirstVsLastFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerConvFirstVsLastFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerConvFirstVsLastFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compare results of conv first vs. last.&quot;&quot;&quot;</span>
    <span class="c1"># ... with batch_norm and activation disabled.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_evalConvLayerFProp</span><span class="p">(</span>
            <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;NONE&#39;</span><span class="p">,</span> <span class="n">conv_last</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_evalConvLayerFProp</span><span class="p">(</span>
            <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;NONE&#39;</span><span class="p">,</span> <span class="n">conv_last</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerFPropConvLast"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerFPropConvLast">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerFPropConvLast</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># pyformat: disable</span>
    <span class="c1"># pylint: disable=bad-whitespace</span>
    <span class="n">expected_output1</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[[[</span> <span class="mf">0.22165056</span><span class="p">,</span>  <span class="mf">0.20731729</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.09577402</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.15359652</span><span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.07151584</span><span class="p">,</span>  <span class="mf">0.03027298</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.05370769</span><span class="p">,</span>  <span class="mf">0.0143405</span> <span class="p">]]],</span>
        <span class="p">[[[</span><span class="o">-</span><span class="mf">0.08854639</span><span class="p">,</span>  <span class="mf">0.06143938</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.37708873</span><span class="p">,</span>  <span class="mf">0.00889082</span><span class="p">]],</span>
         <span class="p">[[</span><span class="o">-</span><span class="mf">0.58154356</span><span class="p">,</span>  <span class="mf">0.30798748</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.37575331</span><span class="p">,</span>  <span class="mf">0.54729235</span><span class="p">]]]]</span>
    <span class="c1"># pyformat: enable</span>
    <span class="c1"># pylint: enable=bad-whitespace</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evalConvLayerFProp</span><span class="p">(</span><span class="n">conv_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;ConvLast actual = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">)])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output1</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerConvWithBias"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerConvWithBias">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerConvWithBias</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compare results with bias vs. with neither batch_norm nor bias.&quot;&quot;&quot;</span>
    <span class="c1"># Results should match since bias is initialized to be 0.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_evalConvLayerFProp</span><span class="p">(</span><span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_evalConvLayerFProp</span><span class="p">(</span><span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerWeightNormFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerWeightNormFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerWeightNormFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># pyformat: disable</span>
    <span class="c1"># pylint: disable=bad-whitespace</span>
    <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[[[</span> <span class="mf">0.37172362</span><span class="p">,</span> <span class="mf">0.92405349</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.07635488</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.35431579</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">1.94415355</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]]],</span>
        <span class="p">[[[</span> <span class="mf">0.28692839</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span><span class="p">]],</span>
         <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.87443149</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">1.61808443</span><span class="p">]]]]</span>
    <span class="c1"># pyformat: enable</span>
    <span class="c1"># pylint: enable=bad-whitespace</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evalConvLayerFProp</span><span class="p">(</span><span class="n">weight_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;actual1 = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">)])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvLayerTest.testCausalConvLayerFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testCausalConvLayerFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testCausalConvLayerFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">causal_convolution</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;NONE&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">batch_norm</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">inputs1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="c1"># Change the input for the last two steps.</span>
      <span class="n">inputs2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">inputs1</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">inputs1</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

      <span class="n">output1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">output2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs2</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">])</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;CausalConv output: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">v1</span><span class="p">))</span>
      <span class="c1"># pylint: disable=bad-whitespace,bad-continuation,line-too-long</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="p">[</span>
          <span class="p">[[[</span><span class="o">-</span><span class="mf">0.01093466</span><span class="p">,</span>  <span class="mf">0.00369835</span><span class="p">],</span>
            <span class="p">[</span> <span class="mf">0.03474921</span><span class="p">,</span>  <span class="mf">0.01418608</span><span class="p">],</span>
            <span class="p">[</span> <span class="mf">0.01887876</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00763734</span><span class="p">]],</span>
           <span class="p">[[</span><span class="o">-</span><span class="mf">0.06922598</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.04526342</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.02428233</span><span class="p">,</span>  <span class="mf">0.02042499</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.04504267</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01260209</span><span class="p">]],</span>
           <span class="p">[[</span><span class="o">-</span><span class="mf">0.14253227</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.11353028</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.09067881</span><span class="p">,</span>  <span class="mf">0.03742362</span><span class="p">],</span>
            <span class="p">[</span> <span class="mf">0.01281691</span><span class="p">,</span>  <span class="mf">0.00644186</span><span class="p">]],</span>
           <span class="p">[[</span><span class="o">-</span><span class="mf">0.06524619</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0555004</span> <span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.18850081</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05325979</span><span class="p">],</span>
            <span class="p">[</span> <span class="mf">0.04960757</span><span class="p">,</span>  <span class="mf">0.05512709</span><span class="p">]]],</span>
          <span class="p">[[[</span><span class="o">-</span><span class="mf">0.01077277</span><span class="p">,</span>  <span class="mf">0.03013588</span><span class="p">],</span>
            <span class="p">[</span> <span class="mf">0.00325067</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0223705</span> <span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.00895232</span><span class="p">,</span>  <span class="mf">0.03310337</span><span class="p">]],</span>
           <span class="p">[[</span> <span class="mf">0.03113075</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02388876</span><span class="p">],</span>
            <span class="p">[</span> <span class="mf">0.03238059</span><span class="p">,</span>  <span class="mf">0.00590346</span><span class="p">],</span>
            <span class="p">[</span> <span class="mf">0.12839797</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02194144</span><span class="p">]],</span>
           <span class="p">[[</span><span class="o">-</span><span class="mf">0.09115655</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.06798521</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.09801255</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01440183</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.04321899</span><span class="p">,</span>  <span class="mf">0.00340509</span><span class="p">]],</span>
           <span class="p">[[</span><span class="o">-</span><span class="mf">0.089603</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.07257183</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.04469771</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0389927</span> <span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.01747611</span><span class="p">,</span>  <span class="mf">0.00903451</span><span class="p">]]]</span>
      <span class="p">])</span>  <span class="c1"># pyformat: disable</span>
      <span class="c1"># pylint: enable=bad-whitespace,bad-continuation,line-too-long</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">v1</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">v2</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="ne">AssertionError</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">v1</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="n">v2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerBackProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerBackProp">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerBackProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">inputs1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">output1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">output1</span><span class="p">)</span>

      <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">))</span>

      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">sg</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="k">for</span> <span class="n">sg</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">test_utils</span><span class="o">.</span><span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span>
      <span class="p">]</span>

      <span class="k">for</span> <span class="n">sg</span><span class="p">,</span> <span class="n">ng</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sg</span><span class="p">,</span> <span class="n">ng</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-02</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-02</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvLayerFPropTanh"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvLayerFPropTanh">[docs]</a>  <span class="k">def</span> <span class="nf">testConvLayerFPropTanh</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;TANH&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">conv_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">inputs1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="n">output1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">conv_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="c1"># pyformat: disable</span>
      <span class="c1"># pylint: disable=bad-whitespace</span>
      <span class="n">expected_output1</span> <span class="o">=</span> <span class="p">[</span>
          <span class="p">[[[</span> <span class="mf">0.35109526</span><span class="p">,</span>  <span class="mf">0.72346997</span><span class="p">],</span>
            <span class="p">[</span> <span class="mf">0.0751792</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.84315312</span><span class="p">]],</span>
           <span class="p">[[</span> <span class="mf">0.33594984</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18976833</span><span class="p">],</span>
            <span class="p">[</span> <span class="mf">0.95773894</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.28015777</span><span class="p">]]],</span>
          <span class="p">[[[</span> <span class="mf">0.27572086</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.26577294</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.38503852</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.88501388</span><span class="p">]],</span>
           <span class="p">[[</span><span class="o">-</span><span class="mf">0.92332661</span><span class="p">,</span>  <span class="mf">0.69921255</span><span class="p">],</span>
            <span class="p">[</span><span class="o">-</span><span class="mf">0.75103623</span><span class="p">,</span>  <span class="mf">0.9219743</span> <span class="p">]]]]</span>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace</span>
      <span class="n">actual</span> <span class="o">=</span> <span class="n">output1</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
      <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;actual = &#39;</span><span class="p">,</span> <span class="n">actual</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output1</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ConvLayerTest.testConvSetLayerConstruction"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvSetLayerConstruction">[docs]</a>  <span class="k">def</span> <span class="nf">testConvSetLayerConstruction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvSetLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv_set&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shapes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">]]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">ConvSetLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_evalConvSetLayerFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                             <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                             <span class="n">weight_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;RELU&#39;</span><span class="p">,</span>
                             <span class="n">conv_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                             <span class="n">dilation_rate</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ClearCachedSession</span><span class="p">()</span>
    <span class="n">ops</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvSetLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv_set&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">filter_shapes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">filter_stride</span> <span class="o">=</span> <span class="n">strides</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">dilation_rate</span> <span class="o">=</span> <span class="n">dilation_rate</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">conv_last</span> <span class="o">=</span> <span class="n">conv_last</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">batch_norm</span> <span class="o">=</span> <span class="n">batch_norm</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">weight_norm</span> <span class="o">=</span> <span class="n">weight_norm</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
      <span class="n">params</span><span class="o">.</span><span class="n">cnn_tpl</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">conv_set_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvSetLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">inputs1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="n">output1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">conv_set_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="k">return</span> <span class="n">output1</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<div class="viewcode-block" id="ConvLayerTest.testConvSetLayerFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ConvLayerTest.testConvSetLayerFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testConvSetLayerFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># pyformat: disable</span>
    <span class="c1"># pylint: disable=bad-whitespace,bad-continuation</span>
    <span class="n">expected_output1</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[[[</span> <span class="mf">1.04307961</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.27613628</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.</span>          <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.21081829</span> <span class="p">]],</span>
        <span class="p">[[</span> <span class="mf">0.</span>         <span class="p">,</span>  <span class="mf">0.18475296</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.34087086</span>  <span class="p">,</span>  <span class="mf">2.2726357</span> <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>         <span class="p">]]],</span>
        <span class="p">[[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.25231963</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>       <span class="p">],</span>
        <span class="p">[</span> <span class="mf">1.13677704</span>  <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.996117</span>  <span class="p">,</span>  <span class="mf">1.836285</span>   <span class="p">]],</span>
        <span class="p">[[</span> <span class="mf">0.</span>         <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.04101253</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.12628449</span>  <span class="p">,</span>  <span class="mf">0.37599814</span><span class="p">,</span>  <span class="mf">0.3134549</span> <span class="p">,</span>  <span class="mf">0.51208746</span> <span class="p">]]]</span>
    <span class="p">]</span>
    <span class="c1"># pyformat: enable</span>
    <span class="c1"># pylint: enable=bad-whitespace,bad-continuation</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evalConvSetLayerFProp</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;actual = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">)])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output1</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div></div>

  <span class="c1"># TODO(yonghui): more test for convolution layer</span>


<div class="viewcode-block" id="PoolingLayerTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.PoolingLayerTest">[docs]</a><span class="k">class</span> <span class="nc">PoolingLayerTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="PoolingLayerTest.testPoolLayerFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.PoolingLayerTest.testPoolLayerFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testPoolLayerFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PoolingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;pool&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">window_shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">window_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">pool_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PoolingLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">inputs1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="n">output1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pool_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="nb">print</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">output1</span><span class="o">.</span><span class="n">eval</span><span class="p">())])</span>
      <span class="c1"># pyformat: disable</span>
      <span class="n">expected_output1</span> <span class="o">=</span> <span class="p">[</span>
          <span class="p">[[[</span><span class="mf">18.</span><span class="p">,</span> <span class="mf">19.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">21.</span><span class="p">,</span> <span class="mf">22.</span><span class="p">,</span> <span class="mf">23.</span><span class="p">]],</span>
           <span class="p">[[</span><span class="mf">30.</span><span class="p">,</span> <span class="mf">31.</span><span class="p">,</span> <span class="mf">32.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">33.</span><span class="p">,</span> <span class="mf">34.</span><span class="p">,</span> <span class="mf">35.</span><span class="p">]],</span>
           <span class="p">[[</span><span class="mf">42.</span><span class="p">,</span> <span class="mf">43.</span><span class="p">,</span> <span class="mf">44.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">45.</span><span class="p">,</span> <span class="mf">46.</span><span class="p">,</span> <span class="mf">47.</span><span class="p">]],</span>
           <span class="p">[[</span><span class="mf">42.</span><span class="p">,</span> <span class="mf">43.</span><span class="p">,</span> <span class="mf">44.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">45.</span><span class="p">,</span> <span class="mf">46.</span><span class="p">,</span> <span class="mf">47.</span><span class="p">]]],</span>
          <span class="p">[[[</span><span class="mf">66.</span><span class="p">,</span> <span class="mf">67.</span><span class="p">,</span> <span class="mf">68.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">69.</span><span class="p">,</span> <span class="mf">70.</span><span class="p">,</span> <span class="mf">71.</span><span class="p">]],</span>
           <span class="p">[[</span><span class="mf">78.</span><span class="p">,</span> <span class="mf">79.</span><span class="p">,</span> <span class="mf">80.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">81.</span><span class="p">,</span> <span class="mf">82.</span><span class="p">,</span> <span class="mf">83.</span><span class="p">]],</span>
           <span class="p">[[</span><span class="mf">90.</span><span class="p">,</span> <span class="mf">91.</span><span class="p">,</span> <span class="mf">92.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">93.</span><span class="p">,</span> <span class="mf">94.</span><span class="p">,</span> <span class="mf">95.</span><span class="p">]],</span>
           <span class="p">[[</span><span class="mf">90.</span><span class="p">,</span> <span class="mf">91.</span><span class="p">,</span> <span class="mf">92.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">93.</span><span class="p">,</span> <span class="mf">94.</span><span class="p">,</span> <span class="mf">95.</span><span class="p">]]]]</span>
      <span class="c1"># pyformat: enable</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output1</span><span class="p">,</span> <span class="n">output1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span></div>

<div class="viewcode-block" id="PoolingLayerTest.testPoolLayerMoreShapes"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.PoolingLayerTest.testPoolLayerMoreShapes">[docs]</a>  <span class="k">def</span> <span class="nf">testPoolLayerMoreShapes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">window_shape</span><span class="p">,</span> <span class="n">window_stride</span> <span class="ow">in</span> <span class="p">[</span>
          <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span>
          <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span>
          <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>
      <span class="p">]:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PoolingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;pool&#39;</span>
        <span class="n">params</span><span class="o">.</span><span class="n">window_shape</span> <span class="o">=</span> <span class="n">window_shape</span>
        <span class="n">params</span><span class="o">.</span><span class="n">window_stride</span> <span class="o">=</span> <span class="n">window_stride</span>
        <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">pool_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PoolingLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">inputs1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">output1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pool_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>

        <span class="n">output2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">params</span><span class="o">.</span><span class="n">window_shape</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                 <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">params</span><span class="o">.</span><span class="n">window_stride</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;SAME&#39;</span><span class="p">)</span>

        <span class="n">predicted_out_shape</span> <span class="o">=</span> <span class="n">pool_layer</span><span class="o">.</span><span class="n">OutShape</span><span class="p">(</span><span class="n">inputs1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
        <span class="n">output1_v</span> <span class="o">=</span> <span class="n">output1</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">output2</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">output1_v</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">predicted_out_shape</span><span class="o">.</span><span class="n">as_list</span><span class="p">(),</span> <span class="n">output1_v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ProjectionLayerTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest">[docs]</a><span class="k">class</span> <span class="nc">ProjectionLayerTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="ProjectionLayerTest.testProjectionLayerConstruction"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testProjectionLayerConstruction">[docs]</a>  <span class="k">def</span> <span class="nf">testProjectionLayerConstruction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;proj&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">proj_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;ProjectionLayer_vars&#39;</span><span class="p">)</span>
      <span class="n">proj_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">proj_vars</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">([</span><span class="s1">&#39;proj/w/var:0&#39;</span><span class="p">],</span> <span class="n">proj_var_names</span><span class="p">)</span>
      <span class="n">bn_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;BatchNormLayer_vars&#39;</span><span class="p">)</span>
      <span class="n">bn_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">bn_vars</span><span class="p">]</span>
      <span class="n">expected_var_names</span> <span class="o">=</span> <span class="p">[</span>
          <span class="s1">&#39;proj/beta/var:0&#39;</span><span class="p">,</span> <span class="s1">&#39;proj/gamma/var:0&#39;</span><span class="p">,</span> <span class="s1">&#39;proj/moving_mean/var:0&#39;</span><span class="p">,</span>
          <span class="s1">&#39;proj/moving_variance/var:0&#39;</span>
      <span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">expected_var_names</span><span class="p">,</span> <span class="n">bn_var_names</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_evalProjectionLayer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                           <span class="n">reshape_to_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                           <span class="n">weight_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;RELU&#39;</span><span class="p">,</span>
                           <span class="n">affine_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">input_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                           <span class="n">output_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                           <span class="n">quantized</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ClearCachedSession</span><span class="p">()</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;proj&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="n">output_dim</span>
      <span class="c1"># Disable both activation and batch_norm.</span>
      <span class="n">params</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
      <span class="n">params</span><span class="o">.</span><span class="n">batch_norm</span> <span class="o">=</span> <span class="n">batch_norm</span>
      <span class="n">params</span><span class="o">.</span><span class="n">weight_norm</span> <span class="o">=</span> <span class="n">weight_norm</span>
      <span class="n">params</span><span class="o">.</span><span class="n">affine_last</span> <span class="o">=</span> <span class="n">affine_last</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">quantized</span><span class="p">:</span>
        <span class="n">cc_schedule</span> <span class="o">=</span> <span class="n">quant_utils</span><span class="o">.</span><span class="n">FakeQuantizationSchedule</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
            <span class="n">clip_end_step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">quant_start_step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">qdomain_default</span> <span class="o">=</span> <span class="n">quant_utils</span><span class="o">.</span><span class="n">SymetricScheduledClipQDomain</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
            <span class="n">cc_schedule</span><span class="o">=</span><span class="n">cc_schedule</span><span class="o">.</span><span class="n">Copy</span><span class="p">())</span>
        <span class="n">params</span><span class="o">.</span><span class="n">qdomain</span><span class="o">.</span><span class="n">default</span> <span class="o">=</span> <span class="n">qdomain_default</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">in_padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">reshape_to_2d</span><span class="p">:</span>
        <span class="n">in_padding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">in_padding</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

      <span class="n">proj_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">output</span> <span class="o">=</span> <span class="n">proj_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">in_padding</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="k">if</span> <span class="n">quantized</span><span class="p">:</span>
        <span class="c1"># Put it in the fully quantized range.</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">proj_layer</span><span class="o">.</span><span class="n">PostTrainingStepUpdate</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>
      <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<div class="viewcode-block" id="ProjectionLayerTest.testProjectionLayerFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testProjectionLayerFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testProjectionLayerFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># pylint: disable=bad-whitespace</span>
    <span class="c1"># pyformat: disable</span>
    <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.33779466</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.4527415</span> <span class="p">,</span>  <span class="mf">0.99911398</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.44320837</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.04557215</span><span class="p">]],</span>
        <span class="p">[[</span> <span class="mf">0.69273949</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.30908319</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.54578114</span><span class="p">]]]</span>
    <span class="c1"># pyformat: enable</span>
    <span class="c1"># pylint: enable=bad-whitespace</span>
    <span class="k">for</span> <span class="n">reshape_to_2d</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
      <span class="n">actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evalProjectionLayer</span><span class="p">(</span><span class="n">reshape_to_2d</span><span class="o">=</span><span class="n">reshape_to_2d</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">reshape_to_2d</span><span class="p">:</span>
        <span class="n">expected_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">expected_output</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;expected = </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;actual = </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ProjectionLayerTest.testProjectionLayerWeightNorm"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testProjectionLayerWeightNorm">[docs]</a>  <span class="k">def</span> <span class="nf">testProjectionLayerWeightNorm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># pylint: disable=bad-whitespace</span>
    <span class="c1"># pyformat: disable</span>
    <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.36285588</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.82909501</span><span class="p">,</span>  <span class="mf">1.07323885</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.81163716</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.04895319</span><span class="p">]],</span>
        <span class="p">[[</span> <span class="mf">1.26859784</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.56601691</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.66046333</span><span class="p">]]]</span>
    <span class="c1"># pyformat: enable</span>
    <span class="c1"># pylint: enable=bad-whitespace</span>
    <span class="k">for</span> <span class="n">reshape_to_2d</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
      <span class="n">actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evalProjectionLayer</span><span class="p">(</span>
          <span class="n">reshape_to_2d</span><span class="o">=</span><span class="n">reshape_to_2d</span><span class="p">,</span> <span class="n">weight_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">reshape_to_2d</span><span class="p">:</span>
        <span class="n">expected_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">expected_output</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;expected = </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;actual = </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ProjectionLayerTest.testProjectionLayerAffineFirstVsLastFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testProjectionLayerAffineFirstVsLastFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testProjectionLayerAffineFirstVsLastFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compare results of affine first vs. last.&quot;&quot;&quot;</span>
    <span class="c1"># ... with batch_norm and activation disabled.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_evalProjectionLayer</span><span class="p">(</span>
            <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;NONE&#39;</span><span class="p">,</span> <span class="n">affine_last</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_evalProjectionLayer</span><span class="p">(</span>
            <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;NONE&#39;</span><span class="p">,</span> <span class="n">affine_last</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span></div>

<div class="viewcode-block" id="ProjectionLayerTest.testProjectionLayerAffineLastFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testProjectionLayerAffineLastFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testProjectionLayerAffineLastFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># pylint: disable=bad-whitespace</span>
    <span class="c1"># pyformat: disable</span>
    <span class="n">expected_output1</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.03410175</span><span class="p">,</span>  <span class="mf">0.04741348</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.02665393</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02072855</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.01116518</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.06280501</span><span class="p">]],</span>
        <span class="p">[[</span> <span class="mf">0.04615254</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.03589247</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.00376316</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0464084</span> <span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.01111402</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.13706152</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.02596203</span><span class="p">,</span>  <span class="mf">0.16340451</span><span class="p">]]]</span>
    <span class="c1"># pyformat: enable</span>
    <span class="c1"># pylint: enable=bad-whitespace</span>
    <span class="n">actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evalProjectionLayer</span><span class="p">(</span><span class="n">affine_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;actual = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">)])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output1</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ProjectionLayerTest.testProjectionLayerBackProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testProjectionLayerBackProp">[docs]</a>  <span class="k">def</span> <span class="nf">testProjectionLayerBackProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;proj&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">proj_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">in_padding1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
      <span class="n">inputs1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
      <span class="n">output1</span> <span class="o">=</span> <span class="n">proj_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs1</span><span class="p">,</span> <span class="n">in_padding1</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">output1</span><span class="p">)</span>

      <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">))</span>

      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">sg</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="k">for</span> <span class="n">sg</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">test_utils</span><span class="o">.</span><span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span>
      <span class="p">]</span>

      <span class="k">for</span> <span class="n">sg</span><span class="p">,</span> <span class="n">ng</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sg</span><span class="p">,</span> <span class="n">ng</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">)</span></div>

<div class="viewcode-block" id="ProjectionLayerTest.testProjectionLayerFPropQuantized"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testProjectionLayerFPropQuantized">[docs]</a>  <span class="k">def</span> <span class="nf">testProjectionLayerFPropQuantized</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># pylint: disable=bad-whitespace</span>
    <span class="c1"># pyformat: disable</span>
    <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[[</span><span class="o">-</span><span class="mf">0.0546875</span><span class="p">,</span>  <span class="mf">0.3203125</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.359375</span> <span class="p">,</span>  <span class="mf">0.7421875</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.359375</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.109375</span> <span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.6015625</span><span class="p">,</span>  <span class="mf">0.0703125</span><span class="p">]],</span>
        <span class="p">[[</span> <span class="mf">0.5234375</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.28125</span>  <span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.359375</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.9140625</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.0546875</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7578125</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.71875</span>  <span class="p">,</span>  <span class="mf">0.921875</span> <span class="p">]]]</span>
    <span class="c1"># pyformat: enable</span>
    <span class="c1"># pylint: enable=bad-whitespace</span>
    <span class="k">for</span> <span class="n">reshape_to_2d</span> <span class="ow">in</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
      <span class="c1"># Note: Generally, quantized projections prefer a TANH activation.</span>
      <span class="c1"># We only test that here.</span>
      <span class="n">actual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evalProjectionLayer</span><span class="p">(</span>
          <span class="n">reshape_to_2d</span><span class="o">=</span><span class="n">reshape_to_2d</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;TANH&#39;</span><span class="p">,</span> <span class="n">quantized</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">reshape_to_2d</span><span class="p">:</span>
        <span class="n">expected_output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">expected_output</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;expected = </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;actual = </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ProjectionLayerTest.testFCLayerConstruction"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testFCLayerConstruction">[docs]</a>  <span class="k">def</span> <span class="nf">testFCLayerConstruction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FCLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;fc&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
      <span class="n">layers</span><span class="o">.</span><span class="n">FCLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">proj_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;FCLayer_vars&#39;</span><span class="p">)</span>
      <span class="n">proj_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">proj_vars</span><span class="p">]</span>
      <span class="n">expected_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;fc/w/var:0&#39;</span><span class="p">,</span> <span class="s1">&#39;fc/b/var:0&#39;</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">expected_var_names</span><span class="p">,</span> <span class="n">proj_var_names</span><span class="p">)</span></div>

<div class="viewcode-block" id="ProjectionLayerTest.testFCLayerFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testFCLayerFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testFCLayerFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FCLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;fc&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

      <span class="n">proj_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FCLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="n">output</span> <span class="o">=</span> <span class="n">proj_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="c1"># pylint: disable=bad-whitespace</span>
      <span class="c1"># pyformat: disable</span>
      <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[</span>
          <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.04883499</span><span class="p">],</span>
           <span class="p">[</span> <span class="mf">0.17094055</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
           <span class="p">[</span> <span class="mf">0.09287541</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
           <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.19471419</span><span class="p">]],</span>
          <span class="p">[[</span> <span class="mf">0.15290432</span><span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
           <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">],</span>
           <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.10548697</span><span class="p">],</span>
           <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.22610095</span><span class="p">]]]</span>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace</span>
      <span class="n">actual</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
      <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;actual = &#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">actual</span><span class="p">)])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span></div>

<div class="viewcode-block" id="ProjectionLayerTest.testFCLayerBackProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.ProjectionLayerTest.testFCLayerBackProp">[docs]</a>  <span class="k">def</span> <span class="nf">testFCLayerBackProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FCLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;fc&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">params</span><span class="o">.</span><span class="n">output_dim</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>

      <span class="n">proj_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FCLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
      <span class="n">output</span> <span class="o">=</span> <span class="n">proj_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

      <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">))</span>

      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">sg</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="k">for</span> <span class="n">sg</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">test_utils</span><span class="o">.</span><span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">)</span>
          <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span>
      <span class="p">]</span>

      <span class="k">for</span> <span class="n">sg</span><span class="p">,</span> <span class="n">ng</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sg</span><span class="p">,</span> <span class="n">ng</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="EmbeddingLayerTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest">[docs]</a><span class="k">class</span> <span class="nc">EmbeddingLayerTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="EmbeddingLayerTest.testEmbeddingLayer"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testEmbeddingLayer">[docs]</a>  <span class="k">def</span> <span class="nf">testEmbeddingLayer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">80000</span>
      <span class="n">params</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
      <span class="n">params</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">4</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">emb_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">89</span><span class="p">],</span> <span class="p">[</span><span class="mi">100</span><span class="p">]])</span>
      <span class="n">embs</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">EmbLookupDefaultTheta</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
      <span class="n">embs_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">embs</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">test_utils</span><span class="o">.</span><span class="n">CompareToGoldenSingleFloat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="mf">0.234941</span><span class="p">,</span> <span class="n">embs_sum</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testCheckedIds"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testCheckedIds">[docs]</a>  <span class="k">def</span> <span class="nf">testCheckedIds</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">16</span>
      <span class="n">params</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
      <span class="n">params</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">4</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">emb_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

      <span class="n">neg_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
      <span class="n">neg_embs</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">EmbLookupDefaultTheta</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">)</span>
      <span class="n">oov_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="n">params</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]])</span>
      <span class="n">oov_embs</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">EmbLookupDefaultTheta</span><span class="p">(</span><span class="n">oov_ids</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">InvalidArgumentError</span><span class="p">):</span>
        <span class="n">neg_embs</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">assertRaises</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">InvalidArgumentError</span><span class="p">):</span>
        <span class="n">oov_embs</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testEmbeddingLayerScaling"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testEmbeddingLayerScaling">[docs]</a>  <span class="k">def</span> <span class="nf">testEmbeddingLayerScaling</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">80000</span>
      <span class="n">params</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
      <span class="n">params</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">4</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">scale_sqrt_depth</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">emb_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">89</span><span class="p">],</span> <span class="p">[</span><span class="mi">100</span><span class="p">]])</span>
      <span class="n">embs</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">EmbLookupDefaultTheta</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
      <span class="n">embs_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">embs</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="mf">0.23494134843349457</span> <span class="o">*</span> <span class="n">params</span><span class="o">.</span><span class="n">embedding_dim</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span>
                          <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">embs_sum</span><span class="p">))</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testEmbeddingLayerWithVN"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testEmbeddingLayerWithVN">[docs]</a>  <span class="k">def</span> <span class="nf">testEmbeddingLayerWithVN</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">80000</span>
      <span class="n">params</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
      <span class="n">params</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">4</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.5</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">398847392</span>
      <span class="n">emb_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">emb_layer</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()),</span> <span class="mi">4</span><span class="p">)</span>
      <span class="n">ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">89</span><span class="p">],</span> <span class="p">[</span><span class="mi">100</span><span class="p">]])</span>
      <span class="n">embs</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">EmbLookupDefaultTheta</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
      <span class="n">embs_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">embs</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">test_utils</span><span class="o">.</span><span class="n">CompareToGoldenSingleFloat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.807296</span><span class="p">,</span> <span class="n">embs_sum</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span></div>

  <span class="k">def</span> <span class="nf">_testSimpleEmbeddingLayer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_matmul</span><span class="p">,</span> <span class="n">use_3d_weight_tensor</span><span class="p">,</span>
                                <span class="n">fprop_mode</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">8000</span>
      <span class="n">params</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
      <span class="n">params</span><span class="o">.</span><span class="n">use_matmul</span> <span class="o">=</span> <span class="n">use_matmul</span>
      <span class="n">params</span><span class="o">.</span><span class="n">fprop_mode</span> <span class="o">=</span> <span class="n">fprop_mode</span>
      <span class="n">params</span><span class="o">.</span><span class="n">use_3d_weight_tensor</span> <span class="o">=</span> <span class="n">use_3d_weight_tensor</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>

      <span class="n">emb_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleEmbeddingLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">expected_fprop_mode</span> <span class="o">=</span> <span class="n">fprop_mode</span>
      <span class="k">if</span> <span class="n">expected_fprop_mode</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">expected_fprop_mode</span> <span class="o">=</span> <span class="s1">&#39;matmul&#39;</span> <span class="k">if</span> <span class="n">use_matmul</span> <span class="k">else</span> <span class="s1">&#39;loop&#39;</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">emb_layer</span><span class="o">.</span><span class="n">_fprop_mode</span><span class="p">,</span> <span class="n">expected_fprop_mode</span><span class="p">)</span>

      <span class="n">emb_matrix</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span>
      <span class="n">ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">89</span><span class="p">],</span> <span class="p">[</span><span class="mi">100</span><span class="p">]])</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">EmbLookupDefaultTheta</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
      <span class="n">fast_outputs</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">EmbLookupDefaultThetaOnCpu</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>

    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">emb_matrix_val</span><span class="p">,</span> <span class="n">ids_val</span><span class="p">,</span> <span class="n">outputs_val</span><span class="p">,</span> <span class="n">fast_outputs_val</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
          <span class="p">[</span><span class="n">emb_matrix</span><span class="p">,</span> <span class="n">ids</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">fast_outputs</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">emb_matrix_val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">8000</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">ids_val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">outputs_val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">emb_matrix_val</span><span class="p">[</span><span class="mi">89</span><span class="p">,</span> <span class="p">:],</span> <span class="n">outputs_val</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">emb_matrix_val</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="p">:],</span> <span class="n">outputs_val</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">fast_outputs_val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">emb_matrix_val</span><span class="p">[</span><span class="mi">89</span><span class="p">,</span> <span class="p">:],</span> <span class="n">fast_outputs_val</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">emb_matrix_val</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="p">:],</span> <span class="n">fast_outputs_val</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>

<div class="viewcode-block" id="EmbeddingLayerTest.testSimpleEmbeddingLayerForLoop"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testSimpleEmbeddingLayerForLoop">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleEmbeddingLayerForLoop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testSimpleEmbeddingLayer</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testSimpleEmbeddingLayerForLoop2D"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testSimpleEmbeddingLayerForLoop2D">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleEmbeddingLayerForLoop2D</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testSimpleEmbeddingLayer</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testSimpleEmbeddingLayerMatmul"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testSimpleEmbeddingLayerMatmul">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleEmbeddingLayerMatmul</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testSimpleEmbeddingLayer</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testSimpleEmbeddingLayerGather"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testSimpleEmbeddingLayerGather">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleEmbeddingLayerGather</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testSimpleEmbeddingLayer</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;gather&#39;</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_testSimpleEmbeddingLayerGrad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_matmul</span><span class="p">,</span> <span class="n">use_3d_weight_tensor</span><span class="p">):</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">8000</span>
      <span class="n">params</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
      <span class="n">params</span><span class="o">.</span><span class="n">use_matmul</span> <span class="o">=</span> <span class="n">use_matmul</span>
      <span class="n">params</span><span class="o">.</span><span class="n">use_3d_weight_tensor</span> <span class="o">=</span> <span class="n">use_3d_weight_tensor</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">emb_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleEmbeddingLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">89</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">89</span><span class="p">,</span> <span class="mi">89</span><span class="p">])</span>
      <span class="n">embs</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">EmbLookupDefaultTheta</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">],</span>
                                                                 <span class="p">[</span><span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">]])</span>
      <span class="n">embs_sum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">embs</span><span class="p">)</span>
      <span class="n">emb_weight</span> <span class="o">=</span> <span class="n">emb_layer</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span>
      <span class="n">emb_grad</span><span class="p">,</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">ys</span><span class="o">=</span><span class="p">[</span><span class="n">embs_sum</span><span class="p">],</span> <span class="n">xs</span><span class="o">=</span><span class="p">[</span><span class="n">emb_weight</span><span class="p">])</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">emb_grad_val</span> <span class="o">=</span> <span class="n">emb_grad</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">expected_emb_grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8000</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
    <span class="n">expected_emb_grad</span><span class="p">[</span><span class="mi">89</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">0.8</span>
    <span class="n">expected_emb_grad</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_emb_grad</span><span class="p">,</span> <span class="n">emb_grad_val</span><span class="p">)</span>

<div class="viewcode-block" id="EmbeddingLayerTest.testSimpleEmbeddingLayerGradForLoop"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testSimpleEmbeddingLayerGradForLoop">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleEmbeddingLayerGradForLoop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testSimpleEmbeddingLayerGrad</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testSimpleEmbeddingLayerGradForLoop2D"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testSimpleEmbeddingLayerGradForLoop2D">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleEmbeddingLayerGradForLoop2D</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testSimpleEmbeddingLayerGrad</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testSimpleEmbeddingLayerGradMatmul"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testSimpleEmbeddingLayerGradMatmul">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleEmbeddingLayerGradMatmul</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testSimpleEmbeddingLayerGrad</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testCompareEmbeddingLayers"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testCompareEmbeddingLayers">[docs]</a>  <span class="k">def</span> <span class="nf">testCompareEmbeddingLayers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="mi">8000</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="mi">128</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="n">ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">CreateSimple</span><span class="p">():</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
        <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb&#39;</span>
        <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
        <span class="n">p</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">classes</span>
        <span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">dims</span>
        <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleEmbeddingLayer</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">simple</span> <span class="o">=</span> <span class="n">CreateSimple</span><span class="p">()</span>
      <span class="n">simple_outs</span> <span class="o">=</span> <span class="n">simple</span><span class="o">.</span><span class="n">EmbLookupDefaultTheta</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
      <span class="n">simple_grad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">simple_outs</span><span class="p">,</span> <span class="n">simple</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

      <span class="k">def</span> <span class="nf">CreateOriginal</span><span class="p">():</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
        <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;emb&#39;</span>
        <span class="n">p</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
        <span class="n">p</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">classes</span>
        <span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">dims</span>
        <span class="n">p</span><span class="o">.</span><span class="n">max_num_shards</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">EmbeddingLayer</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">original</span> <span class="o">=</span> <span class="n">CreateOriginal</span><span class="p">()</span>
      <span class="n">weight</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">simple</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">wm</span><span class="p">)</span>
      <span class="n">theta</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">NestedMap</span><span class="p">()</span>
      <span class="n">theta</span><span class="o">.</span><span class="n">wm</span> <span class="o">=</span> <span class="p">[</span><span class="n">weight</span><span class="p">]</span>
      <span class="n">original_outs</span> <span class="o">=</span> <span class="n">original</span><span class="o">.</span><span class="n">EmbLookup</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span>
      <span class="n">original_grad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">original_outs</span><span class="p">,</span> <span class="n">weight</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">ids_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4000</span><span class="p">,))</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">g</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
      <span class="n">s_outs</span><span class="p">,</span> <span class="n">s_grad</span><span class="p">,</span> <span class="n">o_outs</span><span class="p">,</span> <span class="n">o_grad</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
          <span class="p">[</span><span class="n">simple_outs</span><span class="p">,</span> <span class="n">simple_grad</span><span class="p">,</span> <span class="n">original_outs</span><span class="p">,</span> <span class="n">original_grad</span><span class="p">],</span>
          <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">ids</span><span class="p">:</span> <span class="n">ids_val</span><span class="p">})</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">s_outs</span><span class="p">,</span> <span class="n">o_outs</span><span class="p">)</span>

      <span class="c1"># tf.embedding_lookup&#39;s gradient is a sparse representation.</span>
      <span class="c1"># For testing, we convert it to a dense representation.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllEqual</span><span class="p">(</span><span class="n">ids_val</span><span class="p">,</span> <span class="n">o_grad</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
      <span class="n">o_grad_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">classes</span><span class="p">,</span> <span class="n">dims</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">o_grad</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">o_grad_matrix</span><span class="p">[</span><span class="n">o_grad</span><span class="o">.</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">o_grad</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">s_grad</span><span class="p">,</span> <span class="n">o_grad_matrix</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testPositionalEmbeddingLayer"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testPositionalEmbeddingLayer">[docs]</a>  <span class="k">def</span> <span class="nf">testPositionalEmbeddingLayer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;position_emb&#39;</span>
      <span class="n">p</span><span class="o">.</span><span class="n">min_timescale</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">p</span><span class="o">.</span><span class="n">max_timescale</span> <span class="o">=</span> <span class="mi">7</span>
      <span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">4</span>
      <span class="n">seq_length</span> <span class="o">=</span> <span class="mi">11</span>

      <span class="n">pos_emb_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">position_embs</span> <span class="o">=</span> <span class="n">pos_emb_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)</span>
      <span class="n">actual_position_embs</span><span class="p">,</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">position_embs</span><span class="p">])</span>

      <span class="c1"># pylint: disable=bad-whitespace</span>
      <span class="c1"># pyformat: disable</span>
      <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.84147096</span><span class="p">,</span>  <span class="mf">0.14237173</span><span class="p">,</span>  <span class="mf">0.54030228</span><span class="p">,</span>  <span class="mf">0.98981327</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.90929741</span><span class="p">,</span>  <span class="mf">0.28184283</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.41614676</span><span class="p">,</span>  <span class="mf">0.95946062</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.14112</span>   <span class="p">,</span>  <span class="mf">0.4155719</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.9899925</span> <span class="p">,</span>  <span class="mf">0.90956032</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.7568025</span> <span class="p">,</span>  <span class="mf">0.54083425</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.65364361</span><span class="p">,</span>  <span class="mf">0.84112918</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.95892417</span><span class="p">,</span>  <span class="mf">0.65507787</span><span class="p">,</span>  <span class="mf">0.28366217</span><span class="p">,</span>  <span class="mf">0.75556135</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.27941549</span><span class="p">,</span>  <span class="mf">0.75597537</span><span class="p">,</span>  <span class="mf">0.96017027</span><span class="p">,</span>  <span class="mf">0.65460002</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.65698659</span><span class="p">,</span>  <span class="mf">0.84147096</span><span class="p">,</span>  <span class="mf">0.7539022</span> <span class="p">,</span>  <span class="mf">0.54030228</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.98935831</span><span class="p">,</span>  <span class="mf">0.90982294</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14550003</span><span class="p">,</span>  <span class="mf">0.41499668</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.41211855</span><span class="p">,</span>  <span class="mf">0.9596386</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.91113025</span><span class="p">,</span>  <span class="mf">0.28123617</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.54402113</span><span class="p">,</span>  <span class="mf">0.98990309</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.83907151</span><span class="p">,</span>  <span class="mf">0.14174587</span><span class="p">]]</span>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;expected_position_embs:&#39;</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;actual_position_embs:&#39;</span><span class="p">,</span> <span class="n">actual_position_embs</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">actual_position_embs</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testPositionalEmbeddingLayerWithPosition"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testPositionalEmbeddingLayerWithPosition">[docs]</a>  <span class="k">def</span> <span class="nf">testPositionalEmbeddingLayerWithPosition</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;position_emb&#39;</span>
      <span class="n">p</span><span class="o">.</span><span class="n">min_timescale</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">p</span><span class="o">.</span><span class="n">max_timescale</span> <span class="o">=</span> <span class="mi">7</span>
      <span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">4</span>
      <span class="n">pos_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]),</span>
          <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

      <span class="n">pos_emb_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">position_embs</span> <span class="o">=</span> <span class="n">pos_emb_layer</span><span class="o">.</span><span class="n">FPropWithPosition</span><span class="p">(</span><span class="n">pos_emb_layer</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                                                      <span class="n">pos_tensor</span><span class="p">)</span>
      <span class="n">actual_position_embs</span><span class="p">,</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">position_embs</span><span class="p">])</span>

      <span class="c1"># pylint: disable=bad-whitespace,bad-continuation</span>
      <span class="c1"># pyformat: disable</span>
      <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[</span>
          <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">1.</span>       <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.84147096</span><span class="p">,</span>  <span class="mf">0.14237173</span><span class="p">,</span>  <span class="mf">0.54030228</span><span class="p">,</span>  <span class="mf">0.98981327</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.90929741</span><span class="p">,</span>  <span class="mf">0.28184283</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.41614676</span><span class="p">,</span>  <span class="mf">0.95946062</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.14112</span>   <span class="p">,</span>  <span class="mf">0.4155719</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.9899925</span> <span class="p">,</span>  <span class="mf">0.90956032</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.7568025</span> <span class="p">,</span>  <span class="mf">0.54083425</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.65364361</span><span class="p">,</span>  <span class="mf">0.84112918</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.95892417</span><span class="p">,</span>  <span class="mf">0.65507787</span><span class="p">,</span>  <span class="mf">0.28366217</span><span class="p">,</span>  <span class="mf">0.75556135</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.27941549</span><span class="p">,</span>  <span class="mf">0.75597537</span><span class="p">,</span>  <span class="mf">0.96017027</span><span class="p">,</span>  <span class="mf">0.65460002</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.84147096</span><span class="p">,</span>  <span class="mf">0.14237173</span><span class="p">,</span>  <span class="mf">0.54030228</span><span class="p">,</span>  <span class="mf">0.98981327</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.90929741</span><span class="p">,</span>  <span class="mf">0.28184283</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.41614676</span><span class="p">,</span>  <span class="mf">0.95946062</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.14112</span>   <span class="p">,</span>  <span class="mf">0.4155719</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.9899925</span> <span class="p">,</span>  <span class="mf">0.90956032</span><span class="p">]],</span>
          <span class="p">[[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">1.</span>       <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.84147096</span><span class="p">,</span>  <span class="mf">0.14237173</span><span class="p">,</span>  <span class="mf">0.54030228</span><span class="p">,</span>  <span class="mf">0.98981327</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.90929741</span><span class="p">,</span>  <span class="mf">0.28184283</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.41614676</span><span class="p">,</span>  <span class="mf">0.95946062</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.84147096</span><span class="p">,</span>  <span class="mf">0.14237173</span><span class="p">,</span>  <span class="mf">0.54030228</span><span class="p">,</span>  <span class="mf">0.98981327</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.90929741</span><span class="p">,</span>  <span class="mf">0.28184283</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.41614676</span><span class="p">,</span>  <span class="mf">0.95946062</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.14112</span>   <span class="p">,</span>  <span class="mf">0.4155719</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.9899925</span> <span class="p">,</span>  <span class="mf">0.90956032</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.7568025</span> <span class="p">,</span>  <span class="mf">0.54083425</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.65364361</span><span class="p">,</span>  <span class="mf">0.84112918</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.84147096</span><span class="p">,</span>  <span class="mf">0.14237173</span><span class="p">,</span>  <span class="mf">0.54030228</span><span class="p">,</span>  <span class="mf">0.98981327</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">]]</span>
      <span class="p">]</span>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace,bad-continuation</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;expected_position_embs:&#39;</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;actual_position_embs:&#39;</span><span class="p">,</span> <span class="n">actual_position_embs</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">actual_position_embs</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">)</span></div>

<div class="viewcode-block" id="EmbeddingLayerTest.testPositionalEmbeddingLayerWithScaling"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.EmbeddingLayerTest.testPositionalEmbeddingLayerWithScaling">[docs]</a>  <span class="k">def</span> <span class="nf">testPositionalEmbeddingLayerWithScaling</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;position_emb&#39;</span>
      <span class="n">p</span><span class="o">.</span><span class="n">min_timescale</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">p</span><span class="o">.</span><span class="n">max_timescale</span> <span class="o">=</span> <span class="mi">7</span>
      <span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">4</span>
      <span class="n">p</span><span class="o">.</span><span class="n">trainable_scaling</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">p</span><span class="o">.</span><span class="n">trainable_scaling_init</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">)</span>
      <span class="n">seq_length</span> <span class="o">=</span> <span class="mi">11</span>

      <span class="n">pos_emb_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">PositionalEmbeddingLayer</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">position_embs</span> <span class="o">=</span> <span class="n">pos_emb_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">seq_length</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">actual_position_embs</span><span class="p">,</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">position_embs</span><span class="p">])</span>

      <span class="c1"># pylint: disable=bad-whitespace</span>
      <span class="c1"># pyformat: disable</span>
      <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[</span>
          <span class="p">[</span> <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">0.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">,</span>  <span class="mf">1.</span>        <span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.84147096</span><span class="p">,</span>  <span class="mf">0.14237173</span><span class="p">,</span>  <span class="mf">0.54030228</span><span class="p">,</span>  <span class="mf">0.98981327</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.90929741</span><span class="p">,</span>  <span class="mf">0.28184283</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.41614676</span><span class="p">,</span>  <span class="mf">0.95946062</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.14112</span>   <span class="p">,</span>  <span class="mf">0.4155719</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.9899925</span> <span class="p">,</span>  <span class="mf">0.90956032</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.7568025</span> <span class="p">,</span>  <span class="mf">0.54083425</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.65364361</span><span class="p">,</span>  <span class="mf">0.84112918</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.95892417</span><span class="p">,</span>  <span class="mf">0.65507787</span><span class="p">,</span>  <span class="mf">0.28366217</span><span class="p">,</span>  <span class="mf">0.75556135</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.27941549</span><span class="p">,</span>  <span class="mf">0.75597537</span><span class="p">,</span>  <span class="mf">0.96017027</span><span class="p">,</span>  <span class="mf">0.65460002</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.65698659</span><span class="p">,</span>  <span class="mf">0.84147096</span><span class="p">,</span>  <span class="mf">0.7539022</span> <span class="p">,</span>  <span class="mf">0.54030228</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.98935831</span><span class="p">,</span>  <span class="mf">0.90982294</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14550003</span><span class="p">,</span>  <span class="mf">0.41499668</span><span class="p">],</span>
          <span class="p">[</span> <span class="mf">0.41211855</span><span class="p">,</span>  <span class="mf">0.9596386</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.91113025</span><span class="p">,</span>  <span class="mf">0.28123617</span><span class="p">],</span>
          <span class="p">[</span><span class="o">-</span><span class="mf">0.54402113</span><span class="p">,</span>  <span class="mf">0.98990309</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.83907151</span><span class="p">,</span>  <span class="mf">0.14174587</span><span class="p">]]</span>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">),</span>
                          <span class="n">actual_position_embs</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="SoftmaxLayerTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest">[docs]</a><span class="k">class</span> <span class="nc">SoftmaxLayerTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">_RunSimpleFullSoftmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                            <span class="n">num_shards</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">chunk_size</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">class_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">class_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">class_probabilities</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">num_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                            <span class="n">default_qdomain</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">training_step</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                            <span class="n">fprop_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">fprop_dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">fprop_dtype</span> <span class="o">=</span> <span class="n">dtype</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">class_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">class_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">class_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">class_ids</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">class_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">class_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">class_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">class_weights</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">)]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">)]</span>

      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
      <span class="n">params</span><span class="o">.</span><span class="n">fprop_dtype</span> <span class="o">=</span> <span class="n">fprop_dtype</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;softmax&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">10</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">=</span> <span class="n">num_shards</span>
      <span class="n">params</span><span class="o">.</span><span class="n">chunk_size</span> <span class="o">=</span> <span class="n">chunk_size</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">123456</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">default_qdomain</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">params</span><span class="o">.</span><span class="n">qdomain</span><span class="o">.</span><span class="n">default</span> <span class="o">=</span> <span class="n">default_qdomain</span>

      <span class="k">if</span> <span class="n">num_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Turn on sampled soft-max; the asserts need to hold for it to be used.</span>
        <span class="n">params</span><span class="o">.</span><span class="n">num_sampled</span> <span class="o">=</span> <span class="n">num_samples</span>
        <span class="k">assert</span> <span class="n">class_probabilities</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="k">assert</span> <span class="n">chunk_size</span> <span class="ow">is</span> <span class="mi">0</span>
        <span class="k">assert</span> <span class="n">params</span><span class="o">.</span><span class="n">is_eval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">True</span>

      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">softmax</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">xent_loss</span> <span class="o">=</span> <span class="n">softmax</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span>
          <span class="n">softmax</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
          <span class="n">inputs</span><span class="p">,</span>
          <span class="n">class_weights</span><span class="o">=</span><span class="n">class_weights</span><span class="p">,</span>
          <span class="n">class_ids</span><span class="o">=</span><span class="n">class_ids</span><span class="p">,</span>
          <span class="n">class_probabilities</span><span class="o">=</span><span class="n">class_probabilities</span><span class="p">)</span>

      <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">&#39;SimpleFullSoftmax_vars&#39;</span><span class="p">)</span>
      <span class="n">expected_var_names</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_shards</span><span class="p">):</span>
        <span class="n">expected_var_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">u</span><span class="s1">&#39;softmax/weight_</span><span class="si">%d</span><span class="s1">/var:0&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">expected_var_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">u</span><span class="s1">&#39;softmax/bias_</span><span class="si">%d</span><span class="s1">/var:0&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>

      <span class="n">all_var_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">expected_var_names</span><span class="p">),</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">all_var_names</span><span class="p">))</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="k">if</span> <span class="n">training_step</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">step_op</span> <span class="o">=</span> <span class="n">softmax</span><span class="o">.</span><span class="n">PostTrainingStepUpdate</span><span class="p">(</span><span class="n">training_step</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">step_op</span><span class="p">:</span>
          <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">step_op</span><span class="p">])</span>
      <span class="k">return</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">xent_loss</span><span class="p">)</span>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_Sampled"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_Sampled">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_Sampled</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmax</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">12345</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span>
    <span class="n">log_perplexity</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mf">8.654818</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">log_perplexity</span><span class="p">,</span> <span class="mf">3.934008</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span></div>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_SampledAndSharded"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_SampledAndSharded">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_SampledAndSharded</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmax</span><span class="p">(</span>
        <span class="n">num_shards</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">12345</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span>
    <span class="n">log_perplexity</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mf">8.545459</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">log_perplexity</span><span class="p">,</span> <span class="mf">3.884299</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span></div>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_Non2D"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_Non2D">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_Non2D</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmax</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">class_weights</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
        <span class="n">class_ids</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">per_example_xent</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">per_example_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmax</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">class_weights</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
        <span class="n">class_probabilities</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">per_example_xent</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">per_example_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span></div>

  <span class="k">def</span> <span class="nf">_testSimpleFullSoftmax_Basic_Helper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">):</span>
    <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmax</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="o">=</span><span class="n">fprop_dtype</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span>
    <span class="n">log_perplexity</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;log_perplexity&#39;</span><span class="p">,</span> <span class="n">log_perplexity</span><span class="p">])</span>
    <span class="n">err</span> <span class="o">=</span> <span class="mf">1e-5</span>
    <span class="k">if</span> <span class="n">fprop_dtype</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">float16</span> <span class="ow">or</span> <span class="n">fprop_dtype</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">:</span>
      <span class="n">err</span> <span class="o">=</span> <span class="mf">1e-2</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mf">6.22425</span><span class="p">,</span> <span class="n">err</span><span class="o">=</span><span class="n">err</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">log_perplexity</span><span class="p">,</span> <span class="mf">2.8292</span><span class="p">,</span> <span class="n">err</span><span class="o">=</span><span class="n">err</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertAllEqual</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">per_example_argmax</span><span class="p">,</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_Basic_Float32"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_Basic_Float32">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_Basic_Float32</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testSimpleFullSoftmax_Basic_Helper</span><span class="p">(</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></div>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_Basic_Float32Float16"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_Basic_Float32Float16">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_Basic_Float32Float16</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_testSimpleFullSoftmax_Basic_Helper</span><span class="p">(</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span></div>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_Sharded"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_Sharded">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_Sharded</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmax</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span>
    <span class="n">log_perplexity</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;log_perplexity&#39;</span><span class="p">,</span> <span class="n">log_perplexity</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mf">6.14888</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">log_perplexity</span><span class="p">,</span> <span class="mf">2.79495</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span></div>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_Chunked"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_Chunked">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_Chunked</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">chunk_size</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;chunk_size = &#39;</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>
      <span class="n">xent_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmax</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">xent_output</span><span class="o">.</span><span class="n">total_xent</span>
      <span class="n">log_perplexity</span> <span class="o">=</span> <span class="n">xent_output</span><span class="o">.</span><span class="n">avg_xent</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;xent_output &#39;</span><span class="p">,</span> <span class="n">xent_output</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;xent_output.per_example_argmax.dtype &#39;</span><span class="p">,</span>
            <span class="n">xent_output</span><span class="o">.</span><span class="n">per_example_argmax</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mf">6.22425</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">log_perplexity</span><span class="p">,</span> <span class="mf">2.82920</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllEqual</span><span class="p">(</span><span class="n">xent_output</span><span class="o">.</span><span class="n">per_example_argmax</span><span class="p">,</span>
                          <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">xent_output</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span></div>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_Basic_Distributions"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_Basic_Distributions">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_Basic_Distributions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">class_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">class_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)]</span>

      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;softmax&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">10</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">123456</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">softmax</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">xent_loss</span> <span class="o">=</span> <span class="n">softmax</span><span class="o">.</span><span class="n">XentLoss</span><span class="p">(</span>
          <span class="n">inputs</span><span class="p">,</span>
          <span class="n">class_weights</span><span class="o">=</span><span class="n">class_weights</span><span class="p">,</span>
          <span class="n">class_probabilities</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">class_ids</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">num_classes</span><span class="p">))</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span><span class="p">)</span>
      <span class="n">log_perplexity</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">])</span>
      <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;log_perplexity&#39;</span><span class="p">,</span> <span class="n">log_perplexity</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mf">6.22425</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">log_perplexity</span><span class="p">,</span> <span class="mf">2.8292</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span></div>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_GlobalVN"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_GlobalVN">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_GlobalVN</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">class_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">class_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)]</span>

      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;softmax&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">10</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">123456</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">23456</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>
      <span class="n">softmax</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">xent_loss</span> <span class="o">=</span> <span class="n">softmax</span><span class="o">.</span><span class="n">XentLoss</span><span class="p">(</span>
          <span class="n">inputs</span><span class="p">,</span> <span class="n">class_weights</span><span class="o">=</span><span class="n">class_weights</span><span class="p">,</span> <span class="n">class_ids</span><span class="o">=</span><span class="n">class_ids</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span><span class="p">)</span>
      <span class="n">log_perplexity</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;testSimpleFullSoftmax_GlobalVN loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">])</span>
      <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;testSimpleFullSoftmax_GlobalVN log_perplexity&#39;</span><span class="p">,</span> <span class="n">log_perplexity</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mf">19.9612</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">log_perplexity</span><span class="p">,</span> <span class="mf">3.46426</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span></div>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_PerStepVN"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_PerStepVN">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_PerStepVN</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">class_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">class_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)]</span>

      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;softmax&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">10</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">32</span>
      <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">123456</span><span class="p">)</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">23456</span>
      <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>
      <span class="n">softmax</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">xent_loss</span> <span class="o">=</span> <span class="n">softmax</span><span class="o">.</span><span class="n">XentLoss</span><span class="p">(</span>
          <span class="n">inputs</span><span class="p">,</span> <span class="n">class_weights</span><span class="o">=</span><span class="n">class_weights</span><span class="p">,</span> <span class="n">class_ids</span><span class="o">=</span><span class="n">class_ids</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span><span class="p">)</span>
      <span class="n">log_perplexity</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;testShardedFullSoftmax_PerStepVN loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">])</span>
      <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;testShardedFullSoftmax_PerStepVN log_perplexity&#39;</span><span class="p">,</span> <span class="n">log_perplexity</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mf">19.9612</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">log_perplexity</span><span class="p">,</span> <span class="mf">3.46426</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span></div>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmax_FakeQuantized"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmax_FakeQuantized">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmax_FakeQuantized</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">default_qdomain</span> <span class="o">=</span> <span class="n">quant_utils</span><span class="o">.</span><span class="n">SymetricScheduledClipQDomain</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">default_qdomain</span><span class="o">.</span><span class="n">cc_schedule</span> <span class="o">=</span> <span class="n">quant_utils</span><span class="o">.</span><span class="n">FakeQuantizationSchedule</span><span class="o">.</span><span class="n">Params</span><span class="p">(</span>
    <span class="p">)</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
        <span class="n">clip_start_step</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">clip_end_step</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">quant_start_step</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">xent_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmax</span><span class="p">(</span>
        <span class="n">default_qdomain</span><span class="o">=</span><span class="n">default_qdomain</span><span class="p">,</span> <span class="n">training_step</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span>
    <span class="n">log_perplexity</span> <span class="o">=</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">avg_xent</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">([</span><span class="s1">&#39;log_perplexity&#39;</span><span class="p">,</span> <span class="n">log_perplexity</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mf">6.285590</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="n">log_perplexity</span><span class="p">,</span> <span class="mf">2.857086</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">)</span></div>

  <span class="k">def</span> <span class="nf">_RunSimpleFullSoftmaxGradientChecker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span>
                                           <span class="n">chunk_size</span><span class="p">,</span> <span class="n">num_shards</span><span class="p">):</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">use_gpu</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">),</span>
                                        <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">)]:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;dtype </span><span class="si">%s</span><span class="s1"> tolerance </span><span class="si">%g</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">tolerance</span><span class="p">)</span>
      <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="n">use_gpu</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">input_dim</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
        <span class="n">class_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">class_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
        <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;softmax&#39;</span>
        <span class="n">params</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="n">params</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">input_dim</span>
        <span class="n">params</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="n">params</span><span class="o">.</span><span class="n">num_shards</span> <span class="o">=</span> <span class="n">num_shards</span>
        <span class="n">params</span><span class="o">.</span><span class="n">chunk_size</span> <span class="o">=</span> <span class="n">chunk_size</span>
        <span class="n">params</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">123456</span><span class="p">)</span>
        <span class="n">params</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">softmax</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">SimpleFullSoftmax</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">xent_loss</span> <span class="o">=</span> <span class="n">softmax</span><span class="o">.</span><span class="n">XentLoss</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">class_weights</span><span class="o">=</span><span class="n">class_weights</span><span class="p">,</span> <span class="n">class_ids</span><span class="o">=</span><span class="n">class_ids</span><span class="p">)</span>
        <span class="n">softmax_vars</span> <span class="o">=</span> <span class="n">softmax</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="c1"># Now add the backward graph.</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span><span class="p">,</span> <span class="n">softmax_vars</span><span class="p">)</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">softmax_vars</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">grad_x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">softmax_vars</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
          <span class="n">grad_symbolic</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">grad_x</span><span class="p">)</span>
          <span class="n">grad_numeric</span> <span class="o">=</span> <span class="n">test_utils</span><span class="o">.</span><span class="n">ComputeNumericGradient</span><span class="p">(</span>
              <span class="n">sess</span><span class="p">,</span> <span class="n">xent_loss</span><span class="o">.</span><span class="n">total_xent</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
              <span class="n">grad_symbolic</span><span class="p">,</span> <span class="n">grad_numeric</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">tolerance</span><span class="p">)</span>

<div class="viewcode-block" id="SoftmaxLayerTest.testSimpleFullSoftmaxGradientChecker"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.SoftmaxLayerTest.testSimpleFullSoftmaxGradientChecker">[docs]</a>  <span class="k">def</span> <span class="nf">testSimpleFullSoftmaxGradientChecker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmaxGradientChecker</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmaxGradientChecker</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmaxGradientChecker</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_RunSimpleFullSoftmaxGradientChecker</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="FeedForwardNetTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.FeedForwardNetTest">[docs]</a><span class="k">class</span> <span class="nc">FeedForwardNetTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="FeedForwardNetTest.testFeedForwardNetConstruction"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.FeedForwardNetTest.testFeedForwardNetConstruction">[docs]</a>  <span class="k">def</span> <span class="nf">testFeedForwardNetConstruction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FeedForwardNet</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ffn&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">dropout_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
          <span class="n">hidden_layer_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;TANH&#39;</span><span class="p">,</span>
          <span class="n">params_init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
      <span class="n">proj_l</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
      <span class="n">proj_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FeedForwardNet</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ffn2&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">dropout_prob</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
          <span class="n">hidden_layer_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;TANH&#39;</span><span class="p">,</span>
          <span class="n">params_init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
      <span class="n">proj_l</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
      <span class="n">proj_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FeedForwardNet</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ffn3&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">dropout_prob</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
          <span class="n">hidden_layer_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
          <span class="n">activation</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;TANH&#39;</span><span class="p">,</span> <span class="s1">&#39;RELU&#39;</span><span class="p">],</span>
          <span class="n">params_init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
      <span class="n">proj_l</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
      <span class="n">proj_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">)</span></div>

<div class="viewcode-block" id="FeedForwardNetTest.testFeedForwardNet"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.FeedForwardNetTest.testFeedForwardNet">[docs]</a>  <span class="k">def</span> <span class="nf">testFeedForwardNet</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FeedForwardNet</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ffn&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">hidden_layer_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
          <span class="n">dropout_prob</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;RELU&#39;</span><span class="p">,</span> <span class="s1">&#39;NONE&#39;</span><span class="p">])</span>
      <span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Xavier</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">837465638</span><span class="p">)</span>
      <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">params_init</span>
      <span class="n">feedforward_net</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">p1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p1&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">output_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;RELU&#39;</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">p1</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">params_init</span>
      <span class="n">p1_l</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>

      <span class="n">p2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p2&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
          <span class="n">output_dim</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;NONE&#39;</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">p2</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">params_init</span>
      <span class="n">p2_l</span> <span class="o">=</span> <span class="n">p2</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p2</span><span class="p">)</span>

      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">out1</span> <span class="o">=</span> <span class="n">feedforward_net</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

      <span class="n">out2</span> <span class="o">=</span> <span class="n">p2_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">p1_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">out1_v</span><span class="p">,</span> <span class="n">out2_v</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">out1</span><span class="p">,</span> <span class="n">out2</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">out1_v</span><span class="p">,</span> <span class="n">out2_v</span><span class="p">)</span></div>

<div class="viewcode-block" id="FeedForwardNetTest.testFeedForwardNetWithSkipConnections"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.FeedForwardNetTest.testFeedForwardNetWithSkipConnections">[docs]</a>  <span class="k">def</span> <span class="nf">testFeedForwardNetWithSkipConnections</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FeedForwardNet</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ffn&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
          <span class="n">hidden_layer_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span>
          <span class="n">dropout_prob</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;RELU&#39;</span><span class="p">,</span> <span class="s1">&#39;RELU&#39;</span><span class="p">,</span> <span class="s1">&#39;RELU&#39;</span><span class="p">,</span> <span class="s1">&#39;RELU&#39;</span><span class="p">],</span>
          <span class="n">skip_connections</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;ResNet&#39;</span><span class="p">,</span> <span class="s1">&#39;DenseNet&#39;</span><span class="p">,</span> <span class="s1">&#39;DenseNet&#39;</span><span class="p">])</span>
      <span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Xavier</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">837465638</span><span class="p">)</span>
      <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">params_init</span>
      <span class="n">feedforward_net</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">p1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p1&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
          <span class="n">output_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;NONE&#39;</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">p1</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">params_init</span>
      <span class="n">p1_l</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span>
      <span class="n">p_bn1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p1&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">params_init</span><span class="o">=</span><span class="n">params_init</span><span class="p">)</span>
      <span class="n">bn1_l</span> <span class="o">=</span> <span class="n">p_bn1</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p_bn1</span><span class="p">)</span>

      <span class="n">p2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p2&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">output_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;NONE&#39;</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">p2</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">params_init</span>
      <span class="n">p2_l</span> <span class="o">=</span> <span class="n">p2</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p2</span><span class="p">)</span>
      <span class="n">p_bn2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p2&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">params_init</span><span class="o">=</span><span class="n">params_init</span><span class="p">)</span>
      <span class="n">bn2_l</span> <span class="o">=</span> <span class="n">p_bn2</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p_bn2</span><span class="p">)</span>

      <span class="n">p3</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p3&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">output_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;RELU&#39;</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">p3</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">params_init</span>
      <span class="n">p3_l</span> <span class="o">=</span> <span class="n">p3</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p3</span><span class="p">)</span>

      <span class="n">p4</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">ProjectionLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;p4&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
          <span class="n">output_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;RELU&#39;</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">p4</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">params_init</span>
      <span class="n">p4_l</span> <span class="o">=</span> <span class="n">p4</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p4</span><span class="p">)</span>

      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">out1</span> <span class="o">=</span> <span class="n">feedforward_net</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
      <span class="c1"># skip = None</span>
      <span class="n">l1_proj_out</span> <span class="o">=</span> <span class="n">p1_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
      <span class="n">l1_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">bn1_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">l1_proj_out</span><span class="p">))</span>
      <span class="c1"># skip = ResNet</span>
      <span class="n">l2_proj_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">l1_proj_out</span><span class="p">,</span> <span class="n">p2_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">l1_out</span><span class="p">))</span>
      <span class="n">l2_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">bn2_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">l2_proj_out</span><span class="p">))</span>
      <span class="c1"># skip = ResNet</span>
      <span class="n">l3_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">l2_out</span><span class="p">,</span> <span class="n">p3_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">l2_out</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
      <span class="c1"># skip = DenseNet</span>
      <span class="n">out2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">l3_out</span><span class="p">,</span> <span class="n">p4_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">l3_out</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">out1_v</span><span class="p">,</span> <span class="n">out2_v</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">out1</span><span class="p">,</span> <span class="n">out2</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">out1_v</span><span class="p">,</span> <span class="n">out2_v</span><span class="p">)</span></div>

<div class="viewcode-block" id="FeedForwardNetTest.testFeedForwardNetSmokeTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.FeedForwardNetTest.testFeedForwardNetSmokeTest">[docs]</a>  <span class="k">def</span> <span class="nf">testFeedForwardNetSmokeTest</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">FeedForwardNet</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ffn&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">hidden_layer_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
          <span class="n">dropout_prob</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">activation</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;RELU&#39;</span><span class="p">,</span> <span class="s1">&#39;NONE&#39;</span><span class="p">])</span>
      <span class="n">params_init</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Xavier</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">837465638</span><span class="p">)</span>
      <span class="n">p</span><span class="o">.</span><span class="n">params_init</span> <span class="o">=</span> <span class="n">params_init</span>
      <span class="n">feedforward_net</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">feedforward_net</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
      <span class="n">out_abs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">feedforward_net</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">)))</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="c1"># pyformat: disable</span>
      <span class="n">test_utils</span><span class="o">.</span><span class="n">CompareToGoldenSingleFloat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.000002</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>  <span class="c1"># pylint: disable=line-too-long</span>
      <span class="c1"># pyformat: enable</span>
      <span class="n">test_utils</span><span class="o">.</span><span class="n">CompareToGoldenSingleFloat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="mf">126.990379</span><span class="p">,</span> <span class="n">out_abs</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span></div>

<div class="viewcode-block" id="FeedForwardNetTest.testDropoutLayerTrain"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.FeedForwardNetTest.testDropoutLayerTrain">[docs]</a>  <span class="k">def</span> <span class="nf">testDropoutLayerTrain</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">3980847392</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DropoutLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">keep_prob</span> <span class="o">=</span> <span class="mf">0.5</span>
      <span class="n">p</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">1234</span>
      <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;dropout&#39;</span>

      <span class="n">dl</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
      <span class="n">xd</span> <span class="o">=</span> <span class="n">dl</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">xd</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">xd</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertGreater</span><span class="p">((</span><span class="n">xd</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mf">0.3</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertLess</span><span class="p">((</span><span class="n">xd</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mf">0.7</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">xd</span><span class="p">[</span><span class="n">xd</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">xd</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">p</span><span class="o">.</span><span class="n">keep_prob</span><span class="p">)</span></div>

<div class="viewcode-block" id="FeedForwardNetTest.testDropoutLayerEval"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.FeedForwardNetTest.testDropoutLayerEval">[docs]</a>  <span class="k">def</span> <span class="nf">testDropoutLayerEval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">3980847392</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DropoutLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">keep_prob</span> <span class="o">=</span> <span class="mf">0.5</span>
      <span class="n">p</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">1234</span>
      <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;dropout&#39;</span>
      <span class="n">p</span><span class="o">.</span><span class="n">is_eval</span> <span class="o">=</span> <span class="kc">True</span>

      <span class="n">dl</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
      <span class="n">xd</span> <span class="o">=</span> <span class="n">dl</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

      <span class="n">x</span><span class="p">,</span> <span class="n">xd</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">xd</span><span class="p">])</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllEqual</span><span class="p">(</span><span class="n">xd</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="LayerNormTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.LayerNormTest">[docs]</a><span class="k">class</span> <span class="nc">LayerNormTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="LayerNormTest.testLayerNormFProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.LayerNormTest.testLayerNormFProp">[docs]</a>  <span class="k">def</span> <span class="nf">testLayerNormFProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNorm</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;ln&#39;</span>
      <span class="n">p</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">layer_norm</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">npy_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span>
                                   <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dim</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">npy_input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">output</span> <span class="o">=</span> <span class="n">layer_norm</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">sym_output</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

      <span class="c1"># Mean should be zero and variance should be close to one.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sym_output</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="mf">1e-5</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertNear</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">sym_output</span><span class="p">),</span> <span class="mf">1e-4</span><span class="p">)</span>

      <span class="c1"># Compare with numpy.</span>
      <span class="n">mean</span> <span class="o">=</span> <span class="n">npy_input</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">npy_input</span> <span class="o">-</span> <span class="n">mean</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">npy_output</span> <span class="o">=</span> <span class="p">(</span><span class="n">npy_input</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sym_output</span><span class="p">,</span> <span class="n">npy_output</span><span class="p">)</span></div>

<div class="viewcode-block" id="LayerNormTest.testLayerNormBProp"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.LayerNormTest.testLayerNormBProp">[docs]</a>  <span class="k">def</span> <span class="nf">testLayerNormBProp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNorm</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;ln&#39;</span>
      <span class="n">p</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">layer_norm</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span>
          <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">input_dim</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">output</span> <span class="o">=</span> <span class="n">layer_norm</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

      <span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_vars</span><span class="p">))</span>

      <span class="n">grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">sym_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">sg</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="k">for</span> <span class="n">sg</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
      <span class="n">num_grads</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">test_utils</span><span class="o">.</span><span class="n">ComputeNumericGradient</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span>
      <span class="p">]</span>

      <span class="k">for</span> <span class="n">sg</span><span class="p">,</span> <span class="n">ng</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sym_grads</span><span class="p">,</span> <span class="n">num_grads</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">sg</span><span class="p">,</span> <span class="n">ng</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-02</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-02</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="DeterministicDropoutTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.DeterministicDropoutTest">[docs]</a><span class="k">class</span> <span class="nc">DeterministicDropoutTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="DeterministicDropoutTest.testDeterministicDropoutLayer"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.DeterministicDropoutTest.testDeterministicDropoutLayer">[docs]</a>  <span class="k">def</span> <span class="nf">testDeterministicDropoutLayer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DeterministicDropoutLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span><span class="n">keep_prob</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;drop&#39;</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">DeterministicDropoutLayer</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
      <span class="n">global_step</span> <span class="o">=</span> <span class="n">py_utils</span><span class="o">.</span><span class="n">GetOrCreateGlobalStep</span><span class="p">()</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">global_step</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1234</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
      <span class="n">graph</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="s1">&#39;step_seed&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">5678</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>

      <span class="n">x</span> <span class="o">=</span> <span class="n">dropout</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">dropout</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">x_val</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array_repr</span><span class="p">(</span><span class="n">x_val</span><span class="p">))</span>
      <span class="c1"># pyformat: disable</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span>
          <span class="p">[[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.0000000</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.0000000</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">],</span>
           <span class="p">[</span><span class="mf">0.0000000</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.0000000</span><span class="p">,</span> <span class="mf">0.0000000</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.0000000</span><span class="p">]],</span>
          <span class="n">x_val</span><span class="p">)</span></div></div>
      <span class="c1"># pyformat: enable</span>


<div class="viewcode-block" id="GradNormTrackerTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.GradNormTrackerTest">[docs]</a><span class="k">class</span> <span class="nc">GradNormTrackerTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="GradNormTrackerTest.testGradNormTracker"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.GradNormTrackerTest.testGradNormTracker">[docs]</a>  <span class="k">def</span> <span class="nf">testGradNormTracker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GradNormTracker</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;grad_norm_tracker&#39;</span><span class="p">,</span> <span class="n">clip_threshold</span><span class="o">=</span><span class="mf">3.0</span><span class="p">)</span>
      <span class="n">grad_norm_tracker</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">grad_norm_clip</span> <span class="o">=</span> <span class="n">grad_norm_tracker</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">grad_norm</span><span class="p">)</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="n">random_normal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">))</span>
      <span class="c1"># We are expected to reject 16% of the outliers.</span>
      <span class="n">outliers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
      <span class="n">total_rejections</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
          <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">grad_norm_clip</span><span class="p">],</span> <span class="p">{</span><span class="n">grad_norm</span><span class="p">:</span> <span class="n">random_normal</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">+</span> <span class="n">j</span><span class="p">]})</span>
        <span class="n">clip</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">grad_norm_clip</span><span class="p">],</span> <span class="p">{</span><span class="n">grad_norm</span><span class="p">:</span> <span class="n">outliers</span><span class="p">[</span><span class="n">i</span><span class="p">]})[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">clip</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
          <span class="n">total_rejections</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="c1"># Q(yonghui): Why is total_rejections not deterministic?</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total_rejections&#39;</span><span class="p">,</span> <span class="n">total_rejections</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertGreater</span><span class="p">(</span><span class="n">total_rejections</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span></div>

<div class="viewcode-block" id="GradNormTrackerTest.testGradNormTrackerClipCapMin"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.GradNormTrackerTest.testGradNormTrackerClipCapMin">[docs]</a>  <span class="k">def</span> <span class="nf">testGradNormTrackerClipCapMin</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GradNormTracker</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;grad_norm_tracker&#39;</span><span class="p">,</span>
          <span class="n">clip_threshold</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
          <span class="n">grad_norm_clip_cap_min</span><span class="o">=</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">10.0</span><span class="p">))</span>
      <span class="n">grad_norm_tracker</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">grad_norm_clip</span> <span class="o">=</span> <span class="n">grad_norm_tracker</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">grad_norm</span><span class="p">)</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="n">random_normal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">))</span>
      <span class="c1"># We expect no outliers being rejected due to the grad_norm_clip_cap_min.</span>
      <span class="n">outliers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
      <span class="n">total_rejections</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
          <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">grad_norm_clip</span><span class="p">],</span> <span class="p">{</span><span class="n">grad_norm</span><span class="p">:</span> <span class="n">random_normal</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">+</span> <span class="n">j</span><span class="p">]})</span>
        <span class="n">clip</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">grad_norm_clip</span><span class="p">],</span> <span class="p">{</span><span class="n">grad_norm</span><span class="p">:</span> <span class="n">outliers</span><span class="p">[</span><span class="n">i</span><span class="p">]})[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">clip</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
          <span class="n">total_rejections</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;total_rejections&#39;</span><span class="p">,</span> <span class="n">total_rejections</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">total_rejections</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="GradNormTrackerTest.testGradNormTrackerHasNan"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.GradNormTrackerTest.testGradNormTrackerHasNan">[docs]</a>  <span class="k">def</span> <span class="nf">testGradNormTrackerHasNan</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">GradNormTracker</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;grad_norm_tracker&#39;</span><span class="p">,</span> <span class="n">clip_threshold</span><span class="o">=</span><span class="mf">3.0</span><span class="p">)</span>
      <span class="n">grad_norm_tracker</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="n">has_nan</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
      <span class="n">grad_norm_clip</span> <span class="o">=</span> <span class="n">grad_norm_tracker</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">grad_norm</span><span class="p">,</span> <span class="n">has_nan</span><span class="p">)</span>

      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

      <span class="n">random_normal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">))</span>
      <span class="n">outliers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
      <span class="n">total_rejections</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
          <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">grad_norm_clip</span><span class="p">],</span> <span class="p">{</span><span class="n">grad_norm</span><span class="p">:</span> <span class="n">random_normal</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">+</span> <span class="n">j</span><span class="p">]})</span>
        <span class="n">clip</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">grad_norm_clip</span><span class="p">],</span> <span class="p">{</span><span class="n">grad_norm</span><span class="p">:</span> <span class="n">outliers</span><span class="p">[</span><span class="n">i</span><span class="p">]})[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">clip</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
          <span class="n">total_rejections</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">total_rejections</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="HighwaySkipLayerTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.HighwaySkipLayerTest">[docs]</a><span class="k">class</span> <span class="nc">HighwaySkipLayerTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="HighwaySkipLayerTest.testHighwaySkipLayerConstruction"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.HighwaySkipLayerTest.testHighwaySkipLayerConstruction">[docs]</a>  <span class="k">def</span> <span class="nf">testHighwaySkipLayerConstruction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">HighwaySkipLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;gffn&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">carry_bias_init</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
          <span class="n">couple_carry_transform_gates</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
          <span class="n">params_init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
      <span class="n">proj_l</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
      <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
      <span class="n">proj_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span></div>

<div class="viewcode-block" id="HighwaySkipLayerTest.testHighwaySkipLayerCarryGate"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.HighwaySkipLayerTest.testHighwaySkipLayerCarryGate">[docs]</a>  <span class="k">def</span> <span class="nf">testHighwaySkipLayerCarryGate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">398847392</span><span class="p">)</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">HighwaySkipLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span><span class="o">.</span><span class="n">Set</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;gffn&#39;</span><span class="p">,</span>
          <span class="n">input_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
          <span class="n">carry_bias_init</span><span class="o">=</span><span class="mf">1000.0</span><span class="p">,</span>
          <span class="n">couple_carry_transform_gates</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
          <span class="n">params_init</span><span class="o">=</span><span class="n">py_utils</span><span class="o">.</span><span class="n">WeightInit</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
      <span class="n">proj_l</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
      <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
      <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
      <span class="n">out</span> <span class="o">=</span> <span class="n">proj_l</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">a</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">out</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="UniformLabelSmootherTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.UniformLabelSmootherTest">[docs]</a><span class="k">class</span> <span class="nc">UniformLabelSmootherTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="UniformLabelSmootherTest.testUniformLabelSmoother"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.UniformLabelSmootherTest.testUniformLabelSmoother">[docs]</a>  <span class="k">def</span> <span class="nf">testUniformLabelSmoother</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">UniformLabelSmoother</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;uls&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>
      <span class="n">params</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="mf">0.1</span>

      <span class="n">smooth_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">UniformLabelSmoother</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">target_labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">target_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">))</span>
      <span class="n">output</span> <span class="o">=</span> <span class="n">smooth_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">,</span> <span class="n">target_labels</span><span class="p">,</span>
                                              <span class="n">target_ids</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="c1"># pylint: disable=bad-whitespace</span>
      <span class="c1"># pyformat: disable</span>
      <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[[</span>
          <span class="p">[</span><span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.89999998</span><span class="p">]</span>
      <span class="p">]]</span>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace</span>
      <span class="n">output_v</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">output_v</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">output_v</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">output_v</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span></div>

<div class="viewcode-block" id="UniformLabelSmootherTest.testUniformLabelSmootherLargerToken"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.UniformLabelSmootherTest.testUniformLabelSmootherLargerToken">[docs]</a>  <span class="k">def</span> <span class="nf">testUniformLabelSmootherLargerToken</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
      <span class="n">params</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">UniformLabelSmoother</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">params</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;uls&#39;</span>
      <span class="n">params</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">5</span>
      <span class="n">params</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="mf">0.1</span>
      <span class="n">params</span><span class="o">.</span><span class="n">uncertainty_larger</span> <span class="o">=</span> <span class="mf">0.2</span>
      <span class="n">params</span><span class="o">.</span><span class="n">token_id_uncertainty_larger</span> <span class="o">=</span> <span class="mi">4</span>

      <span class="n">smooth_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">UniformLabelSmoother</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
      <span class="n">target_labels</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">target_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
      <span class="n">target_paddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">target_ids</span><span class="p">))</span>
      <span class="n">output</span> <span class="o">=</span> <span class="n">smooth_layer</span><span class="o">.</span><span class="n">FPropDefaultTheta</span><span class="p">(</span><span class="n">target_paddings</span><span class="p">,</span> <span class="n">target_labels</span><span class="p">,</span>
                                              <span class="n">target_ids</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="c1"># pylint: disable=bad-whitespace</span>
      <span class="c1"># pyformat: disable</span>
      <span class="n">expected_output</span> <span class="o">=</span> <span class="p">[[</span>
          <span class="p">[</span><span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">,</span>  <span class="mf">0.89999998</span><span class="p">,</span>  <span class="mf">0.025</span>     <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.05</span>      <span class="p">,</span>  <span class="mf">0.05</span>      <span class="p">,</span>  <span class="mf">0.05</span>      <span class="p">,</span>  <span class="mf">0.80000001</span><span class="p">,</span>  <span class="mf">0.05</span>      <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.05</span>      <span class="p">,</span>  <span class="mf">0.05</span>      <span class="p">,</span>  <span class="mf">0.05</span>      <span class="p">,</span>  <span class="mf">0.80000001</span><span class="p">,</span>  <span class="mf">0.05</span>      <span class="p">],</span>
          <span class="p">[</span><span class="mf">0.05</span>      <span class="p">,</span>  <span class="mf">0.05</span>      <span class="p">,</span>  <span class="mf">0.05</span>      <span class="p">,</span>  <span class="mf">0.80000001</span><span class="p">,</span>  <span class="mf">0.05</span>      <span class="p">]</span>
      <span class="p">]]</span>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace</span>
      <span class="n">output_v</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_output</span><span class="p">,</span> <span class="n">output_v</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">output_v</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">output_v</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="WeightedSumLayerTest"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.WeightedSumLayerTest">[docs]</a><span class="k">class</span> <span class="nc">WeightedSumLayerTest</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>

<div class="viewcode-block" id="WeightedSumLayerTest.testWeightedSumLayer"><a class="viewcode-back" href="../../../lingvo.core.layers_test.html#lingvo.core.layers_test.WeightedSumLayerTest.testWeightedSumLayer">[docs]</a>  <span class="k">def</span> <span class="nf">testWeightedSumLayer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">505837249</span><span class="p">)</span>
      <span class="n">depth</span> <span class="o">=</span> <span class="mi">4</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">n_sources</span> <span class="o">=</span> <span class="mi">3</span>
      <span class="n">ctxs</span> <span class="o">=</span> <span class="p">[[[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">]],</span>
              <span class="p">[[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">]],</span>
              <span class="p">[[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">6.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">]]]</span>
      <span class="n">p</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">WeightedSumLayer</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
      <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;transparent_layer&#39;</span>
      <span class="n">p</span><span class="o">.</span><span class="n">num_sources</span> <span class="o">=</span> <span class="n">n_sources</span>
      <span class="n">p</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">=</span> <span class="mi">505837249</span>
      <span class="n">merger</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">cls</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

      <span class="n">ctxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ctxs</span><span class="p">]</span>
      <span class="n">ctx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">merger</span><span class="o">.</span><span class="n">FProp</span><span class="p">(</span><span class="n">merger</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">ctxs</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
      <span class="n">actual_ctx</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>

      <span class="c1"># pylint: disable=bad-whitespace</span>
      <span class="c1"># pyformat: disable</span>
      <span class="n">expected_ctx</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">2.66666675</span><span class="p">,</span>  <span class="mf">3.66666675</span><span class="p">,</span>  <span class="mf">4.66666698</span><span class="p">,</span>  <span class="mf">5.66666698</span><span class="p">],</span>
                      <span class="p">[</span> <span class="mf">5.0</span><span class="p">,</span>         <span class="mf">6.0</span><span class="p">,</span>         <span class="mf">4.33333349</span><span class="p">,</span>  <span class="mf">5.33333349</span><span class="p">]]</span>
      <span class="c1"># pyformat: enable</span>
      <span class="c1"># pylint: enable=bad-whitespace</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="n">actual_ctx</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">depth</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">assertAllClose</span><span class="p">(</span><span class="n">expected_ctx</span><span class="p">,</span> <span class="n">actual_ctx</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">)</span></div></div>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">main</span><span class="p">()</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>