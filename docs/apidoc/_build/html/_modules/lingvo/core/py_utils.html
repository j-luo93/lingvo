

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lingvo.core.py_utils &mdash; lingvo  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../lingvo.html">lingvo package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>lingvo.core.py_utils</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for lingvo.core.py_utils</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2018 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="sd">&quot;&quot;&quot;Common utilities.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">contextlib</span>
<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">six</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">range</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">zip</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">tensorflow.contrib.model_pruning.python.layers</span> <span class="k">import</span> <span class="n">core_layers</span> <span class="k">as</span> <span class="n">pruning_layers</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib.tpu.python.tpu</span> <span class="k">import</span> <span class="n">tpu_function</span>
<span class="kn">from</span> <span class="nn">tensorflow.core.protobuf</span> <span class="k">import</span> <span class="n">rewriter_config_pb2</span>

<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">hyperparams</span>
<span class="kn">from</span> <span class="nn">lingvo.core</span> <span class="k">import</span> <span class="n">retry</span>
<span class="kn">from</span> <span class="nn">lingvo.core.ops</span> <span class="k">import</span> <span class="n">py_x_ops</span>

<span class="n">tf</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">DEFINE_bool</span><span class="p">(</span><span class="s1">&#39;enable_asserts&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="s1">&#39;If False, we disable all asserts.&#39;</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">DEFINE_bool</span><span class="p">(</span><span class="s1">&#39;enable_check_numerics&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="s1">&#39;If False, we bypass calls to CheckNumerics.&#39;</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">DEFINE_bool</span><span class="p">(</span><span class="s1">&#39;print_debug_tensors&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
                     <span class="s1">&#39;Whether to print debug tensors.&#39;</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">DEFINE_string</span><span class="p">(</span>
    <span class="s1">&#39;xla_device&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;If non-empty, can be cpu, gpu, or tpu (case sensitive)&#39;</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">DEFINE_bool</span><span class="p">(</span>
    <span class="s1">&#39;use_resource_var&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s1">&#39;Use ResourceVariable instead of Variable; this option is &#39;</span>
    <span class="s1">&#39;ignored when xla_device=tpu, as TPU requires resource &#39;</span>
    <span class="s1">&#39;variables&#39;</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">DEFINE_bool</span><span class="p">(</span>
    <span class="s1">&#39;tpu_compatible&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;Create variables in a way compatible with TPU. &#39;</span>
    <span class="s1">&#39;This should be true for any job that will interact &#39;</span>
    <span class="s1">&#39;with variables or a checkpoint that will be produced &#39;</span>
    <span class="s1">&#39;or consumed by TPU&#39;</span><span class="p">)</span>

<span class="n">FLAGS</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">FLAGS</span>

<span class="n">ENQUEUE_OPS</span> <span class="o">=</span> <span class="s1">&#39;__lingvo_enqueue_ops&#39;</span>
<span class="n">CLOSE_QUEUE_OPS</span> <span class="o">=</span> <span class="s1">&#39;__lingvo_close_queue_ops&#39;</span>


<span class="c1"># TODO(syzhang): merge this with summary_utils.scalar().</span>
<div class="viewcode-block" id="_scalar"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._scalar">[docs]</a><span class="k">def</span> <span class="nf">_scalar</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">add_summary</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="Assert"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.Assert">[docs]</a><span class="k">def</span> <span class="nf">Assert</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">Assert</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span></div>


<div class="viewcode-block" id="assert_equal"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.assert_equal">[docs]</a><span class="k">def</span> <span class="nf">assert_equal</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span></div>


<div class="viewcode-block" id="assert_greater_equal"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.assert_greater_equal">[docs]</a><span class="k">def</span> <span class="nf">assert_greater_equal</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">assert_greater_equal</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span></div>


<div class="viewcode-block" id="assert_greater"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.assert_greater">[docs]</a><span class="k">def</span> <span class="nf">assert_greater</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">assert_greater</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span></div>


<div class="viewcode-block" id="assert_less_equal"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.assert_less_equal">[docs]</a><span class="k">def</span> <span class="nf">assert_less_equal</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">assert_less_equal</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span></div>


<div class="viewcode-block" id="assert_less"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.assert_less">[docs]</a><span class="k">def</span> <span class="nf">assert_less</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">assert_less</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span></div>


<div class="viewcode-block" id="assert_between"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.assert_between">[docs]</a><span class="k">def</span> <span class="nf">assert_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span>
      <span class="n">Assert</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">l</span><span class="p">)),</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span>
      <span class="n">Assert</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">)),</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span></div>


<div class="viewcode-block" id="assert_shape_match"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.assert_shape_match">[docs]</a><span class="k">def</span> <span class="nf">assert_shape_match</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="n">filepath</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">extract_stack</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">3</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;msg&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;LINGVO ASSERT </span><span class="si">%s</span><span class="s1">:</span><span class="si">%s</span><span class="s1">(</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span>
        <span class="sa">r</span><span class="s1">&#39;.*/&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">filepath</span><span class="p">),</span> <span class="n">line</span><span class="p">,</span> <span class="n">func</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">py_x_ops</span><span class="o">.</span><span class="n">assert_shape_match</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span></div>


<div class="viewcode-block" id="assert_same_dim0"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.assert_same_dim0">[docs]</a><span class="k">def</span> <span class="nf">assert_same_dim0</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">py_x_ops</span><span class="o">.</span><span class="n">assert_same_dim0</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">no_op</span><span class="p">()</span></div>


<div class="viewcode-block" id="_CheckNumerics"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._CheckNumerics">[docs]</a><span class="k">def</span> <span class="nf">_CheckNumerics</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;name&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;:\d+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_CheckNumerics&#39;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">check_numerics</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">message</span> <span class="k">if</span> <span class="n">message</span> <span class="k">else</span> <span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="CheckNumerics"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.CheckNumerics">[docs]</a><span class="k">def</span> <span class="nf">CheckNumerics</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Check numerics for tensors in inp.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_check_numerics</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">inp</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">_CheckNumerics</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">message</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inp</span><span class="p">]</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">_CheckNumerics</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">message</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inp</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_CheckNumerics</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">message</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="with_dependencies"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.with_dependencies">[docs]</a><span class="k">def</span> <span class="nf">with_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">,</span> <span class="n">output_tensor</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">)</span></div>


<div class="viewcode-block" id="HasRank"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.HasRank">[docs]</a><span class="k">def</span> <span class="nf">HasRank</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">expected_rank</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Syntactic sugar for asserting that tensor has the expected rank.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">expected_rank</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">==</span> <span class="n">expected_rank</span>
    <span class="k">return</span> <span class="n">tensor</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">with_dependencies</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">assert_equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">tensor</span><span class="p">),</span> <span class="n">expected_rank</span><span class="p">)],</span>
                             <span class="n">tensor</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tensor</span></div>


<div class="viewcode-block" id="HasShape"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.HasShape">[docs]</a><span class="k">def</span> <span class="nf">HasShape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">expected_shape</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Syntactic sugar for asserting that tensor has the expected shape.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span><span class="p">:</span>
    <span class="n">filepath</span><span class="p">,</span> <span class="n">line</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">extract_stack</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">3</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;LINGVO ASSERT </span><span class="si">%s</span><span class="s1">:</span><span class="si">%s</span><span class="s1">(</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;.*/&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">filepath</span><span class="p">),</span> <span class="n">line</span><span class="p">,</span>
                                          <span class="n">func</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">with_dependencies</span><span class="p">([</span>
        <span class="n">py_x_ops</span><span class="o">.</span><span class="n">assert_shape_match</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">),</span> <span class="n">expected_shape</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="n">msg</span><span class="p">)</span>
    <span class="p">],</span> <span class="n">tensor</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tensor</span></div>


<div class="viewcode-block" id="GetShape"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.GetShape">[docs]</a><span class="k">def</span> <span class="nf">GetShape</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">ndims</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns tensor&#39;s shape as a list which can be unpacked, unlike tf.shape.</span>

<span class="sd">  Tries to return static shape if it&#39;s available. Note that this means</span>
<span class="sd">  some of the outputs will be ints while the rest will be Tensors.</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: The input tensor.</span>
<span class="sd">    ndims: If not None, returns the shapes for the first `ndims` dimensions.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">ndims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ndims</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span>
    <span class="k">if</span> <span class="n">ndims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">shape</span>
  <span class="k">elif</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">ndims</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">ndims</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span><span class="p">)</span>
  <span class="n">shapes</span> <span class="o">=</span> <span class="p">[</span>
      <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">shape</span><span class="p">[</span><span class="n">x</span><span class="p">]</span>
      <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndims</span><span class="p">)</span>
  <span class="p">]</span>
  <span class="k">return</span> <span class="n">shapes</span></div>


<div class="viewcode-block" id="use_xla"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.use_xla">[docs]</a><span class="k">def</span> <span class="nf">use_xla</span><span class="p">():</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="n">res</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">xla_device</span>
  <span class="k">if</span> <span class="n">res</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">xla_device</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="s1">&#39;gpu&#39;</span><span class="p">,</span> <span class="s1">&#39;tpu&#39;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="use_tpu"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.use_tpu">[docs]</a><span class="k">def</span> <span class="nf">use_tpu</span><span class="p">():</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="n">res</span> <span class="o">=</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">xla_device</span> <span class="o">==</span> <span class="s1">&#39;tpu&#39;</span>
  <span class="k">if</span> <span class="n">res</span><span class="p">:</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">enable_asserts</span>  <span class="c1"># asserts not supported on tpu</span>
  <span class="k">return</span> <span class="n">res</span></div>


<div class="viewcode-block" id="tpu_compat"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.tpu_compat">[docs]</a><span class="k">def</span> <span class="nf">tpu_compat</span><span class="p">():</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">return</span> <span class="n">use_tpu</span><span class="p">()</span> <span class="ow">or</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">tpu_compatible</span></div>


<div class="viewcode-block" id="use_resource_variables"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.use_resource_variables">[docs]</a><span class="k">def</span> <span class="nf">use_resource_variables</span><span class="p">():</span>  <span class="c1"># pylint: disable=invalid-name</span>
  <span class="k">return</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">use_resource_var</span> <span class="ow">or</span> <span class="n">tpu_compat</span><span class="p">()</span></div>


<div class="viewcode-block" id="outside_all_rewrites"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.outside_all_rewrites">[docs]</a><span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">outside_all_rewrites</span><span class="p">():</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">yield</span></div>


<span class="n">_tpu_device_assignment</span> <span class="o">=</span> <span class="kc">None</span>


<div class="viewcode-block" id="SetTpuDeviceAssignment"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.SetTpuDeviceAssignment">[docs]</a><span class="k">def</span> <span class="nf">SetTpuDeviceAssignment</span><span class="p">(</span><span class="n">tpu_device_assignment</span><span class="p">):</span>
  <span class="k">global</span> <span class="n">_tpu_device_assignment</span>
  <span class="k">assert</span> <span class="n">_tpu_device_assignment</span> <span class="ow">is</span> <span class="kc">None</span>
  <span class="n">_tpu_device_assignment</span> <span class="o">=</span> <span class="n">tpu_device_assignment</span></div>


<span class="c1"># This function should called in unittest only.</span>
<div class="viewcode-block" id="ClearTpuDevice"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ClearTpuDevice">[docs]</a><span class="k">def</span> <span class="nf">ClearTpuDevice</span><span class="p">():</span>
  <span class="k">global</span> <span class="n">_tpu_device_assignment</span>
  <span class="n">_tpu_device_assignment</span> <span class="o">=</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="GetTpuDeviceAssignment"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.GetTpuDeviceAssignment">[docs]</a><span class="k">def</span> <span class="nf">GetTpuDeviceAssignment</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">_tpu_device_assignment</span></div>


<div class="viewcode-block" id="SessionConfig"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.SessionConfig">[docs]</a><span class="k">def</span> <span class="nf">SessionConfig</span><span class="p">(</span><span class="n">soft_placement</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a session config proto.</span>

<span class="sd">  Args:</span>
<span class="sd">    soft_placement: Turns allow_soft_placement on iff True.</span>
<span class="sd">    inline: Turns do_function_inlining on iff True.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A TF session config proto.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">session_config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">(</span>
      <span class="n">allow_soft_placement</span><span class="o">=</span><span class="n">soft_placement</span><span class="p">,</span>
      <span class="n">graph_options</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphOptions</span><span class="p">(</span>
          <span class="n">optimizer_options</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">OptimizerOptions</span><span class="p">(</span>
              <span class="n">opt_level</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">OptimizerOptions</span><span class="o">.</span><span class="n">L1</span><span class="p">,</span> <span class="n">do_function_inlining</span><span class="o">=</span><span class="n">inline</span><span class="p">)))</span>
  <span class="c1"># Disable layout optimizer which increases GPU memory usage.</span>
  <span class="n">session_config</span><span class="o">.</span><span class="n">graph_options</span><span class="o">.</span><span class="n">rewrite_options</span><span class="o">.</span><span class="n">layout_optimizer</span> <span class="o">=</span> <span class="p">(</span>
      <span class="n">rewriter_config_pb2</span><span class="o">.</span><span class="n">RewriterConfig</span><span class="o">.</span><span class="n">OFF</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">session_config</span></div>


<span class="n">_NAME_PATTERN</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;[A-Za-z_][A-Za-z0-9_]*&#39;</span><span class="p">)</span>


<div class="viewcode-block" id="NestedMap"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap">[docs]</a><span class="k">class</span> <span class="nc">NestedMap</span><span class="p">(</span><span class="nb">dict</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A simpler helper to maintain a dict.</span>

<span class="sd">  E.g.::</span>

<span class="sd">      &gt;&gt;&gt; foo = NestedMap()</span>
<span class="sd">      &gt;&gt;&gt; foo[&#39;x&#39;] = 10</span>
<span class="sd">      &gt;&gt;&gt; foo.y = 20</span>
<span class="sd">      &gt;&gt;&gt; assert foo.x * 2 == foo.y</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># Disable pytype attribute checking.</span>
  <span class="n">_HAS_DYNAMIC_ATTRIBUTES</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">NestedMap</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span> <span class="o">=</span> <span class="bp">self</span>

  <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">NestedMap</span><span class="o">.</span><span class="n">CheckKey</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">NestedMap</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">__getattribute__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper to help user know what available attributes are.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">NestedMap</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
          <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">; available attributes: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

<div class="viewcode-block" id="NestedMap.copy"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.copy">[docs]</a>  <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># Don&#39;t delegate w/ super: dict.copy() -&gt; dict.</span>
    <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)(</span><span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="NestedMap.DeepCopy"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.DeepCopy">[docs]</a>  <span class="k">def</span> <span class="nf">DeepCopy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">flat_v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">flat_v</span><span class="p">)</span></div>

<div class="viewcode-block" id="NestedMap.CheckKey"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.CheckKey">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">CheckKey</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Asserts that key is valid NestedMap key.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">)</span> <span class="ow">and</span> <span class="n">_NAME_PATTERN</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">key</span></div>

<div class="viewcode-block" id="NestedMap.Flatten"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.Flatten">[docs]</a>  <span class="k">def</span> <span class="nf">Flatten</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Flatten the nested map and returns values in a list.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">Expand</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">:</span>
          <span class="n">ret</span> <span class="o">+=</span> <span class="n">Expand</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">v</span><span class="p">]</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
      <span class="n">ret</span> <span class="o">+=</span> <span class="n">Expand</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="NestedMap.FlattenItems"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.FlattenItems">[docs]</a>  <span class="k">def</span> <span class="nf">FlattenItems</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Flatten the nested map and returns &lt;key, value&gt; pairs in a list.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of &lt;key, value&gt; pairs, where keys for nested entries will be</span>
<span class="sd">      represented in the form of `foo.bar`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">Expand</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
          <span class="n">global_key</span> <span class="o">=</span> <span class="n">key</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span> <span class="o">+</span> <span class="n">k</span> <span class="k">if</span> <span class="n">key</span> <span class="k">else</span> <span class="n">k</span>
          <span class="n">ret</span> <span class="o">+=</span> <span class="n">Expand</span><span class="p">(</span><span class="n">global_key</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">ret</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">:</span>
          <span class="n">ret</span> <span class="o">+=</span> <span class="n">Expand</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[(</span><span class="n">key</span><span class="p">,</span> <span class="n">v</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">Expand</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span></div>

<div class="viewcode-block" id="NestedMap.Transform"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.Transform">[docs]</a>  <span class="k">def</span> <span class="nf">Transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a copy of this NestedMap with fn applied on each value.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">DoTransform</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">:</span>
          <span class="n">ret</span> <span class="o">+=</span> <span class="p">[</span><span class="n">DoTransform</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">ret</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="n">NestedMap</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
      <span class="n">ret</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">DoTransform</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="NestedMap.Filter"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.Filter">[docs]</a>  <span class="k">def</span> <span class="nf">Filter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a copy of this NestedMap with entries that fn(entry) is True.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">DoFilter</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">Filter</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">lst</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">:</span>
          <span class="n">filtered</span> <span class="o">=</span> <span class="n">DoFilter</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">filtered</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lst</span> <span class="o">+=</span> <span class="p">[</span><span class="n">filtered</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">lst</span> <span class="k">if</span> <span class="n">lst</span> <span class="k">else</span> <span class="kc">None</span>
      <span class="k">elif</span> <span class="n">fn</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">v</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="n">ret</span> <span class="o">=</span> <span class="n">NestedMap</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
      <span class="n">filtered</span> <span class="o">=</span> <span class="n">DoFilter</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
      <span class="k">if</span> <span class="n">filtered</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ret</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">filtered</span>

    <span class="k">return</span> <span class="n">ret</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="NestedMap.Pack"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.Pack">[docs]</a>  <span class="k">def</span> <span class="nf">Pack</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lst</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a copy of this with each value replaced by a value in lst.&quot;&quot;&quot;</span>

    <span class="k">class</span> <span class="nc">DoPack</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

      <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lst</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span>

      <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">del</span> <span class="n">x</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_iter</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="n">DoPack</span><span class="p">(</span><span class="n">lst</span><span class="p">))</span></div>

<div class="viewcode-block" id="NestedMap.IsCompatible"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.IsCompatible">[docs]</a>  <span class="k">def</span> <span class="nf">IsCompatible</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns true if self and other is compatible.</span>

<span class="sd">    Args:</span>
<span class="sd">      other: Another NestedMap.</span>

<span class="sd">    If x and y are two compatible `.NestedMap`, `x.Pack(y.Flatten())`</span>
<span class="sd">    produces y and `y.Pack(x.Flatten())` produces x.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">DoCompare</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Compares x and y.&quot;&quot;&quot;</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">):</span>
          <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">!=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
          <span class="k">return</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="n">DoCompare</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">k</span><span class="p">]):</span>
            <span class="k">return</span> <span class="kc">False</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
          <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
          <span class="k">return</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="n">DoCompare</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
      <span class="k">return</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="n">DoCompare</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span></div>

<div class="viewcode-block" id="NestedMap.DebugString"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NestedMap.DebugString">[docs]</a>  <span class="k">def</span> <span class="nf">DebugString</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a debug string for this nested map.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">Print</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Recursively walk value.&quot;&quot;&quot;</span>
      <span class="n">ret</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
          <span class="k">if</span> <span class="n">prefix</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">k</span>
          <span class="n">ret</span> <span class="o">+=</span> <span class="n">Print</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
          <span class="n">ret</span> <span class="o">+=</span> <span class="n">Print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">[</span><span class="si">%d</span><span class="s1">]&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">i</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">+=</span> <span class="p">[(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">value</span><span class="p">)]</span>
      <span class="k">return</span> <span class="n">ret</span>

    <span class="n">kv</span> <span class="o">=</span> <span class="n">Print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>
    <span class="n">maxlen</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">kv</span><span class="p">])</span> <span class="k">if</span> <span class="n">kv</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">strs</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">*</span> <span class="p">(</span><span class="mi">4</span> <span class="o">+</span> <span class="n">maxlen</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">k</span><span class="p">))</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kv</span><span class="p">]</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">strs</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="_Unique"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._Unique">[docs]</a><span class="k">class</span> <span class="nc">_Unique</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A helper to uniqify variables in a NestedMap.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_vset</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_vset</span><span class="p">):</span>
      <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_vset</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
      <span class="k">return</span> <span class="kc">True</span></div>


<div class="viewcode-block" id="ToUniqueList"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ToUniqueList">[docs]</a><span class="k">def</span> <span class="nf">ToUniqueList</span><span class="p">(</span><span class="n">nmap</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the flattened `nmap` with duplicates removed.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">nmap</span><span class="o">.</span><span class="n">Filter</span><span class="p">(</span><span class="n">_Unique</span><span class="p">())</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span></div>


<div class="viewcode-block" id="ReadOnlyAttrDictView"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ReadOnlyAttrDictView">[docs]</a><span class="k">def</span> <span class="nf">ReadOnlyAttrDictView</span><span class="p">(</span><span class="n">backing</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Wraps a dict to provide a read-only view of its contents.</span>

<span class="sd">  Dict keys can also be accessed by attribute.</span>

<span class="sd">  Args:</span>
<span class="sd">    backing: Dict-like object to wrap.</span>
<span class="sd">  Returns:</span>
<span class="sd">    Read-only Mapping that can be accessed by index ([&#39;foo&#39;]) or attr (d.foo).</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">class</span> <span class="nc">Wrapper</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper object.&quot;&quot;&quot;</span>

    <span class="c1"># Disable pytype attribute checking.</span>
    <span class="n">_HAS_DYNAMIC_ATTRIBUTES</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">backing</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">backing</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="n">backing</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">backing</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__hasattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">backing</span>

    <span class="k">def</span> <span class="nf">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;Dictionary is read-only.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;Dictionary is read-only.&#39;</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">Wrapper</span><span class="p">()</span></div>


<div class="viewcode-block" id="WeightInit"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit">[docs]</a><span class="k">class</span> <span class="nc">WeightInit</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Static class providing weight initialization config params.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="WeightInit._Params"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit._Params">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">_Params</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;method&#39;</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="s1">&#39;Initialization method.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="s1">&#39;Initialization scale.&#39;</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="s1">&#39;Random seed used to generate initial values.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p</span></div>

<div class="viewcode-block" id="WeightInit.Gaussian"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit.Gaussian">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">Gaussian</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;scale * tf.random_normal(0, 1.0).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">_Params</span><span class="p">(</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></div>

<div class="viewcode-block" id="WeightInit.Uniform"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit.Uniform">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">Uniform</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;scale * tf.random_uniform(-1.0, 1.0).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">_Params</span><span class="p">(</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></div>

<div class="viewcode-block" id="WeightInit.Xavier"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit.Xavier">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">Xavier</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Xavier initialization (x = sqrt(6. / (in + out)); [-x, x]).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">_Params</span><span class="p">(</span><span class="s1">&#39;xavier&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></div>

<div class="viewcode-block" id="WeightInit.Constant"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit.Constant">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">Constant</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;scale.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">_Params</span><span class="p">(</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="WeightInit.TruncatedGaussian"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit.TruncatedGaussian">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">TruncatedGaussian</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;scale * tf.truncated_normal(0, 1.0).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">_Params</span><span class="p">(</span><span class="s1">&#39;truncated_gaussian&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></div>

<div class="viewcode-block" id="WeightInit.GaussianSqrtDim"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit.GaussianSqrtDim">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">GaussianSqrtDim</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;scale * tf.random_normal(0, 1 / sqrt(dim0)).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">_Params</span><span class="p">(</span><span class="s1">&#39;gaussian_sqrt_dim&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></div>

<div class="viewcode-block" id="WeightInit.UniformSqrtDim"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit.UniformSqrtDim">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">UniformSqrtDim</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;scale * tf.uniform(-1 / sqrt(dim0), 1 / sqrt(dim0)).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">_Params</span><span class="p">(</span><span class="s1">&#39;uniform_sqrt_dim&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></div>

<div class="viewcode-block" id="WeightInit.UniformUnitScaling"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit.UniformUnitScaling">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">UniformUnitScaling</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;scale * sqrt(3) / sqrt(dim0) * tf.uniform(-1, 1).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">_Params</span><span class="p">(</span><span class="s1">&#39;uniform_unit_scaling&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></div>

<div class="viewcode-block" id="WeightInit.TruncatedGaussianSqrtDim"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightInit.TruncatedGaussianSqrtDim">[docs]</a>  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">TruncatedGaussianSqrtDim</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;scale * tf.truncated_normal(0, 1 / sqrt(dim0)).&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">_Params</span><span class="p">(</span><span class="s1">&#39;truncated_gaussian_sqrt_dim&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></div></div>


<span class="n">_DEFAULT_XAVIER_INIT</span> <span class="o">=</span> <span class="mf">1.000001</span>


<div class="viewcode-block" id="DefaultParamInit"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.DefaultParamInit">[docs]</a><span class="k">def</span> <span class="nf">DefaultParamInit</span><span class="p">():</span>
  <span class="c1"># Here we use 1.000001 as a signature for user picking up the</span>
  <span class="c1"># default param initializer.</span>
  <span class="k">return</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">Xavier</span><span class="p">(</span><span class="n">_DEFAULT_XAVIER_INIT</span><span class="p">)</span></div>


<div class="viewcode-block" id="IsDefaultParamInit"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.IsDefaultParamInit">[docs]</a><span class="k">def</span> <span class="nf">IsDefaultParamInit</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;xavier&#39;</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">scale</span> <span class="o">==</span> <span class="n">_DEFAULT_XAVIER_INIT</span> <span class="ow">and</span>
          <span class="n">p</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span></div>


<div class="viewcode-block" id="WeightParams"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightParams">[docs]</a><span class="k">def</span> <span class="nf">WeightParams</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">collections</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a hyperparams for a weight variable given the shape/init/dtype.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">Xavier</span><span class="p">(</span><span class="n">_DEFAULT_XAVIER_INIT</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
  <span class="k">if</span> <span class="n">collections</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">collections</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
  <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;dtype&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="s1">&#39;The weight data type.&#39;</span><span class="p">)</span>
  <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;shape&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="s1">&#39;The weight shape.&#39;</span><span class="p">)</span>
  <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;init&#39;</span><span class="p">,</span> <span class="n">init</span><span class="p">,</span> <span class="s1">&#39;Initialization method.&#39;</span><span class="p">)</span>
  <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;collections&#39;</span><span class="p">,</span> <span class="n">collections</span><span class="p">,</span>
           <span class="s1">&#39;Variable collections this weight belongs to.&#39;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">p</span></div>


<div class="viewcode-block" id="FindNeeded"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.FindNeeded">[docs]</a><span class="k">def</span> <span class="nf">FindNeeded</span><span class="p">(</span><span class="n">endpoints</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;List names of tensors and operations required to compute endpoints.&quot;&quot;&quot;</span>
  <span class="n">names_seen</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
  <span class="n">queue</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">endpoints</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Operation</span><span class="p">):</span>
      <span class="n">queue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">queue</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
  <span class="k">while</span> <span class="n">queue</span><span class="p">:</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">queue</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">name</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">names_seen</span><span class="p">:</span>
      <span class="n">names_seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
      <span class="n">names_seen</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">o</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">outputs</span><span class="p">))</span>
      <span class="n">queue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">op</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>
      <span class="n">queue</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">control_inputs</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">names_seen</span></div>


<div class="viewcode-block" id="FindNeededInList"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.FindNeededInList">[docs]</a><span class="k">def</span> <span class="nf">FindNeededInList</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">,</span> <span class="n">endpoints</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return tensors from tensor_list needed to compute any of endpoints.&quot;&quot;&quot;</span>
  <span class="n">all_needed</span> <span class="o">=</span> <span class="n">FindNeeded</span><span class="p">(</span><span class="n">endpoints</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tensor_list</span> <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">all_needed</span><span class="p">]</span></div>


<div class="viewcode-block" id="_CollectionGetter"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._CollectionGetter">[docs]</a><span class="k">class</span> <span class="nc">_CollectionGetter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get graph local value from a defined collection.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">default_factory</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_key</span> <span class="o">=</span> <span class="n">key</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_factory</span> <span class="o">=</span> <span class="n">default_factory</span>

  <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">collection</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_key</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">collection</span><span class="p">:</span>
      <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">collection</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
      <span class="k">return</span> <span class="n">collection</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_factory</span><span class="p">()</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">value</span></div>


<span class="c1"># Global variable to control multitask variable reuse</span>
<span class="c1"># If False (default) the default tf.get_variable is used, that is:</span>
<span class="c1"># - Reusing scopes only allow getting existing variables</span>
<span class="c1"># - Non-reusing scopes only allow getting new variables</span>
<span class="c1"># With OPPORTUNISTIC_VARIABLE_REUSE==True:</span>
<span class="c1"># - Reusing scopes only allow getting existing variables, as usual</span>
<span class="c1"># - Non-reusing scopes reuse new variables or get new ones</span>
<span class="n">_OPPORTUNISTIC_VARIABLE_REUSE_KEY</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;__lingvo_opportunistic_variable_reuse&#39;</span><span class="p">,)</span>

<span class="n">_get_opportunistic_variable_reuse</span> <span class="o">=</span> <span class="n">_CollectionGetter</span><span class="p">(</span>
    <span class="n">_OPPORTUNISTIC_VARIABLE_REUSE_KEY</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">])</span>

<span class="n">_VARIABLE_RENAME_RULES_KEY</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;__lingvo_variable_rename_rules&#39;</span><span class="p">,)</span>

<span class="n">_get_rename_rules_stack</span> <span class="o">=</span> <span class="n">_CollectionGetter</span><span class="p">(</span><span class="n">_VARIABLE_RENAME_RULES_KEY</span><span class="p">,</span>
                                            <span class="k">lambda</span><span class="p">:</span> <span class="p">[])</span>


<div class="viewcode-block" id="OpportunisticVariableReuseScope"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.OpportunisticVariableReuseScope">[docs]</a><span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">OpportunisticVariableReuseScope</span><span class="p">(</span><span class="n">enable_opportunistic_reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="n">opportunistic_var_reuse</span> <span class="o">=</span> <span class="n">_get_opportunistic_variable_reuse</span><span class="p">()</span>
  <span class="n">old_val</span> <span class="o">=</span> <span class="n">opportunistic_var_reuse</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">opportunistic_var_reuse</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">enable_opportunistic_reuse</span>
  <span class="k">yield</span>
  <span class="n">opportunistic_var_reuse</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_val</span></div>


<div class="viewcode-block" id="VariableRenameScope"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.VariableRenameScope">[docs]</a><span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">VariableRenameScope</span><span class="p">(</span><span class="n">renames</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Append the renaming rules to the stack of renames.</span>

<span class="sd">  Args:</span>
<span class="sd">    renames: pairs of (regexp, new_name_format). If the regexp matches,</span>
<span class="sd">      the new_name_format will be interpolated using the matched groups.</span>

<span class="sd">  Yields:</span>
<span class="sd">    scope in which the renaming rules are applied</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">rename_rules_stack</span> <span class="o">=</span> <span class="n">_get_rename_rules_stack</span><span class="p">()</span>
  <span class="n">rename_rules_stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">renames</span><span class="p">)</span>
  <span class="k">yield</span>
  <span class="n">rename_rules_stack</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span></div>


<div class="viewcode-block" id="GetVariableName"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.GetVariableName">[docs]</a><span class="k">def</span> <span class="nf">GetVariableName</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Get variable name after application of all renaming rules.</span>

<span class="sd">  Args:</span>
<span class="sd">    name: untransformed variable name with scope_name prepended</span>

<span class="sd">  Returns:</span>
<span class="sd">    name possibly modified using renaming rules</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">matched</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="n">new_name</span> <span class="o">=</span> <span class="n">name</span>
  <span class="k">for</span> <span class="n">renames</span> <span class="ow">in</span> <span class="n">_get_rename_rules_stack</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">regexp</span><span class="p">,</span> <span class="n">name_format</span> <span class="ow">in</span> <span class="n">renames</span><span class="p">:</span>
      <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">regexp</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">matched</span><span class="p">:</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Multiple matches for: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="n">matched</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">new_name</span> <span class="o">=</span> <span class="n">name_format</span> <span class="o">%</span> <span class="n">match</span><span class="o">.</span><span class="n">groups</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">new_name</span> <span class="o">!=</span> <span class="n">name</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;WARNING!!! Renaming variable &#39;</span><span class="si">%s</span><span class="s2">&#39; to &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">new_name</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">new_name</span></div>


<div class="viewcode-block" id="GenerateSeedFromName"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.GenerateSeedFromName">[docs]</a><span class="k">def</span> <span class="nf">GenerateSeedFromName</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate a random seed from a name string.&quot;&quot;&quot;</span>
  <span class="n">md5</span> <span class="o">=</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">()</span>
  <span class="n">md5</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
  <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">md5</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">(),</span> <span class="mi">16</span><span class="p">)</span> <span class="o">%</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">31</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span></div>


<span class="c1"># To keep track of all the variables ever gets created by the CreateVariable</span>
<span class="c1"># routine below.</span>
<span class="n">_ALL_VARS_KEY</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;__lingvo_all_vars&#39;</span><span class="p">,)</span>

<span class="n">_get_all_vars</span> <span class="o">=</span> <span class="n">_CollectionGetter</span><span class="p">(</span><span class="n">_ALL_VARS_KEY</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="p">{})</span>


<span class="c1"># TODO(yonghui): Add support for partitioned Variables.</span>
<div class="viewcode-block" id="CreateVariable"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.CreateVariable">[docs]</a><span class="k">def</span> <span class="nf">CreateVariable</span><span class="p">(</span><span class="n">name</span><span class="p">,</span>
                   <span class="n">params</span><span class="p">,</span>
                   <span class="n">reuse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">init_wrapper</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">collections</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates tf.Variable according to param_config.</span>

<span class="sd">  Args:</span>
<span class="sd">    name: A string, name of the variable.</span>
<span class="sd">    params: A WeightParams specifying the details of how</span>
<span class="sd">        this variable should be constructed and initialized.</span>
<span class="sd">    reuse: Whether or not to reuse an existing variable. It has the same</span>
<span class="sd">        semantics as the reuse arg in tf.variable_scope.</span>
<span class="sd">    trainable: Whether or not the variable is trainable.</span>
<span class="sd">    init_wrapper: a callback which takes a tf initializer callable and returns</span>
<span class="sd">        a tensor. It is used when shape of the variable isn&#39;t statically</span>
<span class="sd">        determinable.</span>
<span class="sd">    collections: Override the default variable collection (</span>
<span class="sd">      tf.GraphKeys.GLOBAL_VARIABLES).</span>
<span class="sd">  Returns:</span>
<span class="sd">    tf.identity(var), var pair. The tf.identity() node is colocated</span>
<span class="sd">    with var.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
  <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">)</span>
  <span class="n">dtype</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">dtype</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span>
  <span class="n">dim0</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">if</span> <span class="n">shape</span><span class="p">:</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="n">dim_size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">dim_size</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">]),</span> <span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">shape</span><span class="p">)</span>
    <span class="n">dim0</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">scale</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;constant&#39;</span>
  <span class="n">method</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">method</span>
  <span class="n">scale</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">scale</span>
  <span class="n">seed</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">seed</span>

  <span class="k">if</span> <span class="n">IsDefaultParamInit</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">init</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
        <span class="s1">&#39;WARNING!!! var </span><span class="si">%s</span><span class="s1"> is using the default xavier initializer.&#39;</span>
        <span class="s1">&#39; Make sure this is intended.&#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="c1"># We are in a program/test which need determistic randomization.</span>
    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># We are not given a per-variable random seed. We use hash of</span>
      <span class="c1"># variable name as a stable random seed.</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
        <span class="n">var_name</span> <span class="o">=</span> <span class="n">GetVariableName</span><span class="p">(</span><span class="n">scope</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="n">seed</span> <span class="o">=</span> <span class="n">GenerateSeedFromName</span><span class="p">(</span><span class="n">var_name</span><span class="p">)</span>

  <span class="k">if</span> <span class="p">(</span><span class="n">method</span> <span class="ow">in</span> <span class="p">[</span>
      <span class="s1">&#39;gaussian_sqrt_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform_sqrt_dim&#39;</span><span class="p">,</span> <span class="s1">&#39;truncated_gaussian_sqrt_dim&#39;</span>
  <span class="p">]):</span>
    <span class="n">scale</span> <span class="o">*=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dim0</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;gaussian&#39;</span><span class="p">,</span> <span class="s1">&#39;gaussian_sqrt_dim&#39;</span><span class="p">]:</span>
    <span class="n">v_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal_initializer</span><span class="p">(</span>
        <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">elif</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform_sqrt_dim&#39;</span><span class="p">]:</span>
    <span class="n">v_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">(</span>
        <span class="n">minval</span><span class="o">=-</span><span class="n">scale</span><span class="p">,</span> <span class="n">maxval</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">elif</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;uniform_unit_scaling&#39;</span><span class="p">]:</span>
    <span class="n">v_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">uniform_unit_scaling_initializer</span><span class="p">(</span>
        <span class="n">factor</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">elif</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;truncated_gaussian&#39;</span><span class="p">,</span> <span class="s1">&#39;truncated_gaussian_sqrt_dim&#39;</span><span class="p">]:</span>
    <span class="n">v_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span>
        <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">elif</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;constant&#39;</span><span class="p">]:</span>
    <span class="n">v_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">elif</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;xavier&#39;</span><span class="p">]:</span>
    <span class="c1"># pylint: disable=unused-argument</span>
    <span class="k">def</span> <span class="nf">XavierUniform</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">partition_info</span><span class="p">):</span>
      <span class="sd">&quot;&quot;&quot;Xavier initialization (x = sqrt(6. / (in + out)); scale*[-x, x]).&quot;&quot;&quot;</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">shape</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;</span><span class="se">\&#39;</span><span class="s1">shape</span><span class="se">\&#39;</span><span class="s1"> must not be </span><span class="se">\&#39;</span><span class="s1">None</span><span class="se">\&#39;</span><span class="s1"> or 0 for XavierUniform&#39;</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">receptive_field_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]:</span>
          <span class="n">receptive_field_size</span> <span class="o">*=</span> <span class="n">s</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">receptive_field_size</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">receptive_field_size</span>
      <span class="n">limit</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">6.</span> <span class="o">/</span> <span class="p">(</span><span class="n">fan_in</span> <span class="o">+</span> <span class="n">fan_out</span><span class="p">))</span>
      <span class="k">return</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="o">-</span><span class="n">limit</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>

    <span class="c1"># pylint: enable=unused-argument</span>
    <span class="n">v_init</span> <span class="o">=</span> <span class="n">XavierUniform</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;init_type not supported.&#39;</span>
  <span class="k">if</span> <span class="n">init_wrapper</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;Expecting </span><span class="se">\&#39;</span><span class="s1">params.shape</span><span class="se">\&#39;</span><span class="s1"> being None when &#39;</span>
        <span class="s1">&#39;</span><span class="se">\&#39;</span><span class="s1">init_wrapper</span><span class="se">\&#39;</span><span class="s1"> is specified, instead getting </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">)</span> <span class="o">%</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span>
    <span class="c1"># Later variable will init from Tensor value instead of intializer callable.</span>
    <span class="n">v_init</span> <span class="o">=</span> <span class="n">init_wrapper</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">v_init</span><span class="p">)</span>

  <span class="c1"># TODO(yonghui): Possibly get away from variable_scope and implement our own</span>
  <span class="c1"># variable sharing mechanism.</span>
  <span class="k">def</span> <span class="nf">GetVar</span><span class="p">(</span><span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;reuse: Whether to reuse the variables.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
      <span class="n">var_name</span> <span class="o">=</span> <span class="n">GetVariableName</span><span class="p">(</span><span class="n">scope</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="n">var_scope</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">VariableScope</span><span class="p">(</span>
          <span class="n">scope</span><span class="o">.</span><span class="n">reuse</span><span class="p">,</span>
          <span class="n">custom_getter</span><span class="o">=</span><span class="n">scope</span><span class="o">.</span><span class="n">custom_getter</span><span class="p">,</span>
          <span class="n">caching_device</span><span class="o">=</span><span class="n">scope</span><span class="o">.</span><span class="n">caching_device</span><span class="p">,</span>
          <span class="n">use_resource</span><span class="o">=</span><span class="n">scope</span><span class="o">.</span><span class="n">use_resource</span> <span class="ow">or</span> <span class="n">use_resource_variables</span><span class="p">())</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">var_scope</span><span class="p">),</span> \
        <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">var_name</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="n">reuse</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
          <span class="s1">&#39;var&#39;</span><span class="p">,</span>
          <span class="n">shape</span><span class="p">,</span>
          <span class="n">dtype</span><span class="p">,</span>
          <span class="n">v_init</span><span class="p">,</span>
          <span class="n">collections</span><span class="o">=</span><span class="n">collections</span><span class="p">,</span>
          <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>
          <span class="n">validate_shape</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">False</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">_get_opportunistic_variable_reuse</span><span class="p">()[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">var</span> <span class="o">=</span> <span class="n">GetVar</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>  <span class="c1"># Possibly the variable already exists</span>
      <span class="n">var</span> <span class="o">=</span> <span class="n">GetVar</span><span class="p">(</span><span class="n">reuse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">GetVar</span><span class="p">()</span>

  <span class="n">all_vars</span> <span class="o">=</span> <span class="n">_get_all_vars</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Reusing var </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">cached</span> <span class="o">=</span> <span class="n">all_vars</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">cached</span> <span class="o">==</span> <span class="n">p</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;Cached config:</span><span class="se">\n</span><span class="s1"> </span><span class="si">%s</span><span class="s1"> vs new config:</span><span class="se">\n</span><span class="s1"> </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                         <span class="p">(</span><span class="n">cached</span><span class="o">.</span><span class="n">ToText</span><span class="p">(),</span> <span class="n">p</span><span class="o">.</span><span class="n">ToText</span><span class="p">()))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Creating var </span><span class="si">%s</span><span class="s1"> and device </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">var</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">all_vars</span><span class="p">[</span><span class="n">var</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">Copy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">collections</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>

  <span class="c1"># This tf.identity colocated with var.</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">var</span><span class="p">),</span> <span class="n">var</span></div>


<span class="n">global_variable_scope</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable_scope</span><span class="p">()</span>


<div class="viewcode-block" id="GetOrCreateGlobalStep"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.GetOrCreateGlobalStep">[docs]</a><span class="k">def</span> <span class="nf">GetOrCreateGlobalStep</span><span class="p">():</span>
  <span class="sd">&quot;&quot;&quot;Create if needed and return the global_step.&quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span>
      <span class="n">global_variable_scope</span><span class="p">,</span> <span class="n">use_resource</span><span class="o">=</span><span class="n">use_resource_variables</span><span class="p">()):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_or_create_global_step</span><span class="p">()</span></div>


<div class="viewcode-block" id="CreateTaskGlobalStep"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.CreateTaskGlobalStep">[docs]</a><span class="k">def</span> <span class="nf">CreateTaskGlobalStep</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">task_name</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Create if needed and return the global_step.&quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="n">global_variable_scope</span><span class="p">):</span>
    <span class="n">graph_collections</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">GLOBAL_VARIABLES</span><span class="p">,</span> <span class="s1">&#39;TASK_GLOBAL_STEP&#39;</span><span class="p">]</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">CreateVariable</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">task_name</span> <span class="o">+</span> <span class="s1">&#39;_global_step&#39;</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="n">WeightParams</span><span class="p">([],</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="n">graph_collections</span><span class="p">)</span>
    <span class="n">_scalar</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">v</span></div>


<div class="viewcode-block" id="_LogPlacement"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._LogPlacement">[docs]</a><span class="k">def</span> <span class="nf">_LogPlacement</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">copy</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Logs theta and its copy&#39;s device placement.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">GetDevices</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Flatten a NestedMap m and extracts each value&#39;s device.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()]</span>

  <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;=== </span><span class="si">%s</span><span class="s1"> ===&#39;</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
      <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span>
      <span class="n">theta</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span>
          <span class="p">[(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> -&gt; </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
           <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">GetDevices</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="n">GetDevices</span><span class="p">(</span><span class="n">copy</span><span class="p">))])</span><span class="o">.</span><span class="n">DebugString</span><span class="p">())</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;==========&#39;</span><span class="p">)</span></div>


<div class="viewcode-block" id="CreateLocalTheta"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.CreateLocalTheta">[docs]</a><span class="k">def</span> <span class="nf">CreateLocalTheta</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">device_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Creates local copy of theta and shards across devices device list.</span>

<span class="sd">  Leaves variables intact.</span>

<span class="sd">  Args:</span>
<span class="sd">    theta: a NestedMap of variables.</span>
<span class="sd">    device_list: list of devices to shard across. If None, defaults</span>
<span class="sd">      to a list [&#39;&#39;].</span>
<span class="sd">    label: Logging label.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `.NestedMap` of identity() wrapped theta</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">class</span> <span class="nc">AddIdentity</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device_list</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_list</span> <span class="o">=</span> <span class="n">device_list</span> <span class="k">if</span> <span class="n">device_list</span> <span class="k">else</span> <span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_index</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_index</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_list</span><span class="p">)]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_index</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

  <span class="n">copy</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="n">AddIdentity</span><span class="p">(</span><span class="n">device_list</span><span class="p">))</span>
  <span class="n">_LogPlacement</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">copy</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">copy</span></div>


<div class="viewcode-block" id="_GetVarsToLoad"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._GetVarsToLoad">[docs]</a><span class="k">def</span> <span class="nf">_GetVarsToLoad</span><span class="p">(</span><span class="n">all_vars</span><span class="p">,</span> <span class="n">variable_loading_rules</span><span class="p">,</span> <span class="n">var_ignore_rules</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Determines variables to load and their names in checkpoint.&quot;&quot;&quot;</span>
  <span class="c1"># This list contains mappings from var names as they appear in the checkpoint</span>
  <span class="c1"># to the vars in our model they correspond to.</span>
  <span class="n">vars_to_load</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">model_var</span> <span class="ow">in</span> <span class="n">all_vars</span><span class="p">:</span>
    <span class="n">already_matched</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">for</span> <span class="n">regexp</span><span class="p">,</span> <span class="n">name_format</span> <span class="ow">in</span> <span class="n">variable_loading_rules</span><span class="p">:</span>
      <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">regexp</span><span class="p">,</span> <span class="n">model_var</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="c1"># Skip if var doesn&#39;t match the loading rules, or if it should be ignored.</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">match</span> <span class="ow">or</span> <span class="nb">any</span><span class="p">(</span>
          <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">model_var</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">var_ignore_rules</span><span class="p">):</span>
        <span class="k">continue</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="n">already_matched</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> is already matched!&#39;</span> <span class="o">%</span> <span class="n">model_var</span><span class="o">.</span><span class="n">name</span>
      <span class="n">already_matched</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="n">checkpoint_var_name</span> <span class="o">=</span> <span class="n">name_format</span> <span class="o">%</span> <span class="n">match</span><span class="o">.</span><span class="n">groups</span><span class="p">()</span>
      <span class="k">if</span> <span class="n">checkpoint_var_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;:0&#39;</span><span class="p">):</span>
        <span class="n">checkpoint_var_name</span> <span class="o">=</span> <span class="n">checkpoint_var_name</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
      <span class="n">vars_to_load</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">checkpoint_var_name</span><span class="p">,</span> <span class="n">model_var</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">vars_to_load</span></div>


<div class="viewcode-block" id="_OverrideVarsFromCheckpoint"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._OverrideVarsFromCheckpoint">[docs]</a><span class="k">def</span> <span class="nf">_OverrideVarsFromCheckpoint</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span>
                                <span class="n">variable_loading_rules</span><span class="p">,</span> <span class="n">var_ignore_rules</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Overrides variables from a provided checkpoint.&quot;&quot;&quot;</span>
  <span class="n">vars_to_load</span> <span class="o">=</span> <span class="n">_GetVarsToLoad</span><span class="p">(</span><span class="n">all_vars</span><span class="p">,</span> <span class="n">variable_loading_rules</span><span class="p">,</span>
                                <span class="n">var_ignore_rules</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">vars_to_load</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Variable loading rules did not match any vars.&#39;</span><span class="p">)</span>
  <span class="n">load_var_names</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">v</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vars_to_load</span><span class="p">])</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Overriding vars from checkpoint: </span><span class="si">%r</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">load_var_names</span><span class="p">)</span>

  <span class="k">while</span> <span class="n">vars_to_load</span><span class="p">:</span>
    <span class="c1"># When restoring, it&#39;s possible the same value in the checkpoint</span>
    <span class="c1"># can be restored to multiple variables (e.g. during</span>
    <span class="c1"># distillation).  However, tf.train.Saver, since it&#39;s used for</span>
    <span class="c1"># both saving and restoring, requires the name in the checkpoint</span>
    <span class="c1"># to be unique for each variable.  So, we call it multiple times</span>
    <span class="c1"># with a unique set of names each time.</span>
    <span class="n">unique_vars_to_load</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">remaining_vars_to_load</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vars_to_load</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unique_vars_to_load</span><span class="p">:</span>
        <span class="n">unique_vars_to_load</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">remaining_vars_to_load</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="n">var_list</span><span class="o">=</span><span class="n">unique_vars_to_load</span><span class="p">)</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">)</span>
    <span class="n">vars_to_load</span> <span class="o">=</span> <span class="n">remaining_vars_to_load</span></div>


<div class="viewcode-block" id="OverrideVarsFromCheckpoints"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.OverrideVarsFromCheckpoints">[docs]</a><span class="k">def</span> <span class="nf">OverrideVarsFromCheckpoints</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">,</span> <span class="n">ckpts_loading_rules</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Overrides model variables from checkpoints.</span>

<span class="sd">  Args:</span>
<span class="sd">    session: Tensorflow session.</span>
<span class="sd">    all_vars: List of all the parameters in the model.</span>
<span class="sd">    ckpts_loading_rules: A dictionary of checkpoint path: loading rules.</span>
<span class="sd">        Checkpoint path must be a path to a pretrained model, and loading rules</span>
<span class="sd">        is expected to be a tuple of two lists: the first consisting of tuples</span>
<span class="sd">        of strings defining (regex to match parameter names in the model to</span>
<span class="sd">        override, format string to determine the corresponding var in the</span>
<span class="sd">        checkpoint), and the second list consisting of a list of regexes to</span>
<span class="sd">        match parameter names in the model which should not be overridden,</span>
<span class="sd">        even if they match those in the loading rules.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if colliding vars exist or loading rules is not a list.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ckpts_loading_rules</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Overriding vars from multiple checkpoints.&#39;</span><span class="p">)</span>

  <span class="n">vars_overridden</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">loading_rules</span> <span class="ow">in</span> <span class="n">ckpts_loading_rules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Overriding vars from checkpoint: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loading_rules</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;Loading rules for </span><span class="si">%s</span><span class="s1"> must be a tuple of two lists!&#39;</span> <span class="o">%</span> <span class="n">ckpt_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loading_rules</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">loading_rules</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;Loading rules for </span><span class="si">%s</span><span class="s1"> must be a tuple of two lists!&#39;</span> <span class="o">%</span> <span class="n">ckpt_path</span><span class="p">)</span>

    <span class="c1"># Filter the model variables to be overridden.</span>
    <span class="n">vars_to_override</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">var</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">_GetVarsToLoad</span><span class="p">(</span><span class="n">all_vars</span><span class="p">,</span> <span class="n">loading_rules</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">loading_rules</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="p">]</span>

    <span class="n">overlap</span> <span class="o">=</span> <span class="nb">set</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">vars_overridden</span><span class="p">,</span> <span class="n">vars_to_override</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">overlap</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Colliding variables to override: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">overlap</span><span class="p">)</span>

    <span class="n">_OverrideVarsFromCheckpoint</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">loading_rules</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                <span class="n">loading_rules</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">vars_overridden</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">vars_to_override</span><span class="p">)</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Model variables overridden: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">vars_overridden</span><span class="p">)</span></div>


<div class="viewcode-block" id="_ComputeGradientsSimple"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._ComputeGradientsSimple">[docs]</a><span class="k">def</span> <span class="nf">_ComputeGradientsSimple</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span>
      <span class="n">loss</span><span class="p">,</span>
      <span class="n">all_vars</span><span class="p">,</span>
      <span class="n">aggregation_method</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># Tree</span>
      <span class="n">colocate_gradients_with_ops</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="_ComputeGradientsTpu"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._ComputeGradientsTpu">[docs]</a><span class="k">def</span> <span class="nf">_ComputeGradientsTpu</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes gradients for local loss across whole TPU cluster.&quot;&quot;&quot;</span>
  <span class="c1"># Scale the loss to account for the full batch size.</span>
  <span class="n">shards</span> <span class="o">=</span> <span class="n">tpu_function</span><span class="o">.</span><span class="n">get_tpu_context</span><span class="p">()</span><span class="o">.</span><span class="n">number_of_shards</span>
  <span class="k">assert</span> <span class="n">shards</span>
  <span class="n">loss</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">shards</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

  <span class="c1"># Computes the gradients.</span>
  <span class="c1"># Sum the grads so that we can compute statistics across the whole batch.</span>
  <span class="n">all_grads</span> <span class="o">=</span> <span class="n">_ComputeGradientsSimple</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">all_vars</span><span class="p">)</span>

  <span class="c1"># NOTE: We can&#39;t use tpu_optimizer.CrossShardOptimizer since</span>
  <span class="c1"># we need to scale the grads *after* the cross_replica_sum to</span>
  <span class="c1"># match GPU version!</span>
  <span class="c1"># TODO(cwhipkey): should we do something different here? - we could do</span>
  <span class="c1"># some operations on the gradients before the aggregation (see comments in</span>
  <span class="c1"># tensorflow/contrib/tpu/python/tpu/tpu_optimizer.py - see compute_gradients -</span>
  <span class="c1"># for some more details).</span>
  <span class="n">aggregated_grads</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">all_grads</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">g</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">colocate_with</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
        <span class="n">aggregated_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">tpu</span><span class="o">.</span><span class="n">cross_replica_sum</span><span class="p">(</span><span class="n">g</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">aggregated_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">aggregated_grads</span></div>


<div class="viewcode-block" id="ComputeGradients"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ComputeGradients">[docs]</a><span class="k">def</span> <span class="nf">ComputeGradients</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">vmap</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes gradients of variables in vmap w.r.t. to loss.</span>

<span class="sd">  Args:</span>
<span class="sd">    loss: A scalar Tensor.</span>
<span class="sd">    vmap: A `.NestedMap` of variables.</span>

<span class="sd">  Returns:</span>
<span class="sd">    var_grad - a NestedMap of (variable, gradient). You can view</span>
<span class="sd">    var_grad as an ordered list of (key, (var, grad)) tuples. Every</span>
<span class="sd">    key of var_grad exists in vmap. Every variable in vmap that</span>
<span class="sd">    contributes to loss must exist in var_grad. Every var of var_grad</span>
<span class="sd">    must exist in vmap.  grad is the corresponding gradient computed</span>
<span class="sd">    for var. grad is guaranteed to be not None.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">HasRank</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vmap</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">)</span>

  <span class="c1"># Uniqify and remove None.</span>
  <span class="n">filtered_vmap</span> <span class="o">=</span> <span class="n">vmap</span><span class="o">.</span><span class="n">Filter</span><span class="p">(</span><span class="n">_Unique</span><span class="p">())</span>
  <span class="k">assert</span> <span class="n">filtered_vmap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

  <span class="c1"># Filter out variables not contributing to &#39;loss&#39;.</span>
  <span class="n">trainable_variables</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">())</span>
  <span class="n">dependent_ops_and_tensors</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">FindNeeded</span><span class="p">([</span><span class="n">loss</span><span class="p">]))</span>

  <span class="k">def</span> <span class="nf">Needed</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">v</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">trainable_variables</span><span class="p">:</span>
        <span class="c1"># Skip non-trainable variables. Otherwise,</span>
        <span class="c1"># tf.Optimizer.apply_gradients throws up an exception instead</span>
        <span class="c1"># of skipping the update.</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="c1"># Not sure needed since tf.gradients will do this for us.</span>
    <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">dependent_ops_and_tensors</span>

  <span class="n">filtered_vmap</span> <span class="o">=</span> <span class="n">filtered_vmap</span><span class="o">.</span><span class="n">Filter</span><span class="p">(</span><span class="n">Needed</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">filtered_vmap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
  <span class="n">filtered_vlist</span> <span class="o">=</span> <span class="n">filtered_vmap</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

  <span class="c1"># tpu vs non-tpu is slightly different.</span>
  <span class="n">take_grad</span> <span class="o">=</span> <span class="n">_ComputeGradientsTpu</span> <span class="k">if</span> <span class="n">use_tpu</span><span class="p">()</span> <span class="k">else</span> <span class="n">_ComputeGradientsSimple</span>
  <span class="n">grads</span> <span class="o">=</span> <span class="n">take_grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">filtered_vlist</span><span class="p">)</span>

  <span class="c1"># Formulate pairs of (var, grad) and pack them into the same</span>
  <span class="c1"># structure as filtered_vmap.</span>
  <span class="n">var_grad</span> <span class="o">=</span> <span class="n">filtered_vmap</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">filtered_vlist</span><span class="p">,</span> <span class="n">grads</span><span class="p">)))</span>

  <span class="c1"># Removes pairs whose grad is None.</span>
  <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span> <span class="ow">in</span> <span class="n">var_grad</span><span class="o">.</span><span class="n">FlattenItems</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">g</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;ComputeGradients drops </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">var_grad</span><span class="o">.</span><span class="n">Filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v_g</span><span class="p">:</span> <span class="n">v_g</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span></div>


<div class="viewcode-block" id="ApplyGradMultiplier"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ApplyGradMultiplier">[docs]</a><span class="k">def</span> <span class="nf">ApplyGradMultiplier</span><span class="p">(</span><span class="n">vs_gs_scale</span><span class="p">,</span> <span class="n">grad_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Scale gradients by grad_scale on same device as corresponding variables.</span>

<span class="sd">  Args:</span>
<span class="sd">    vs_gs_scale: A `.NestedMap` of (variable, gradient, scale).</span>
<span class="sd">    grad_scale: If None, each vs_gs entry has the scale. Otherwise,</span>
<span class="sd">      grad_scale applies to every entry.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `.NestedMap` of (variable, gradient * grad_scale). In particular, if</span>
<span class="sd">    grad_scale is 0, the result gradient is always 0, even if the input</span>
<span class="sd">    gradient is inf or nan.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">if</span> <span class="n">grad_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">vs_gs_scale</span> <span class="o">=</span> <span class="n">vs_gs_scale</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">v_g</span><span class="p">:</span> <span class="p">(</span><span class="n">v_g</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v_g</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">grad_scale</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">ScaleOrZero</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">CheckNumerics</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> is not finite.&#39;</span> <span class="o">%</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="mf">0.</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">grad</span><span class="p">),</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">grad</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">Scale</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Scales the gradient.&quot;&quot;&quot;</span>
    <span class="n">var</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">item</span>
    <span class="k">assert</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;No grad found for &#39;</span><span class="p">,</span> <span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">IndexedSlices</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">IndexedSlices</span><span class="p">(</span>
            <span class="n">ScaleOrZero</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">grad</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">scale</span><span class="p">),</span> <span class="n">grad</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span>
            <span class="n">grad</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">ScaleOrZero</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">vs_gs_scale</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="n">Scale</span><span class="p">)</span></div>


<div class="viewcode-block" id="AdjustGradientsWithL2Loss"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.AdjustGradientsWithL2Loss">[docs]</a><span class="k">def</span> <span class="nf">AdjustGradientsWithL2Loss</span><span class="p">(</span><span class="n">var_grads</span><span class="p">,</span> <span class="n">l2_regularizer_weight</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Adjusts the map of (var, grad) with L2 regularization.</span>

<span class="sd">  Args:</span>
<span class="sd">    var_grads: a NestedMap of (variable, gradient).</span>
<span class="sd">    l2_regularizer_weight: L2 regularization weight.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple (l2_loss, var_grads).</span>

<span class="sd">    - l2_loss: A scalar. The l2 loss.</span>
<span class="sd">    - var_grads: a NestedMap of (variable, gradient) regulated by L2.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">GetVar</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
    <span class="n">var</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">item</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">IndexedSlices</span><span class="p">):</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="n">HasRank</span><span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">uniq_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span><span class="o">.</span><span class="n">y</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">uniq_ids</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">var</span>

  <span class="n">l2_loss</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">l2_regularizer_weight</span> <span class="o">*</span> <span class="n">SumSquared</span><span class="p">(</span>
      <span class="n">var_grads</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="n">GetVar</span><span class="p">)</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>

  <span class="k">def</span> <span class="nf">L2Grad</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adjusts item&#39;s grad w/ L2 loss term.&quot;&quot;&quot;</span>
    <span class="n">var</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">item</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">IndexedSlices</span><span class="p">):</span>
      <span class="c1"># Note: IndexedSlces appears for embedding lookups.</span>
      <span class="c1"># Embedding lookup ids can have duplicate. For duplicated ids, we</span>
      <span class="c1"># only want to consider once for each ids.</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">HasRank</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">emb</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">ids</span> <span class="o">=</span> <span class="n">HasRank</span><span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span>  <span class="c1"># [#ids, dims]</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="c1"># Counts is a vector of size vocab_size. counts[i] is i-th words</span>
        <span class="c1"># occurances in &#39;ids&#39;.</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unsorted_segment_sum</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">values</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ids</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

        <span class="c1"># Gradients for duplicated ids will be summed when they get</span>
        <span class="c1"># applied, and hence we account for that by first dividing</span>
        <span class="c1"># gradient resulting from l2 loss by how many times the id is</span>
        <span class="c1"># duplicated.</span>
        <span class="c1">#</span>
        <span class="c1"># For each id in &#39;ids&#39;, we know counts[id] is non-zero,</span>
        <span class="c1"># hence, it&#39;s always safe to take reciprocal.</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">ids</span><span class="p">))</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># [#ids, 1]</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">l2_regularizer_weight</span> <span class="o">*</span> <span class="n">weights</span> <span class="o">*</span> <span class="n">values</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">IndexedSlices</span><span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">values</span> <span class="o">+</span> <span class="n">delta</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">l2_regularizer_weight</span> <span class="o">*</span> <span class="n">var</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">grad</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">+=</span> <span class="n">delta</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">grad</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">l2_loss</span><span class="p">,</span> <span class="n">var_grads</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="n">L2Grad</span><span class="p">)</span></div>


<div class="viewcode-block" id="SplitRecursively"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.SplitRecursively">[docs]</a><span class="k">def</span> <span class="nf">SplitRecursively</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_splits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Splits Tensors in &#39;x&#39; recursively.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: a Tensor, or a list or NestMap containing Tensors to split.</span>
<span class="sd">    num_splits: number of splits per Tensor.</span>
<span class="sd">    axis: the split axis.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list of split values of length &#39;num_splits&#39;.</span>

<span class="sd">    - If &#39;x&#39; is a Tensor, a list of split Tensors.</span>
<span class="sd">    - If &#39;x&#39; is a list, a list of lists, where each sublist has the same length</span>
<span class="sd">      as &#39;x&#39; and the k&#39;th element in each sublist corresponds to a split of the</span>
<span class="sd">      k&#39;th element from &#39;x&#39;.</span>
<span class="sd">    - If &#39;x&#39; is a NestedMap, a list of `.NestedMap`, where each field</span>
<span class="sd">      corresponds to a split from the same field of &#39;x&#39;.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">num_splits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
    <span class="n">splits</span> <span class="o">=</span> <span class="p">[</span><span class="n">SplitRecursively</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="n">num_splits</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
    <span class="n">splits</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">splits</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">]</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">NestedMap</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_splits</span><span class="p">)]</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="n">val_splits</span> <span class="o">=</span> <span class="n">SplitRecursively</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">num_splits</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_splits</span><span class="p">):</span>
        <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val_splits</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">results</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Unexpected type for SplitRecursively: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></div>


<div class="viewcode-block" id="ConcatRecursively"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ConcatRecursively">[docs]</a><span class="k">def</span> <span class="nf">ConcatRecursively</span><span class="p">(</span><span class="n">splits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Concatenates tensors from &#39;splits&#39;.</span>

<span class="sd">  This is the inverse function of SplitRecursively.</span>

<span class="sd">  Args:</span>
<span class="sd">    splits: a list of splits to concatenate, where elements can be Tensors,</span>
<span class="sd">      lists, or `.NestedMap`. The elements must share the same type and</span>
<span class="sd">      structure.  For example, list elements must have the same length;</span>
<span class="sd">      `.NestedMap` must have the same set of fields.</span>
<span class="sd">    axis: the concatenation axis.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Concatenated data.</span>

<span class="sd">    - If input &#39;splits&#39; are Tensors, returns a concatenated Tensor.</span>
<span class="sd">    - If input &#39;splits&#39; are lists, returns a list of the same length where the</span>
<span class="sd">      k&#39;th element represents concatenated data of the k&#39;th element from each</span>
<span class="sd">      split.</span>
<span class="sd">    - If input &#39;splits&#39; are `.NestedMap`, returns a NestedMap with each field</span>
<span class="sd">      concatenated from corresponding fields of input splits.</span>

<span class="sd">  Raises:</span>
<span class="sd">    TypeError: if &#39;splits&#39; is not a list or elements of &#39;splits&#39; do not have</span>
<span class="sd">      known or matching types.</span>
<span class="sd">    ValueError: if &#39;splits&#39; is empty or elements of &#39;splits&#39; do not have</span>
<span class="sd">      matching structures.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">splits</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Non-list inputs for ConcatRecursively: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">splits</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">splits</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Empty inputs for ConcatRecursively: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">splits</span><span class="p">)</span>

  <span class="n">tmpl</span> <span class="o">=</span> <span class="n">splits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tmpl</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">splits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tmpl</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Type mismatch for ConcatRecursively: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">splits</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">split</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">tmpl</span><span class="p">)</span> <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Length mismatch for ConcatRecursively: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">splits</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">ConcatRecursively</span><span class="p">([</span><span class="n">split</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                           <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">],</span> <span class="n">axis</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tmpl</span><span class="p">))</span>
    <span class="p">]</span>
  <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tmpl</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">split</span><span class="p">,</span> <span class="n">NestedMap</span><span class="p">)</span> <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Type mismatch for ConcatRecursively: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">splits</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">NestedMap</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">tmpl</span><span class="p">:</span>
      <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ConcatRecursively</span><span class="p">([</span><span class="n">split</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">splits</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">results</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Unexpected type for ConcatRecursively: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">splits</span><span class="p">))</span></div>


<div class="viewcode-block" id="AddToPruningCollections"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.AddToPruningCollections">[docs]</a><span class="k">def</span> <span class="nf">AddToPruningCollections</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Add mask, threshold, and weight vars to their respective collections.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">mask</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">pruning_layers</span><span class="o">.</span><span class="n">MASK_COLLECTION</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="n">pruning_layers</span><span class="o">.</span><span class="n">WEIGHT_COLLECTION</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="n">pruning_layers</span><span class="o">.</span><span class="n">MASK_COLLECTION</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="n">pruning_layers</span><span class="o">.</span><span class="n">THRESHOLD_COLLECTION</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span></div>


<div class="viewcode-block" id="WeightedAvg"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightedAvg">[docs]</a><span class="k">def</span> <span class="nf">WeightedAvg</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">sum_reduction_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes weighted average of values from a tensor.</span>

<span class="sd">  Args:</span>
<span class="sd">    values: a tensor of values</span>
<span class="sd">    weights: a tensor of weights</span>
<span class="sd">    sum_reduction_fn: called to reduce the values and weights to single value.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple (avg, total_weight).</span>

<span class="sd">    - avg: weighted average value</span>
<span class="sd">    - total_weight: sum of all weights</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">values</span> <span class="o">=</span> <span class="n">with_dependencies</span><span class="p">([</span>
      <span class="n">assert_equal</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">values</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
          <span class="n">message</span><span class="o">=</span><span class="s1">&#39;shape of values and weights tensors must match.&#39;</span><span class="p">)</span>
  <span class="p">],</span> <span class="n">values</span><span class="p">)</span>
  <span class="n">total_weight</span> <span class="o">=</span> <span class="n">sum_reduction_fn</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
  <span class="n">avg</span> <span class="o">=</span> <span class="n">sum_reduction_fn</span><span class="p">(</span><span class="n">values</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
      <span class="n">total_weight</span><span class="p">,</span> <span class="n">values</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">avg</span><span class="p">,</span> <span class="n">total_weight</span></div>


<div class="viewcode-block" id="WeightedAvgOfMetrics"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.WeightedAvgOfMetrics">[docs]</a><span class="k">def</span> <span class="nf">WeightedAvgOfMetrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes the weighted average of metrics in the list.</span>

<span class="sd">  Args:</span>
<span class="sd">    metrics: list of dictionaries of metrics</span>

<span class="sd">  Returns:</span>
<span class="sd">    ret_dict - dictionary of weighted averages of each metrics.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">ret_dict</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="n">lists_of_metrics</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lists_of_metrics</span><span class="p">:</span>
        <span class="n">lists_of_metrics</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="n">lists_of_metrics</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">value</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>

  <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">values_and_weights</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">lists_of_metrics</span><span class="p">)):</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">values_and_weights</span><span class="p">])</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">values_and_weights</span><span class="p">])</span>
    <span class="n">ret_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">WeightedAvg</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">ret_dict</span></div>


<div class="viewcode-block" id="CombineMetrics"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.CombineMetrics">[docs]</a><span class="k">def</span> <span class="nf">CombineMetrics</span><span class="p">(</span><span class="n">loss_metric_weight_pairs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Combines metrics from `loss_metric_weight_pairs` according to weights.</span>

<span class="sd">  Keys must either exist in all metrics, in which it will be processed as a</span>
<span class="sd">  weighted sum, or exist in only one metrics, in which case it will be copied.</span>

<span class="sd">  Args:</span>
<span class="sd">    loss_metric_weight_pairs: a list of (metrics, weight) pairs, where each</span>
<span class="sd">      weight is a float and each metrics is a dict with str keys and</span>
<span class="sd">      (metric_value, target_weight) values.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A dict with the same set of keys as input metrics and values of</span>
<span class="sd">    (weighted_sum(metric_value), weighted_sum(target_weight)).</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if there exists a metric that exists in more than one element</span>
<span class="sd">      of `loss_metric_weight_pairs` but not in all of them.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">all_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span>
      <span class="n">k</span> <span class="k">for</span> <span class="n">loss_metrics</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">loss_metric_weight_pairs</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iterkeys</span><span class="p">(</span><span class="n">loss_metrics</span><span class="p">)</span>
  <span class="p">])</span>
  <span class="n">result</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">all_keys</span><span class="p">:</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">loss_metrics</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">loss_metric_weight_pairs</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">loss_metrics</span><span class="p">:</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">count</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_metric_weight_pairs</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Found metric </span><span class="si">%s</span><span class="s1"> which exists in more than one&#39;</span>
                       <span class="s1">&#39;but not all loss metrics.&#39;</span> <span class="o">%</span> <span class="n">k</span><span class="p">)</span>

    <span class="n">total_val</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_target_weight</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">loss_metrics</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">loss_metric_weight_pairs</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">loss_metrics</span><span class="p">:</span>
        <span class="n">val</span><span class="p">,</span> <span class="n">target_weight</span> <span class="o">=</span> <span class="n">loss_metrics</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
          <span class="c1"># Single metric, don&#39;t multiply by weight.</span>
          <span class="n">total_val</span> <span class="o">=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">target_weight</span>
          <span class="n">total_target_weight</span> <span class="o">=</span> <span class="n">target_weight</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="c1"># Total weighted sum of all predictions.</span>
          <span class="n">total_val</span> <span class="o">+=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">val</span> <span class="o">*</span> <span class="n">target_weight</span>
          <span class="n">total_target_weight</span> <span class="o">+=</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">target_weight</span>

    <span class="n">result</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_val</span> <span class="o">/</span> <span class="n">total_target_weight</span><span class="p">,</span> <span class="n">total_target_weight</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="StatsCounter"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.StatsCounter">[docs]</a><span class="k">class</span> <span class="nc">StatsCounter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A single counter in TF.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_var</span> <span class="o">=</span> <span class="n">CreateVariable</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="n">WeightParams</span><span class="p">([],</span> <span class="n">WeightInit</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
        <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_var</span><span class="o">.</span><span class="n">value</span><span class="p">()</span> <span class="o">+</span> <span class="mi">0</span>  <span class="c1"># Makes a copy.</span>

<div class="viewcode-block" id="StatsCounter.Value"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.StatsCounter.Value">[docs]</a>  <span class="k">def</span> <span class="nf">Value</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the current counter value.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_value</span></div>

<div class="viewcode-block" id="StatsCounter.IncBy"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.StatsCounter.IncBy">[docs]</a>  <span class="k">def</span> <span class="nf">IncBy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">delta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Increment the counter by delta and return the new value.&quot;&quot;&quot;</span>
    <span class="c1"># NOTE: We must ensure _value is computed (_var + 0) before</span>
    <span class="c1"># updating _var with delta.</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">to_int64</span><span class="p">(</span><span class="n">delta</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_value</span><span class="p">]):</span>
      <span class="n">_scalar</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_value</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_var</span><span class="p">,</span> <span class="n">delta</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="_AddVN"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._AddVN">[docs]</a><span class="k">def</span> <span class="nf">_AddVN</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
  <span class="n">seed</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">seed</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">and</span> <span class="n">step</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">+=</span> <span class="n">step</span> <span class="o">*</span> <span class="mi">203984</span>
  <span class="n">noises</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">noises</span></div>


<div class="viewcode-block" id="AddGlobalVN"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.AddGlobalVN">[docs]</a><span class="k">def</span> <span class="nf">AddGlobalVN</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Adds variational noise to weights if specified by params.&quot;&quot;&quot;</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">params</span>
  <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">global_vn</span><span class="p">:</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">_AddVN</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">weights</span></div>


<div class="viewcode-block" id="AddPerStepVN"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.AddPerStepVN">[docs]</a><span class="k">def</span> <span class="nf">AddPerStepVN</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Adds per-setp variational noise to weights if specified by params.&quot;&quot;&quot;</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">params</span>
  <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">vn</span><span class="o">.</span><span class="n">per_step_vn</span><span class="p">:</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">_AddVN</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">weights</span></div>


<div class="viewcode-block" id="VariationalNoiseParams"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.VariationalNoiseParams">[docs]</a><span class="k">def</span> <span class="nf">VariationalNoiseParams</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="n">global_vn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">per_step_vn</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a hyperparams for variational noise.&quot;&quot;&quot;</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">()</span>
  <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span>
      <span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span>
      <span class="s1">&#39;Std of the variational noise to apply . This can be a scalar,&#39;</span>
      <span class="s1">&#39; or a scalar tensor.&#39;</span><span class="p">)</span>
  <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;global_vn&#39;</span><span class="p">,</span> <span class="n">global_vn</span><span class="p">,</span>
           <span class="s1">&#39;Adds global variational noise every training setp iff True.&#39;</span><span class="p">)</span>
  <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;per_step_vn&#39;</span><span class="p">,</span> <span class="n">per_step_vn</span><span class="p">,</span>
           <span class="s1">&#39;Adds per-timesetp variational noise iff True.&#39;</span><span class="p">)</span>
  <span class="n">p</span><span class="o">.</span><span class="n">Define</span><span class="p">(</span><span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="s1">&#39;Random seed used to generate noise.&#39;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">p</span></div>


<div class="viewcode-block" id="GetStepSeed"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.GetStepSeed">[docs]</a><span class="k">def</span> <span class="nf">GetStepSeed</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Gets step_seed.&quot;&quot;&quot;</span>
  <span class="n">graph</span> <span class="o">=</span> <span class="n">graph</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
  <span class="n">step_seed_tensors</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_collection_ref</span><span class="p">(</span><span class="s1">&#39;step_seed&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">step_seed_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">step_seed_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="k">return</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="ResetStepSeed"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ResetStepSeed">[docs]</a><span class="k">def</span> <span class="nf">ResetStepSeed</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Resets step_seed to specified value.&quot;&quot;&quot;</span>
  <span class="n">graph</span> <span class="o">=</span> <span class="n">graph</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
  <span class="n">step_seed_tensors</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_collection_ref</span><span class="p">(</span><span class="s1">&#39;step_seed&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">step_seed_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">step_seed_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="k">elif</span> <span class="ow">not</span> <span class="n">step_seed_tensors</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="s1">&#39;step_seed&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
        <span class="n">seed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Multiple tensors in step_seed collection.&#39;</span><span class="p">)</span></div>


<div class="viewcode-block" id="GetIncStepSeed"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.GetIncStepSeed">[docs]</a><span class="k">def</span> <span class="nf">GetIncStepSeed</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns and increments the step_seed.&quot;&quot;&quot;</span>
  <span class="n">graph</span> <span class="o">=</span> <span class="n">graph</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
  <span class="n">step_seed_tensors</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_collection_ref</span><span class="p">(</span><span class="s1">&#39;step_seed&#39;</span><span class="p">)</span>
  <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">step_seed_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">step_seed_tensors</span><span class="p">)</span>
  <span class="n">step_seed</span> <span class="o">=</span> <span class="n">step_seed_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="c1"># TODO(lepikhin): introduce a routine filling a queue of uint32 random seeds</span>
  <span class="c1"># independent of underlying PRNG used by tensorflow.</span>
  <span class="n">step_seed_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">step_seed_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
  <span class="k">return</span> <span class="n">step_seed</span></div>


<div class="viewcode-block" id="GetOpSeedPair"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.GetOpSeedPair">[docs]</a><span class="k">def</span> <span class="nf">GetOpSeedPair</span><span class="p">(</span><span class="n">op_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the seed pair for an operation given op_seed.&quot;&quot;&quot;</span>
  <span class="n">graph</span> <span class="o">=</span> <span class="n">graph</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
  <span class="n">step_seed</span> <span class="o">=</span> <span class="n">GetIncStepSeed</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
  <span class="n">global_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_global_step</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
  <span class="n">seeds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">global_step</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">step_seed</span><span class="p">,</span> <span class="n">global_step</span><span class="o">.</span><span class="n">dtype</span><span class="p">)])</span>

  <span class="k">if</span> <span class="n">op_seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seeds</span> <span class="o">+=</span> <span class="n">op_seed</span>

  <span class="k">return</span> <span class="n">seeds</span></div>


<div class="viewcode-block" id="DeterministicDropout"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.DeterministicDropout">[docs]</a><span class="k">def</span> <span class="nf">DeterministicDropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">seeds</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Similar to `tf.nn.dropout()`, but fully deterministic.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A float Tensor on which to apply dropout.</span>
<span class="sd">    keep_prob: A scalar of keep probability.</span>
<span class="sd">    seeds: A Tensor of shape [2]. 2 seeds for deterministic random number</span>
<span class="sd">      generator.</span>
<span class="sd">    name: An optional name for this operation.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A Tensor with the same shape as `x`.</span>

<span class="sd">  Raises:</span>
<span class="sd">    InvalidArgumentError: if keep_prob is invalid.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">keep_prob</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">keep_prob</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">InvalidArgumentError</span><span class="p">(</span>
        <span class="s1">&#39;keep_prob must be in range (0, 1]. Value: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">keep_prob</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">x</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">as</span> <span class="n">name</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">use_tpu</span><span class="p">():</span>
      <span class="n">seeds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">seeds</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
        <span class="n">keep_prob</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>
    <span class="c1"># uniform in [keep_prob, 1.0 + keep_prob)</span>
    <span class="c1"># StatelessRandomUniform op does not support non-float (e.g. bfloat16) dtype</span>
    <span class="c1"># and non-int32 seed types.</span>
    <span class="n">random_tensor</span> <span class="o">=</span> <span class="n">keep_prob</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">stateless</span><span class="o">.</span><span class="n">stateless_random_uniform</span><span class="p">(</span>
        <span class="n">GetShape</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">seed</span><span class="o">=</span><span class="n">seeds</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)</span>
    <span class="n">binary_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">random_tensor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
      <span class="n">binary_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">binary_tensor</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
      <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">keep_prob</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="o">*</span> <span class="n">binary_tensor</span>
    <span class="n">result</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">result</span></div>


<span class="n">BATCH_NORM_UPDATES</span> <span class="o">=</span> <span class="s1">&#39;batch_norm_updates&#39;</span>

<span class="n">_BATCH_NORM_UPDATES_DICT</span> <span class="o">=</span> <span class="s1">&#39;__batch_norm_update_dict&#39;</span>
<span class="n">_get_batch_norm_updates_dict</span> <span class="o">=</span> <span class="n">_CollectionGetter</span><span class="p">(</span><span class="n">_BATCH_NORM_UPDATES_DICT</span><span class="p">,</span>
                                                 <span class="k">lambda</span><span class="p">:</span> <span class="p">{})</span>


<div class="viewcode-block" id="UpdateBatchNormVars"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.UpdateBatchNormVars">[docs]</a><span class="k">def</span> <span class="nf">UpdateBatchNormVars</span><span class="p">(</span><span class="n">batch_norm_var</span><span class="p">,</span> <span class="n">batch_norm_stats</span><span class="p">,</span> <span class="n">decay</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Update batch normalization moving averages.&quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span>
      <span class="s1">&#39;AssignMovingAvg&#39;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span>
          <span class="n">batch_norm_var</span><span class="p">,</span>
          <span class="n">batch_norm_stats</span><span class="p">,</span>
          <span class="n">decay</span><span class="p">,</span>
      <span class="p">])</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">colocate_with</span><span class="p">(</span><span class="n">batch_norm_var</span><span class="p">):</span>
      <span class="n">decay</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span>
          <span class="mf">1.0</span> <span class="o">-</span> <span class="n">decay</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">batch_norm_var</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">base_dtype</span><span class="p">)</span>
      <span class="n">update_delta</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_norm_var</span> <span class="o">-</span> <span class="n">batch_norm_stats</span><span class="p">)</span> <span class="o">*</span> <span class="n">decay</span>
      <span class="n">bn_update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">assign_sub</span><span class="p">(</span><span class="n">batch_norm_var</span><span class="p">,</span> <span class="n">update_delta</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">scope</span><span class="p">)</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="n">BATCH_NORM_UPDATES</span><span class="p">,</span> <span class="n">bn_update</span><span class="p">)</span>
  <span class="n">bn_update_dict</span> <span class="o">=</span> <span class="n">_get_batch_norm_updates_dict</span><span class="p">()</span>
  <span class="k">assert</span> <span class="n">bn_update</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bn_update_dict</span>
  <span class="n">bn_update_dict</span><span class="p">[</span><span class="n">bn_update</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_norm_var</span><span class="p">,</span> <span class="n">batch_norm_stats</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">bn_update</span></div>


<div class="viewcode-block" id="FindRelevantBatchNormUpdates"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.FindRelevantBatchNormUpdates">[docs]</a><span class="k">def</span> <span class="nf">FindRelevantBatchNormUpdates</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">batch_norm_updates</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Finds and returns a list of relevant batch-normalization updates.</span>

<span class="sd">  Args:</span>
<span class="sd">    loss: The loss that is being optimized for.</span>
<span class="sd">    batch_norm_updates: A list of batch normalization updates.</span>
<span class="sd">  Returns:</span>
<span class="sd">    A pair of lists. The first list contains all the batch normalization updates</span>
<span class="sd">    that are relevant to the loss being optimized, and the second list contains</span>
<span class="sd">    all in batch_norm_updates but not in the first list.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">dependent_ops_and_tensors</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">FindNeeded</span><span class="p">([</span><span class="n">loss</span><span class="p">]))</span>
  <span class="n">relevant_updates</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">irrelevant_updates</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="n">bn_update_dict</span> <span class="o">=</span> <span class="n">_get_batch_norm_updates_dict</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">bn_update</span> <span class="ow">in</span> <span class="n">batch_norm_updates</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">bn_update</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">bn_update_dict</span><span class="p">,</span> <span class="p">(</span>
        <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> is probably not a valid batch normalization update op.&#39;</span>
        <span class="s1">&#39; Make sure batch normalization is done through calling&#39;</span>
        <span class="s1">&#39; the py_utils.UpdateBatchNormVars helper routine.&#39;</span><span class="p">)</span>
    <span class="n">bn_stat_name</span> <span class="o">=</span> <span class="n">bn_update_dict</span><span class="p">[</span><span class="n">bn_update</span><span class="o">.</span><span class="n">name</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
    <span class="k">if</span> <span class="n">bn_stat_name</span> <span class="ow">in</span> <span class="n">dependent_ops_and_tensors</span><span class="p">:</span>
      <span class="c1"># If a batch normalization stat is computed in the forward pass in</span>
      <span class="c1"># computing loss, then the corresponding batch normalization update is</span>
      <span class="c1"># relevant. Otherwise, it is not.</span>
      <span class="n">relevant_updates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn_update</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">irrelevant_updates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bn_update</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">relevant_updates</span><span class="p">,</span> <span class="n">irrelevant_updates</span></div>


<span class="n">_MODEL_SPLIT_ID_STACK</span> <span class="o">=</span> <span class="s1">&#39;__model_split_id_stack&#39;</span>
<span class="n">_get_model_split_id_stack</span> <span class="o">=</span> <span class="n">_CollectionGetter</span><span class="p">(</span><span class="n">_MODEL_SPLIT_ID_STACK</span><span class="p">,</span>
                                              <span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>


<div class="viewcode-block" id="GetModelSplit"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.GetModelSplit">[docs]</a><span class="k">def</span> <span class="nf">GetModelSplit</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">_get_model_split_id_stack</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span></div>


<div class="viewcode-block" id="ModelSplit"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ModelSplit">[docs]</a><span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">ModelSplit</span><span class="p">(</span><span class="n">split_id</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">split_id</span> <span class="o">&gt;=</span> <span class="mi">0</span>
  <span class="n">_get_model_split_id_stack</span><span class="p">()</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">split_id</span><span class="p">)</span>
  <span class="k">yield</span>
  <span class="n">_get_model_split_id_stack</span><span class="p">()</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span></div>


<span class="n">_SAMPLE_STEP_KEY</span> <span class="o">=</span> <span class="s1">&#39;sample_step&#39;</span>


<div class="viewcode-block" id="SampleStep"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.SampleStep">[docs]</a><span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">SampleStep</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A context for a sample step during decoding.</span>

<span class="sd">  Example usage::</span>

<span class="sd">      with py_utils.SampleStep(step):</span>
<span class="sd">        sample = self.DecodeOneStep()</span>

<span class="sd">  Args:</span>
<span class="sd">    step: the step tensor.</span>

<span class="sd">  Yields:</span>
<span class="sd">    a context manager for the step scope.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">stack</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection_ref</span><span class="p">(</span><span class="n">_SAMPLE_STEP_KEY</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
    <span class="k">yield</span> <span class="n">step</span>
  <span class="k">finally</span><span class="p">:</span>
    <span class="n">stack</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span></div>


<div class="viewcode-block" id="_GetSampleStep"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._GetSampleStep">[docs]</a><span class="k">def</span> <span class="nf">_GetSampleStep</span><span class="p">():</span>
  <span class="n">stack</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">_SAMPLE_STEP_KEY</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">stack</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">stack</span> <span class="k">else</span> <span class="kc">None</span></div>


<div class="viewcode-block" id="AddDebugTensor"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.AddDebugTensor">[docs]</a><span class="k">def</span> <span class="nf">AddDebugTensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">summarize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Adds `tensor` to the debug collection.</span>

<span class="sd">  Prints the tensor if `--print_debug_tensors` is True.</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor: A tensor.</span>
<span class="sd">    summarize: Only print this many entries of each tensor. If None,</span>
<span class="sd">      then a maximum of 3 elements are printed per input tensor.</span>
<span class="sd">    name: An optional name for the tensor.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A Tensor that evaluates to the same value as the input tensor.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">FLAGS</span><span class="o">.</span><span class="n">print_debug_tensors</span><span class="p">:</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">_GetSampleStep</span><span class="p">()</span>
    <span class="n">tensors_to_print</span> <span class="o">=</span> <span class="p">([]</span> <span class="k">if</span> <span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="n">step</span><span class="p">])</span> <span class="o">+</span> <span class="p">[</span><span class="n">tensor</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">as</span> <span class="n">s</span><span class="p">:</span>
      <span class="n">tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Print</span><span class="p">(</span>
          <span class="n">tensor</span><span class="p">,</span>
          <span class="n">tensors_to_print</span><span class="p">,</span>
          <span class="n">message</span><span class="o">=</span><span class="s1">&#39;DEBUG tensor </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">s</span><span class="p">,</span>
          <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
          <span class="n">summarize</span><span class="o">=</span><span class="n">summarize</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tensor</span></div>


<div class="viewcode-block" id="ArgMax"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ArgMax">[docs]</a><span class="k">def</span> <span class="nf">ArgMax</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;tf.argmax wrapper.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs: A tensor, whose last dimension is being reduced on.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tensor of rank tf.rank(logits)-1. If i == ret[indices],</span>
<span class="sd">    logits[indices, i] is the maximum among logits[indices, :].</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">use_tpu</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>


<div class="viewcode-block" id="_EnsureMatrixShape"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention._EnsureMatrixShape">[docs]</a><span class="k">def</span> <span class="nf">_EnsureMatrixShape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">x</span><span class="o">.</span><span class="n">set_shape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">ndims</span> <span class="o">==</span> <span class="mi">2</span>
  <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="Matmul"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.Matmul">[docs]</a><span class="k">def</span> <span class="nf">Matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;tf.matmul wrapper expecting x and y are actually matrices.&quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">_EnsureMatrixShape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">_EnsureMatrixShape</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="SumSquared"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.SumSquared">[docs]</a><span class="k">def</span> <span class="nf">SumSquared</span><span class="p">(</span><span class="n">tensor_list</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes sum([x*x for x in tensor_list].&quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;SumSquared&#39;</span><span class="p">):</span>
    <span class="n">sum_squared</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">IndexedSlices</span><span class="p">):</span>
          <span class="n">sum_squared</span> <span class="o">+=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">values</span><span class="p">))]</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">sum_squared</span> <span class="o">+=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">t</span><span class="p">))]</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">sum_squared</span><span class="p">)</span></div>


<div class="viewcode-block" id="PiecewiseConstant"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.PiecewiseConstant">[docs]</a><span class="k">def</span> <span class="nf">PiecewiseConstant</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">vdtype</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns the piecewise value of x_in.&quot;&quot;&quot;</span>
  <span class="n">x_in</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">x_in</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
  <span class="k">assert</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span>
  <span class="n">bs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">boundaries</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">vs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">vdtype</span><span class="p">)</span>
  <span class="c1"># The following is equivalent to &#39;return vs[index]&#39;.</span>
  <span class="n">index</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">bs</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
  <span class="n">one_hot_vec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">depth</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">vdtype</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">Matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">vs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">one_hot_vec</span><span class="p">))[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span></div>


<div class="viewcode-block" id="PadSequenceDimension"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.PadSequenceDimension">[docs]</a><span class="k">def</span> <span class="nf">PadSequenceDimension</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">pad_val</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Pads x to `length` using `pad_val` along the second dim.</span>

<span class="sd">  Assumes `x` is a tensor with rank &gt;= 2, and it only pads `x` to `length`</span>
<span class="sd">  along the second dim. Explicitly sets the returned tensor shape to `shape` if</span>
<span class="sd">  given. Raises runtime errors if x.shape[1] &gt; length or x.shape[i] != shape[i]</span>
<span class="sd">  where i != 1.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: the tensor to be padded with shape [batch, seq_len, ...].</span>
<span class="sd">    length: an int to specify the length to pad x to.</span>
<span class="sd">    pad_val: an int or float used to pad x.</span>
<span class="sd">    shape: an int array specifying the shape of the padded tensor if specified.</span>

<span class="sd">  Returns:</span>
<span class="sd">    The padded tensor with shape [batch, seq_len, ...], where</span>
<span class="sd">    ret[:, :seq_len, ...] == x.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">rank</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">assert_greater_equal</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]):</span>
    <span class="n">slen</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">pad_len</span> <span class="o">=</span> <span class="n">length</span> <span class="o">-</span> <span class="n">slen</span>
  <span class="n">pad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">scatter_nd</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="n">pad_len</span><span class="p">],</span> <span class="p">[</span><span class="n">rank</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="n">pad_val</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">shape</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Shape must be a list or tuple.&#39;</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">HasRank</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">x</span><span class="o">.</span><span class="n">set_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="ApplyPadding"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.ApplyPadding">[docs]</a><span class="k">def</span> <span class="nf">ApplyPadding</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">padded</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">broadcast</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Applies padding to a tensor.</span>

<span class="sd">  This is preferable to using arithmetic means for masking out padded values</span>
<span class="sd">  such as::</span>

<span class="sd">      # Equiv to ApplyPadding(padding, x))</span>
<span class="sd">      x *= 1.0 - padding</span>
<span class="sd">      # Equiv to ApplyPadding(padding, new, old)</span>
<span class="sd">      new = old * padding + new * (1 - padding)</span>

<span class="sd">  Aside from just being easier to read and reason about, using this function</span>
<span class="sd">  is friendly to quantized representations because it does not mix arithmetic</span>
<span class="sd">  on the padding values with the values in the tensor being padded (which can</span>
<span class="sd">  have a very different range than the 0..1 padding tensor).</span>

<span class="sd">  In addition, this works around issues in quantized schemes where we are</span>
<span class="sd">  guaranteed to have an exact 0 but not necessarily any other number (i.e. 1).</span>

<span class="sd">  Args:</span>
<span class="sd">    padding: Tensor of padding values where 0 == keep and 1 == pad.</span>
<span class="sd">    x: Tensor to apply padding to.</span>
<span class="sd">    padded: Optional. Values to include for padded elements. Defaults to</span>
<span class="sd">        zeros. Must be the same shape as &#39;x&#39; if specified.</span>
<span class="sd">    broadcast: Whether to broadcast the padding shape to the shape of &#39;x&#39;.</span>
<span class="sd">        You almost certainly want this to be true as it matches how padding</span>
<span class="sd">        would be expanded if applied arithmetically.</span>
<span class="sd">  Returns:</span>
<span class="sd">    A tensor with the same shape as x with padded values masked.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">padded</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">padded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">broadcast</span><span class="p">:</span>
    <span class="n">padding</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Broadcast padding to the full shape.</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">padding</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">padded</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="Retry"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.Retry">[docs]</a><span class="k">def</span> <span class="nf">Retry</span><span class="p">(</span><span class="n">max_retries</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retry_value</span><span class="o">=</span><span class="ne">Exception</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">retry</span><span class="o">.</span><span class="n">Retry</span><span class="p">(</span><span class="n">max_retries</span><span class="p">,</span> <span class="n">retry_value</span><span class="p">)</span></div>


<span class="c1"># FailedPreconditionError: variables are not initialized.</span>
<span class="c1"># AbortedError: processes restarts.</span>
<span class="c1"># UnavailableError: Bad hardware status: 0x1</span>
<span class="n">transient_tf_errors</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">FailedPreconditionError</span><span class="p">,</span>
                       <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">AbortedError</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">UnavailableError</span><span class="p">)</span>


<div class="viewcode-block" id="RetryOnTransientTfError"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.RetryOnTransientTfError">[docs]</a><span class="k">def</span> <span class="nf">RetryOnTransientTfError</span><span class="p">(</span><span class="n">max_retries</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">Retry</span><span class="p">(</span><span class="n">max_retries</span><span class="o">=</span><span class="n">max_retries</span><span class="p">,</span> <span class="n">retry_value</span><span class="o">=</span><span class="n">transient_tf_errors</span><span class="p">)</span></div>


<div class="viewcode-block" id="PadOrTrimTo"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.PadOrTrimTo">[docs]</a><span class="k">def</span> <span class="nf">PadOrTrimTo</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Pad and slice x to the given shape.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: A tensor.</span>
<span class="sd">    shape: The shape of the returned tensor.</span>

<span class="sd">  Returns:</span>
<span class="sd">    &#39;x&#39; is padded with zeros and sliced so that the result has the given shape.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">HasRank</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">))</span>
  <span class="c1"># If dim-i is less than shape[i], pads on the right shape[i] -</span>
  <span class="c1"># dim-i.  Otherwise, pads [0, 0] for dim-i.</span>
  <span class="n">pad</span> <span class="o">=</span> <span class="n">shape</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">shape</span><span class="p">)</span>
  <span class="n">zeros</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">pad</span><span class="p">)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">zeros</span><span class="p">,</span> <span class="n">pad</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
  <span class="c1"># If dim-i is larger than shape[i], we slice [0:shape[i]] for dim-i.</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">zeros</span><span class="p">,</span> <span class="n">shape</span><span class="p">),</span> <span class="n">shape</span><span class="p">)</span></div>


<div class="viewcode-block" id="StackTensorsRecursively"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.StackTensorsRecursively">[docs]</a><span class="k">def</span> <span class="nf">StackTensorsRecursively</span><span class="p">(</span><span class="n">values</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Recursively stacks Tensors in a list of `.NestedMap`.</span>

<span class="sd">  Args:</span>
<span class="sd">    values: a list of `.NestedMap` or Tensors to stacks.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A `.NestedMap` with stacked values or a stacked Tensor.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">flatten</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">values</span><span class="p">]</span>
  <span class="n">stacked</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">flatten</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
    <span class="n">stacked</span> <span class="o">+=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">flatten</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">flatten</span><span class="p">))])]</span>
  <span class="n">ret</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">Pack</span><span class="p">(</span><span class="n">stacked</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">ret</span></div>


<div class="viewcode-block" id="MixByWeight"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.MixByWeight">[docs]</a><span class="k">def</span> <span class="nf">MixByWeight</span><span class="p">(</span><span class="n">inputs_with_weights</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Returns a weighted random choice from the give inputs.</span>

<span class="sd">  Args:</span>
<span class="sd">    inputs_with_weights: a list of (fn, weight) pairs, where each fn returns</span>
<span class="sd">      a tf.Tensor or a nested structure containing tf.Tensor and weight is a</span>
<span class="sd">      float &gt; 0. Function return types must be consistent across elements.</span>
<span class="sd">      The tf.Operation to compute the result tensor will only be invoked for</span>
<span class="sd">      one input at a time. For example, if each fn represents an input record</span>
<span class="sd">      stream, a record will be drawn only from a selected stream while the other</span>
<span class="sd">      streams will remain unchanged.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A probablistic sample from the inputs proportional to the weights. The</span>
<span class="sd">    return type will be the same as return type of individual &#39;fn&#39; from the</span>
<span class="sd">    inputs.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Compute weight ranges per input.</span>
  <span class="c1"># A list of (input, (cum_weight_low, cum_weight_high))</span>
  <span class="n">inputs_with_weight_ranges</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">cumulative_weight</span> <span class="o">=</span> <span class="mf">0.0</span>
  <span class="k">for</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">inputs_with_weights</span><span class="p">:</span>
    <span class="n">inputs_with_weight_ranges</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="n">cumulative_weight</span><span class="p">,</span>
                                            <span class="n">cumulative_weight</span> <span class="o">+</span> <span class="n">weight</span><span class="p">)))</span>
    <span class="n">cumulative_weight</span> <span class="o">+=</span> <span class="n">weight</span>

  <span class="n">r</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">maxval</span><span class="o">=</span><span class="n">cumulative_weight</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">case</span><span class="p">(</span>
      <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">cum_weight_low</span> <span class="o">&lt;=</span> <span class="n">r</span><span class="p">,</span> <span class="n">r</span> <span class="o">&lt;</span> <span class="n">cum_weight_high</span><span class="p">),</span> <span class="n">inp</span><span class="p">)</span>
       <span class="k">for</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span>
            <span class="p">(</span><span class="n">cum_weight_low</span><span class="p">,</span> <span class="n">cum_weight_high</span><span class="p">))</span> <span class="ow">in</span> <span class="n">inputs_with_weight_ranges</span><span class="p">],</span>
      <span class="n">exclusive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="CheckShapes"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.CheckShapes">[docs]</a><span class="k">def</span> <span class="nf">CheckShapes</span><span class="p">(</span><span class="n">shapes</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Asserts that shapes is a tuple of fully defined tf.TensorShape.&quot;&quot;&quot;</span>
  <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shapes</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">shapes</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shapes</span><span class="p">:</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">s</span><span class="o">.</span><span class="n">is_fully_defined</span><span class="p">()</span></div>


<div class="viewcode-block" id="UpdateFpropDtype"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.UpdateFpropDtype">[docs]</a><span class="k">def</span> <span class="nf">UpdateFpropDtype</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Recursively update the fprop_dtype of the Params.&quot;&quot;&quot;</span>
  <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">IterParams</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">hyperparams</span><span class="o">.</span><span class="n">Params</span><span class="p">):</span>
      <span class="n">UpdateFpropDtype</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">fprop_dtype</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;fprop_dtype&#39;</span><span class="p">:</span>
      <span class="n">params</span><span class="o">.</span><span class="n">fprop_dtype</span> <span class="o">=</span> <span class="n">fprop_dtype</span></div>


<div class="viewcode-block" id="NameScopeDecorator"><a class="viewcode-back" href="../../../lingvo.core.py_utils.html#lingvo.core.attention.NameScopeDecorator">[docs]</a><span class="k">def</span> <span class="nf">NameScopeDecorator</span><span class="p">(</span><span class="n">name_scope</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Decorates a python function to introduce a tf.name_scope.</span>

<span class="sd">  Example::</span>

<span class="sd">      @py_utils.NameScopeDecorator(&#39;foobar&#39;)</span>
<span class="sd">      def MyFoobarMethod(self):</span>
<span class="sd">        # ... Do TF things</span>

<span class="sd">  Args:</span>
<span class="sd">    name_scope: The name scope to introduce.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A function decorator.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">Decorator</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">Wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">name_scope</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Wrapped</span>

  <span class="k">return</span> <span class="n">Decorator</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../',
            VERSION:'',
            LANGUAGE:'en',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>